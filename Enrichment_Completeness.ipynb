{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\n"
     ]
    }
   ],
   "source": [
    "from mgkit.io import gff\n",
    "from mgkit import kegg\n",
    "import mgkit\n",
    "import mgkit.plots\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mgkit.utils import dictionary\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from mgkit import graphs\n",
    "import os, sys\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import datetime\n",
    "import timeit\n",
    "import re\n",
    "import platform\n",
    "import getpass\n",
    "import argparse\n",
    "\n",
    "mgkit.logger.config_log()\n",
    "\n",
    "#On Server\n",
    "#input_dir=\"\"\n",
    "#output_dir=\"\"\n",
    "user=getpass.getuser()\n",
    "if \"windows\" in platform.platform().lower():\n",
    "    windows=True\n",
    "else:\n",
    "    windows=False\n",
    "if windows:\n",
    "    core=os.path.join(\"C:\\Users\",user)\n",
    "    g_drive=\"Google Drive\\Honours\"\n",
    "else:\n",
    "    core=os.path.join(\"/home\",user)\n",
    "    g_drive=\"grive/Honours\"\n",
    "print core\n",
    "\n",
    "#Made some OS agnostic changes\n",
    "#gff_dir=os.path.join(*[core,\"Documents\",\"Hons\",\"Seaquence\",\"francesco_data\",\"gff_bins-2016-06-14\"])\n",
    "gff_dir=os.path.join(*[core,\"Documents\",\"Hons\",\"Seaquence\",\"francesco_data\",\"gff_bins-2016-06-14b\"])\n",
    "#gff_dir=core+\"/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14\"\n",
    "\n",
    "tax_file=os.path.join(*[core,g_drive,\"metabolic_analysis\",\"ID_TAX_BINS_TEMP.txt\"])\n",
    "#tax_file=core+\"/grive/metabolic_analysis/ID_TAX_BINS_TEMP.txt\"\n",
    "\n",
    "output_dir=os.path.join(*[core,g_drive,\"metabolic_analysis\"])\n",
    "#output_dir=core+\"/grive/metabolic_analysis/\"\n",
    "\n",
    "coral_kegg=os.path.join(*[output_dir,\"KO_hits\",\"plut.pathways.txt\"])\n",
    "#coral_kegg=output_dir+\"KO_hits/plut.pathways.txt\"\n",
    "\n",
    "cmn_cpds=os.path.join(*[output_dir,\"Automated_Network_Analyses\",\"boring_cps.txt\"])\n",
    "#cmn_cpds=output_dir+\"Automated_Network_Analyses/boring_cps.txt\"\n",
    "\n",
    "\n",
    "symbiodinium_kegg=os.path.join(*[output_dir,\"KO_hits\",\"SymbC15_firstpass_ko_mapping_protID_distinct_KO.txt\"])\n",
    "#symbiodinium_kegg=output_dir+\"KO_hits/SymbC15_firstpass_ko_mapping_protID_distinct_KO.txt\"\n",
    "\n",
    "#microbial_kegg=os.path.join(*[output_dir,\"KO_hits\",\"Microbial_KO_mapping_protID.txt\"])\n",
    "microbial_kegg=os.path.join(*[output_dir,\"KO_hits\",\"TREMBL_SWISSPROT_Microbial_KO_mapping_protID.txt\"])\n",
    "#microbial_kegg=output_dir+\"KO_hits/Microbial_KO_mapping_protID.txt\"\n",
    "all_kegg=os.path.join(*[output_dir,\"KO_hits\",\"all_kos.txt\"])\n",
    "\n",
    "hmm_dir=os.path.join(*[core,g_drive,\"HMM_searches\",\"Symbioses_test\",\"euk_repeat_results\"])\n",
    "\n",
    "database_dir=os.path.join(output_dir,\"Databases\")\n",
    "\n",
    "abundance_file=os.path.join(*[output_dir,\"Misc_files\",\"id_trimmed_relative_enriched_bin_abundance.tsv\"])\n",
    "\n",
    "raw_coverage_contig=os.path.join(*[output_dir,\"Misc_files\",\"bin_contig_sep_coverages.tsv\"])\n",
    "\n",
    "completeness_contamination=os.path.join(*[output_dir,\"Misc_files\",\"Completeness_Contamination_data.txt\"])\n",
    "\n",
    "gene_dir=os.path.join(*[core,g_drive,\"eukaryote_like_repeats\",\"gene_hits\"])#\"/home/baker/Documents/MountedDrive/seaquence/data/eukaryote_like_repeats/gene_hits\"\n",
    "\n",
    "plots_dir=os.path.join(output_dir,'Plots')\n",
    "\n",
    "def load_cmn_cpds(cmn_cpds):\n",
    "    cpds=set([])\n",
    "    with open(cmn_cpds,'r') as cpd_list:\n",
    "        for line in cpd_list:\n",
    "            cpd=line.strip().split(\"\\t\")[0]\n",
    "            cpds.add(cpd)\n",
    "    return cpds\n",
    "            \n",
    "common_cpds=load_cmn_cpds(cmn_cpds)\n",
    "\n",
    "# General Data loading\n",
    "\n",
    "def store_local_kegg_item_keys(kegg_items,database_dir):\n",
    "    kc=kegg.KeggClientRest()\n",
    "    all_item_names={}\n",
    "    illegal_pairs=[(\"compound\",\"orthology\"),(\"orthology\",\"compound\")]\n",
    "    for kegg_item in kegg_items:\n",
    "        key_name=os.path.join(database_dir,\"{0}_readable_names.tsv\".format(kegg_item))\n",
    "        if not os.path.isfile(key_name):\n",
    "            item_names=kc.get_ids_names(kegg_item)\n",
    "            save_readable_key(key_name,item_names,kegg_item)\n",
    "            all_item_names[kegg_item]=item_names.keys()\n",
    "        else:\n",
    "            all_item_names[kegg_item]=load_readable_names(database_dir,[kegg_item],False)[kegg_item].keys()\n",
    "    for kegg_item_1, kegg_item_2 in itertools.permutations(all_item_names.iterkeys(),2):\n",
    "        print \"considering the pair: {0}, {1}\".format(kegg_item_1,kegg_item_2)\n",
    "        if (kegg_item_1,kegg_item_2) not in illegal_pairs:\n",
    "            shared_key_name=os.path.join(database_dir,\"{0}_linked_{1}_database.tsv\").format(kegg_item_1, kegg_item_2)\n",
    "            if not os.path.isfile(shared_key_name):\n",
    "                print \"The processing of pair: {0},{1} has begun.\".format(kegg_item_1,kegg_item_2)\n",
    "                kc=kegg.KeggClientRest()\n",
    "                linked_ids=kc.link_ids(kegg_item_2,all_item_names[kegg_item_1])\n",
    "                save_key_pairings(shared_key_name,linked_ids,(kegg_item_1,kegg_item_2))\n",
    "        else:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "def load_local_kegg_database_pairings(database_dir,kegg_item_pairs, process_all):\n",
    "    '''Loads the local databases of kegg_item_1, kegg_item_2 pairings and return a dictionary of\n",
    "    these pairings in the form kegg_item_1:kegg_items_2 (There can be more than one linked item). This\n",
    "    loading is based on the earlier use of mgkits kc.link_ids to store all of the pairings needed.\n",
    "    \n",
    "    Input:\n",
    "        database_dir   - The directory with the databases\n",
    "        kegg_item_pairs- A list of kegg item pairs to load\n",
    "        process_all    - A boolean decision as whether to load all existing pairs.\n",
    "        \n",
    "    Output: A dictionary linking either all existing kegg item pairs or just those specified. It has the form\n",
    "    dict[item_1,item_2]={kegg_item_1:kegg_2_items}'''\n",
    "    linking_dictionary={}\n",
    "    if process_all:\n",
    "        for file_name in glob(os.path.join(database_dir,'*database.tsv')):\n",
    "            db_file=os.basename(file_name)\n",
    "            kegg_1=db_file.split(\"_linked_\")[0]\n",
    "            kegg_2=db_file.split(\"_linked_\")[1].split(\"_database\")[0]\n",
    "            linking_dictionary[(kegg_1,kegg_2)]={}             \n",
    "            with open(file_name) as kegg_links:\n",
    "                next(kegg_links)#Skip the header\n",
    "                for line in kegg_links:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    item_2=item_2.split(\";\")\n",
    "                    linking_dictionary[kegg_item_pair][item_1]=item_2\n",
    "        return linking_dictionary\n",
    "    \n",
    "    for kegg_item_pair in kegg_item_pairs:\n",
    "        file_name=os.path.join(database_dir,\"{0}_linked_{1}_database.tsv\").format(kegg_item_pair[0], kegg_item_pair[1])\n",
    "        if os.path.isfile(file_name):\n",
    "            linking_dictionary[kegg_item_pair]={}\n",
    "            with open(file_name) as kegg_links:\n",
    "                next(kegg_links) #skip the header\n",
    "                for line in kegg_links:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    item_2=item_2.split(\";\")\n",
    "                    linking_dictionary[kegg_item_pair][item_1]=item_2\n",
    "    return linking_dictionary\n",
    "                    \n",
    "def load_readable_names(database_dir,kegg_items,process_all):\n",
    "    '''Loads in the readable names for a specified kegg item from a list of databases.\n",
    "    Input:\n",
    "        database_dir        -  The directory with the databases.\n",
    "        kegg_items          -  The kegg items to get the readable mapping for.\n",
    "        process_all         -  Boolean - Should the function retrieve all available databases.\n",
    "    Output:\n",
    "        readable_item_dict  -  A dictionary of KEGG_ID: Readable name pairs'''\n",
    "    readable_item_dict={}\n",
    "    if process_all:\n",
    "        for file_name in glob(os.path.join(database_dir,'*_readable_names.tsv')):\n",
    "            desc_file=os.basename(file_name)\n",
    "            kegg_item=desv_file.split(\"_readable_names.tsv\")[0]\n",
    "            readable_item_dict[kegg_item]={}\n",
    "            with open(file_name) as kegg_descriptions:\n",
    "                next(kegg_descriptions)\n",
    "                for line in kegg_descriptions:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    readable_item_dict[kegg_item][item_1]=item_2\n",
    "        return readable_item_dict\n",
    "    \n",
    "    for kegg_item in kegg_items:\n",
    "        file_name=os.path.join(database_dir,'{0}_readable_names.tsv'.format(kegg_item))\n",
    "        readable_item_dict[kegg_item]={}\n",
    "        with open(file_name) as kegg_descriptions:\n",
    "            next(kegg_descriptions)\n",
    "            for line in kegg_descriptions:\n",
    "                item_1,item_2=line.strip().split(\"\\t\")\n",
    "                readable_item_dict[kegg_item][item_1]=item_2\n",
    "    return readable_item_dict\n",
    "            \n",
    "            \n",
    "def save_readable_key(key_name,item_names,kegg_item):\n",
    "    df=pd.DataFrame([\n",
    "    [col1,col2] for col1,col2 in item_names.iteritems()\n",
    "                   ])\n",
    "    df.columns=[kegg_item,\"Description\"]\n",
    "    df.to_csv(key_name,sep=\"\\t\",index=None)\n",
    "    return None\n",
    "\n",
    "def save_key_pairings(shared_key_name,item_links,kegg_item_tuple):\n",
    "    df=pd.DataFrame([\n",
    "            [col1,\";\".join(col2)] for col1, col2 in item_links.iteritems()\n",
    "        ])\n",
    "    df.columns=[kegg_item_tuple[0],kegg_item_tuple[1]]\n",
    "    df.to_csv(shared_key_name,sep=\"\\t\",index=None)\n",
    "    return None\n",
    "\n",
    "def remove_ko_pth_hits(file_path):\n",
    "    \n",
    "    with open(file_path,'r') as KO_PTH_pairs:\n",
    "        out_dir=os.path.dirname(file_path)\n",
    "        temp_file=open(os.path.join(out_dir,\"temp.tsv\"),'w')\n",
    "        for line in KO_PTH_pairs:\n",
    "            KO,pathways=line.strip().split(\"\\t\")\n",
    "            pathways=pathways.split(\";\")\n",
    "            pathways=[pathway for pathway in pathways if not pathway.startswith(\"ko\")]\n",
    "            pathways=\";\".join(pathways)\n",
    "            new_line=\"{0}\\t{1}\\n\".format(KO,pathways)\n",
    "            temp_file.write(new_line)\n",
    "    temp_file.close()\n",
    "    \n",
    "def make_local_rcn_eqn_database(database_dir):\n",
    "    kc=kegg.KeggClientRest()\n",
    "    all_reactions=load_readable_names(database_dir,[\"reaction\"],False)[\"reaction\"].keys()\n",
    "    rcn_eqns=kc.get_reaction_equations(all_reactions,max_len=10)\n",
    "    file_name=os.path.join(database_dir, \"reaction_equation_links.tsv\")\n",
    "    df=rcn_eqn_pd_df(rcn_eqns)\n",
    "    df.to_csv(file_name,sep=\"\\t\",index=False)\n",
    "        \n",
    "    return\n",
    "\n",
    "def rcn_eqn_pd_df(rcn_eqn_dict):\n",
    "    df=pd.DataFrame([\n",
    "            [rcn, \";\".join(in_cpds),\";\".join(out_cpds)] for rcn, cpds in rcn_eqn_dict.iteritems() for in_cpds,out_cpds in [cpds.values()]\n",
    "    if in_cpds!=[] or out_cpds!=[]    \n",
    "        ])\n",
    "    #df.replace('','NA')\n",
    "    df.columns=[\"Kegg_rcn_ID\",\"side_1_cpds\",\"side_2_cpds\"]\n",
    "    return df\n",
    "\n",
    "def load_local_rcn_eqn_database(database_dir):\n",
    "    file_name=os.path.join(database_dir,\"reaction_equation_links.tsv\")\n",
    "    rcn_eqn_dict={}\n",
    "    n_df=pd.read_csv(file_name,sep=\"\\t\")\n",
    "    n_df.fillna('',inplace=True)\n",
    "    return n_df.set_index(\"Kegg_rcn_ID\").T.to_dict(orient='dict')\n",
    "\n",
    "def load_local_rcn_eqn_database_set(database_dir):\n",
    "    rcn_eqn_pairs=load_local_rcn_eqn_database(database_dir)\n",
    "    return {rcn:{side:set(cpds.split(\";\")) for side,cpds in pairs.iteritems()} for rcn, pairs in rcn_eqn_pairs.iteritems()}\n",
    "            \n",
    "#Load in the coral data\n",
    "def load_bin_names(tax_file):\n",
    "    #Load bin_ids and bins_taxonomy from file.\n",
    "    bin_names={}\n",
    "    bin_pair=[]\n",
    "    with open(tax_file,'r') as bin_tax_pair:\n",
    "        bin_tax_pair.readline()\n",
    "        for line in bin_tax_pair:\n",
    "            bin_pair.append(tuple(line.strip().split(\"\\t\")))\n",
    "\n",
    "    bin_names={bin_id:taxonomy for taxonomy, bin_id in bin_pair}\n",
    "    return bin_names\n",
    "\n",
    "def make_local_complete_module_info_db(database_dir):\n",
    "    '''Creates a local database of the module definitions.'''\n",
    "    all_modules=load_readable_names(database_dir,[\"module\"],False)[\"module\"].keys()\n",
    "    kc=kegg.KeggClientRest()\n",
    "    entries={}\n",
    "    max_len=10\n",
    "    post_processed_defs={}\n",
    "    print \"There are a total of {0} modules to parse\".format(len(all_modules))\n",
    "    N_modules=len(all_modules)\n",
    "    for i in xrange(0,N_modules,max_len):\n",
    "        if N_modules-i<max_len:\n",
    "            n_entries=N_modules-i\n",
    "        else:\n",
    "            n_entries=max_len      \n",
    "        query=\"+\".join(all_modules[i:i+n_entries])\n",
    "        kegg_entries=kc.get_entry(query)\n",
    "        hits=re.findall(\"\\nDEFINITION(.*)\\n\",kegg_entries)\n",
    "        print i, i+max_len-1,\"n_hits:{0}\".format(len(hits))\n",
    "        #if len(hits)!=max_len:\n",
    "        #    print m\n",
    "        for module, definition in itertools.izip(all_modules[i:i+10],hits):\n",
    "            new_def=definition.strip().replace(\" --\",\" \").replace(\"-- \",\" \").replace(\"  \",\" \").strip()\n",
    "            entries[module]=new_def\n",
    "            if \"M\" in definition:\n",
    "                print module,definition\n",
    "                post_processed_defs[module]=new_def\n",
    "        #These post_processed modules should be modules defined in terms of other modules.\n",
    "    for module, definition in post_processed_defs.iteritems():\n",
    "        new_def=definition\n",
    "        print \"This is the definition being considered.\", new_def\n",
    "        new_defs=re.split(\"[, +-]\",definition)\n",
    "        for item in new_defs:\n",
    "            simp_item=item.strip(\")\").strip(\"(\")\n",
    "            if simp_item.startswith(\"M\"):\n",
    "                print \"This is the current item\",item\n",
    "                new_def=new_def.replace(simp_item,\"(\"+entries[simp_item]+\")\")\n",
    "        print new_def\n",
    "        entries[module]=new_def\n",
    "        \n",
    "    temp_entries=entries\n",
    "    protein_complexes='(.)?([K][0-9]+[+]){1,}[K][0-9]+(.)?'\n",
    "    for module, definition in temp_entries.iteritems():\n",
    "        for match in re.finditer(protein_complexes, definition):\n",
    "            match_str=match.group()\n",
    "            if match_str.startswith(\"(\") and match_str.endswith(\")\"):\n",
    "                pass\n",
    "            elif match_str[-1].isdigit() and match_str[0]==\"K\":\n",
    "                match_str=match_str[:] #Trim random end characters\n",
    "                new_match=\"(\"+match_str+\")\"\n",
    "                entries[module]=entries[module].replace(match_str,new_match)\n",
    "            elif match_str[0]==\"K\":\n",
    "                match_str=match_str[0:-1] #Trim random end characters\n",
    "                new_match=\"(\"+match_str+\")\"\n",
    "                entries[module]=entries[module].replace(match_str,new_match)\n",
    "            elif match_str[-1].isdigit():\n",
    "                match_str=match_str[1:] #Trim random end characters\n",
    "                new_match=\"(\"+match_str+\")\"\n",
    "                entries[module]=entries[module].replace(match_str,new_match)\n",
    "            else:\n",
    "                match_str=match_str[1:-1] #Trim random end characters\n",
    "                new_match=\"(\"+match_str+\")\"\n",
    "                entries[module]=entries[module].replace(match_str,new_match)\n",
    "              \n",
    "        if i%100==0:\n",
    "            kc=kegg.KeggClientRest()\n",
    "            print module\n",
    "    print \"{0} modules were parsed\".format(len(entries))\n",
    "    df=pd.DataFrame([\n",
    "            [module,entry] for module,entry in entries.iteritems()\n",
    "        ])\n",
    "    df.columns=[\"Kegg_id\",\"Kegg_definition\"]\n",
    "    df.to_csv(os.path.join(database_dir,\"Module_definitions_pairs_db.tsv\"),sep=\"\\t\",index=None)\n",
    "    \n",
    "    return\n",
    "\n",
    "def load_local_complete_module_info_db(database_dir):\n",
    "    '''Loads a local database of kegg definitions'''\n",
    "    def_dict={}\n",
    "    with open(os.path.join(database_dir,\"Module_definitions_pairs_db.tsv\")) as definitions:\n",
    "        next(definitions)\n",
    "        for line in definitions:\n",
    "            module,kegg_def=line.strip().split(\"\\t\")\n",
    "            def_dict[module]=kegg_def\n",
    "    \n",
    "    return def_dict\n",
    "\n",
    "def make_new_trusted_database(database_dir):\n",
    "    '''\n",
    "    Definition:\n",
    "        This function will take an entire kegg module definition file and will create\n",
    "        a new local database with the expressions written so that they can simple be\n",
    "        evaluated when loading the files.\n",
    "    Input: \n",
    "        database_dir: str\n",
    "            A directory containing the database of kegg module definitions.\n",
    "    Output:\n",
    "        None\n",
    "    Calls:\n",
    "        replacement: Turns kegg definitions in logical nested tuples of sets.\n",
    "    '''\n",
    "    old_module_def=load_local_complete_module_info_db(database_dir)\n",
    "    #print \"This is the old module information\",old_module_def\n",
    "    new_pd_df=[\"\"]*len(old_module_def)\n",
    "    i=0\n",
    "    for module,definition in old_module_def.iteritems():\n",
    "        try:\n",
    "            logical_evaluation=replacement(definition,False)[1]\n",
    "            new_pd_df[i]=[module,logical_evaluation]\n",
    "            i+=1\n",
    "                \n",
    "        except TypeError:\n",
    "            print \"TypeError 2:\",module, definition\n",
    "        except SyntaxError:\n",
    "            print \"SyntaxError 2:\",module, definition\n",
    "        except NameError:\n",
    "            print \"NameError 2:\",module ,definition\n",
    "    #print new_pd_df      \n",
    "    new_pd_df=pd.DataFrame(new_pd_df)\n",
    "    #print \"The second checkpoint.\"\n",
    "    new_pd_df.columns=[\"ModuleID\",\"KEGG_log_expr\"]\n",
    "    \n",
    "    new_pd_df.to_csv(os.path.join(database_dir, \"module_kegg_log_expr.tsv\"),header=True,sep=\"\\t\",index=False)\n",
    "    return None\n",
    "\n",
    "def fix_module_orthology_pairs(database_dir):\n",
    "    '''Replaces the occurences of modules in the module-orthology links to their corresponding KOs'''\n",
    "    all_pairs=load_local_kegg_database_pairings(database_dir,[[\"module\",\"orthology\"]], False)[\"module\",\"orthology\"]\n",
    "    new_pairings=[]\n",
    "    for module,kos in all_pairs.iteritems():\n",
    "        new_items=[]\n",
    "        rand_module=False\n",
    "        for item in kos:\n",
    "            if item.lower().startswith(\"m\"):\n",
    "                new_items.extend(all_pairs[item])\n",
    "                rand_module=True\n",
    "            else:\n",
    "                new_items.append(item)\n",
    "        if rand_module:\n",
    "            new_pairings.append((module, list(set(new_items))))\n",
    "    for (module, new_items) in new_pairings:\n",
    "        all_pairs[module]=new_items\n",
    "        \n",
    "    df=pd.DataFrame([\n",
    "            [col1,\";\".join(col2)] for col1, col2 in all_pairs.iteritems()\n",
    "        ])\n",
    "    df.columns=[kegg_item_tuple[0],kegg_item_tuple[1]]\n",
    "    fixed_name=os.path.join(database_dir,\"\")\n",
    "    df.to_csv(fixed_name,sep=\"\\t\",index=None)\n",
    "    return\n",
    "        \n",
    "def load_local_cleaned_definition_db(extra_def_file):\n",
    "    cleaned_db={}\n",
    "    with open(os.path.join(extra_def_file)) as paired_exprs:\n",
    "        next(paired_exprs) #Skip header\n",
    "        for line in paired_exprs:\n",
    "            module,expr=line.split(\"\\t\")\n",
    "            kegg_log=eval(expr)\n",
    "            if not isinstance(kegg_log,tuple):\n",
    "                kegg_log=tuple([kegg_log])\n",
    "            cleaned_db[module]=kegg_log\n",
    "    return cleaned_db\n",
    "\n",
    "# For remaking graphs\n",
    "\n",
    "pathways = {\n",
    "    'carbon': ['map01200'],\n",
    "    'nitrogen-sulfur-fatty_acid-photosynthesis': ['map00910', 'map00920', 'map01212', 'map00195'],\n",
    "    'oxidative_phosphorylation': ['map00190'],\n",
    "    'two-component': ['map02020'],\n",
    "    'amino-acids':['map01230'],\n",
    "    #'thiamine-metabolism':'map00730',\n",
    "    #'riboflavin-metabolism':'map00740',\n",
    "    #'Vitamin-B6-metabolism':'map00750',\n",
    "    #'Nicotinate&Nicotinamide-metabolism':'map00760',\n",
    "    #'PantoThenate and CoA Biosynthesis':'map00770',\n",
    "    #'Biotin-Metabolism':'map00780',\n",
    "    #'Lipoic-Acid-Metabolism':'map00785',\n",
    "    #'Folate-Biosynthesis':'map00790',\n",
    "    #'OneCarbonPoolByFolate':'map00670',\n",
    "    #'retinol-metabolism-animals':'map00830',\n",
    "    #'porphyrin&ChlorophyllMetabolism':'map00860',\n",
    "    #'Ubiquinone&OtherTerpenoid-QuinoneBiosynthesis':'map00130',\n",
    "    'vitamins&cofactors':['map00730','map00740','map00750','map00760','map00770','map00780','map00785','map00790','map00670','map00830','map00860','map00130'],\n",
    "    #\"Alanine, aspartate and glutamate metabolism\":'map00250',\n",
    "    #\"Cysteine and methionine metabolism\":'map00270',\n",
    "    #\"Glycine, serine and threonine metabolism\":'map00260',\n",
    "    #\"Valine, leucine and isoleucine degradation\":'map00280',\n",
    "    #\"Valine, leucine and isoleucine biosynthesis\":'map00290',\n",
    "    #\"Lysine biosynthesis\":'map00300',\n",
    "    #\"Lysine degradation\":'map00310',\n",
    "    #\"Arginine biosynthesis\":'map00220',\n",
    "    #\"Arginine and proline metabolism\":'map00330',\n",
    "    #\"Histidine metabolism\":'map00340',\n",
    "    #\"Tyrosine metabolism\":'map00350',\n",
    "    #\"Phenylalanine metabolism\":'map00360',\n",
    "    #\"Tryptophan metabolism\":'map00380',\n",
    "    #\"Phenylalanine, tyrosine and tryptophan biosynthesis\":'map00400',\n",
    "    \"AminoAcidMetabolism\":['map00250','map00270','map00260','map00280','map00290','map00300','map00310','map00220',\\\n",
    "                           'map00330','map00340','map00350','map00360','map00380','map00400']\n",
    "    #\"beta-Alanine metabolism\":'map00410',\n",
    "    #\"Taurine and hypotaurine metabolism\":'map00430',\n",
    "    #\"Phosphonate and phosphinate metabolism\":'map00440',\n",
    "    #\"Selenocompound metabolism\":'map00450',\n",
    "    #\"Cyanoamino acid metabolism\":'map00460',\n",
    "    #\"D-Glutamine and D-glutamate metabolism\":'map00471',\n",
    "    #\"D-Arginine and D-ornithine metabolism\":'map00472',\n",
    "    #\"D-Alanine metabolism\":'map00473',\n",
    "    #\"Glutathione metabolism\":'map00480',\n",
    "   # \"Metabolisms of other amino acids\":['map00410','map00430','map00440','map00450','map00460','map00471','map00472','map00473','map00480']\n",
    "    ,\"Glycosaminoglycan degradation & Synthesis\":[\"map00531\",\"map00532\",\"map00534\"] ,\n",
    "    \"Bacterial Secretion Systems\":[\"ko03070\"],\n",
    "    \"phosphotransferase system (PTS)\":[\"ko02060\"],\n",
    "    \"ABC transporters\":[\"ko02010\"],\n",
    "    \"N-Glycan biosynthesis\": [\"map00510\"],\n",
    "    \"CationicAntiomicrobialPeptide_CAMP_resistance\":[\"map01503\"],\n",
    "    \"Vancomycin_Beta-lactamResistance\":[\"map01502\",\"map01501\"]\n",
    "\n",
    "}\n",
    "\n",
    "pathways ={key:[item.replace(\"ko\",\"map\") for item in items] for key,items in pathways.iteritems()}\n",
    "\n",
    "bin_names=load_bin_names(tax_file)\n",
    "\n",
    "def pathway_to_modules(pathway_dict,database_dir):\n",
    "    links=load_local_kegg_database_pairings(database_dir,[(\"pathway\",\"module\")], False)[\"pathway\",\"module\"]\n",
    "    pathways={path:list(set(itertools.chain(*[links[egx] for egx in pathway if egx in links]))) for path, pathway in pathway_dict.iteritems()}\n",
    "    return pathways\n",
    "\n",
    "MO_pathways=pathway_to_modules(pathways,database_dir)\n",
    "\n",
    "####################################\n",
    "# Abundance parsing\n",
    "####################################\n",
    "def load_relative_abundance(file_name):\n",
    "    abundance_data=pd.DataFrame.from_csv(file_name,sep=\"\\t\")\n",
    "    new_index=np.array(pd.Series(abundance_data.index.values).str.strip(\"_genomic\"))\n",
    "    abundance_data.set_index(new_index,inplace=True)\n",
    "    return abundance_data\n",
    "\n",
    "\n",
    "def rel_abundance_to_dict(df):\n",
    "    abundance_dict={}\n",
    "    column_names=df.columns.values\n",
    "    for genome, rel_abund in df.iterrows():\n",
    "        abundance_dict[genome]={}\n",
    "        for i,column_name in enumerate(column_names):\n",
    "            abundance_dict[genome][column_name]=round(rel_abund[i],9)\n",
    "    return abundance_dict\n",
    "\n",
    "def get_abundance(file_name):\n",
    "    return rel_abundance_to_dict(load_relative_abundance(file_name))\n",
    "\n",
    "def only_key_abundance(abundance_dict,unique_key):\n",
    "    reduced_dict={}\n",
    "    for genome, rel_abund_dict in abundance_dict.iteritems():\n",
    "        for sample, abundance in rel_abund_dict.iteritems():\n",
    "            if unique_key in sample:\n",
    "                reduced_dict[genome]=abundance\n",
    "    return reduced_dict\n",
    "\n",
    "def reduced_abundance(file_name,unique_key):\n",
    "    \n",
    "    return only_key_abundance(get_abundance(file_name),unique_key)\n",
    "    \n",
    "\n",
    "def load_coverages(file_name):\n",
    "    '''Loads in the coverage file with a separate coverage for each contig. '''\n",
    "    with open(file_name) as coverage_file:\n",
    "        header=coverage.readline()\n",
    "    header=tuple(header.strip().split(\"\\t\"))\n",
    "    coverage_file=np.genfromtxt(fule_name,delimiter=\"\\t\",names=True)\n",
    "    return\n",
    "\n",
    "def normalised_coverages(read_counts=True):\n",
    "    return\n",
    "\n",
    "def load_completeness_contamination(file_name):\n",
    "    genome_data=pd.DataFrame.from_csv(file_name,sep=\"\\t\")\n",
    "    genome_data_dict={}\n",
    "    data_names=[\"completeness\",\"contamination\"]\n",
    "    for genome, row in genome_data.iterrows():\n",
    "        genome_data_dict[genome]={}\n",
    "        for item_id,item in itertools.izip(data_names,row):\n",
    "            genome_data_dict[item_id]=item\n",
    "    return genome_data\n",
    "\n",
    "#def \n",
    "\n",
    "def estimate_binning_completeness(coverage_file,completeness_file, total_counts_file):\n",
    "    \n",
    "    return\n",
    "\n",
    "#################################\n",
    "# KEGG Completeness\n",
    "#################################\n",
    "\n",
    "def replacement(definition,return_string=False):\n",
    "    '''\n",
    "    Description:\n",
    "        Turns an irregular definition string into a set of KOs in nested tuples to indicate their relationship and to\n",
    "        prepare them for processing.\n",
    "    Input:\n",
    "        definition: string\n",
    "            Module definition as defined in KEGG    \n",
    "    output:\n",
    "        definition: Same as above\n",
    "        new_nesting: tuple of tuples of sets\n",
    "            The new logical form of the definition to use in evaluating completeness.\n",
    "        \n",
    "    Notes: \n",
    "        This function uses eval which a security risk. Caution should be taken in using this function\n",
    "    '''\n",
    "    \n",
    "    logical_chars=\"[+ ,-]\"\n",
    "    pattern=\"K[0-9]{5}\"\n",
    "    new_expression=definition\n",
    "    logical_groups=\"([K][0-9]+,){1,}[K][0-9]+\" #Find any group of KOs (1 or more) separated by commas\n",
    "    #non_extended_groups='(K[0-9]{5}[^,K0-9\\n\\]]*){1,}(K[0-9]{5}[^,])' #Get any none comma separated chunk of KOs\n",
    "    non_extended_groups='([^,]|^)(K[0-9]{5}[^,K0-9\\n\\]\\)\\[]*){1,}([\\n \\+\\\"\\]\\[\\(\\)]|$)'\n",
    "    end_KOs='(K[0-9]{5})$'\n",
    "    repeated_set='(set\\(\\[){2,}([\"][K][0-9]+[\"][^^ )(+.\\\"-]?).*?(\\]\\)){1,2}'\n",
    "    set_in_set='set\\(\\[[K0-9\",]*(set\\(\\[)\"[K][0-9]+\"\\]\\)'\n",
    "    rear_match=\"([^0-9][,-]K[0-9]{5})\"\n",
    "    forward_match='(K[0-9]{5})[,-][\\(]'\n",
    "    new_expression=new_expression.replace(\" -\",\"-\")\n",
    "    new_expression=new_expression.replace(\", \",\",\")\n",
    "    ko_set_matches=[]\n",
    "        \n",
    "    for match in re.finditer(logical_groups,new_expression):\n",
    "        #print match.group()\n",
    "        ko_set_matches.append(match.group())\n",
    "        #new_expression=new_expression.replace(match.group(),\"set([\"+match.group()+\"])\",1)\n",
    "    set_matches=['']*len(ko_set_matches)\n",
    "    cleaned_matches=[match.strip(\",\") for match in ko_set_matches]\n",
    "    ko_set_matches=set(cleaned_matches)\n",
    "    \n",
    "    \n",
    "    for i,match in enumerate(ko_set_matches):\n",
    "        set_matches[i]=match\n",
    "        new_expression=new_expression.replace(match,\"set([\"+match+\"])\")\n",
    "        \n",
    "    step_0_1=new_expression\n",
    "    for match in re.finditer(non_extended_groups,new_expression):\n",
    "        if match:\n",
    "            new_match=match.group()\n",
    "            #print type(new_match), new_match\n",
    "            for sub_match in re.findall(pattern,new_match):\n",
    "                new_match=new_match.replace(sub_match,\"set([\"+sub_match+\"])\")\n",
    "            new_expression=new_expression.replace(match.group(),new_match)\n",
    "            \n",
    "    for match in re.finditer(rear_match,new_expression):\n",
    "        if match:\n",
    "            new_match=match.group()\n",
    "            #print type(new_match), new_match\n",
    "            for sub_match in re.findall(pattern,new_match):\n",
    "                new_match=new_match.replace(sub_match,\"set([\"+sub_match+\"])\")\n",
    "            new_expression=new_expression.replace(match.group(),new_match)\n",
    "            \n",
    "    for match in re.finditer(forward_match,new_expression):\n",
    "        if match:\n",
    "            new_match=match.group()\n",
    "            #print type(new_match), new_match\n",
    "            for sub_match in re.findall(pattern,new_match):\n",
    "                new_match=new_match.replace(sub_match,\"set([\"+sub_match+\"])\")\n",
    "            #print new_match\n",
    "            new_expression=new_expression.replace(match.group(),new_match)\n",
    "                \n",
    "    step_0_2=new_expression\n",
    "    for match in set(re.findall(pattern,new_expression)):\n",
    "        new_expression=new_expression.replace(match,\"\\\"\"+match+\"\\\"\")\n",
    "    step_1=new_expression\n",
    "    #print new_expression\n",
    "    \n",
    "    new_expression=new_expression.replace(\",\",\",\\\",\\\",\")\n",
    "    #non_set_comma='.{6}[^\\\"],[^\\\"].{6}' #Extends sides to try and ensure uniqueness\n",
    "    #for match in set(re.findall(non_set_comma,new_expression)):\n",
    "    #    new_expression=new_expression.replace(match,\",\\\",\\\",\".join(match.split(\",\")))\n",
    "        \n",
    "    new_expression=new_expression.replace(\" \",\",\\\" \\\",\")\n",
    "    #print new_expression\n",
    "    new_expression=new_expression.replace(\"-\",\",\\\"-\\\",\")\n",
    "    new_expression=new_expression.replace(\"+\",\",\\\"+\\\",\")\n",
    "    step_2=new_expression\n",
    "    #print new_expression\n",
    "    new_expression=new_expression.replace(\"\\\"\\\"\",\"\\\"\")\n",
    "    new_expression=new_expression.replace(\",,\",\",\")\n",
    "    new_expression=new_expression.replace(\",]\",\"]\")\n",
    "    new_expression=new_expression.replace(\",)\",\")\")\n",
    "    new_expression=new_expression.replace(\"\\\"\\\"\",\"\\\"\")\n",
    "    step_3=new_expression\n",
    "    #No Longer needed due to fix in tests.\n",
    "\n",
    "    for match in re.finditer(repeated_set,new_expression):\n",
    "        #print \"This is the match\", match.group()\n",
    "        new_match=match.group().strip(\"set([\")\n",
    "        new_match=new_match.strip(\"])\")\n",
    "        new_match=\"set([\"+new_match+\"])\"\n",
    "        #print\n",
    "        #print \"This is the new match\", new_match\n",
    "        new_expression=new_expression.replace(match.group(),new_match)\n",
    "    \n",
    "    for match in re.finditer(set_in_set,new_expression):\n",
    "        new_match=match.group()\n",
    "        #print new_match.split(\"set([\")\n",
    "        blank, section_1,section_2=new_match.split(\"set([\")\n",
    "        section_2=section_2.strip(\"])\")\n",
    "        #print section_2\n",
    "        new_match=\"set([\"+section_1+section_2\n",
    "        new_expression=new_expression.replace(match.group(),new_match)\n",
    "    step_4=new_expression\n",
    "    isolated_start=\"^\\\"K[0-9]{5}\\\"\"\n",
    "    for match in re.findall(isolated_start,new_expression):\n",
    "        new_expression=new_expression.replace(match,\"(\"+match+\",)\")\n",
    "        \n",
    "    new_expression=\"(\"+new_expression+\")\"\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    if return_string:\n",
    "        return new_expression\n",
    "    try:\n",
    "        new_nesting=eval(new_expression)\n",
    "        return definition,new_nesting \n",
    "    \n",
    "\n",
    "        \n",
    "    except TypeError:\n",
    "        print definition\n",
    "        print \"0_1\",step_0_1\n",
    "        print \"0_2\",step_0_2\n",
    "        print \"Step 1:\", step_1\n",
    "        print \"Step 2:\", step_2\n",
    "        print \"Step 3:\", step_3\n",
    "        print \"Step 4:\", step_4\n",
    "        print \";\".join(set_matches)\n",
    "        print \"Type error\", new_expression\n",
    "        raise\n",
    "        \n",
    "    except SyntaxError:\n",
    "        print definition\n",
    "        print \"0_1\",step_0_1\n",
    "        print \"0_2\",step_0_2\n",
    "        print \"Step 1:\", step_1\n",
    "        print \"Step 2:\", step_2\n",
    "        print \"Step 3:\", step_3\n",
    "        print \"Step 4:\", step_4\n",
    "        print \";\".join(set_matches)\n",
    "        print \"Syntax error\", new_expression\n",
    "        raise\n",
    "        \n",
    "    except NameError:\n",
    "        print definition\n",
    "        print \"0_1\",step_0_1\n",
    "        print \"0_2\",step_0_2\n",
    "        print \"Step 1:\", step_1\n",
    "        print \"Step 2:\", step_2\n",
    "        print \"Step 3:\", step_3\n",
    "        print \"Step 4:\", step_4\n",
    "        print \";\".join(set_matches)\n",
    "        print \"NameError\", new_expression\n",
    "        raise\n",
    "        \n",
    "    return\n",
    "        \n",
    "     \n",
    "\n",
    "def alt_eval_kegg_bool(kegg_expr,ko_set):\n",
    "    '''\n",
    "    Description:\n",
    "        Evaluates a list of boolean expressions blocks to get a list of T, F results summarising the module completeness.\n",
    "    Input: \n",
    "        kegg_expr: List of sets\n",
    "            A kegg expression consting of KOs in nested tuples. eg, (KO1 ((KO2,KO3-KO4),KO5).\n",
    "            The separators represent the kegg boolean separators.\n",
    "\n",
    "        ko_set: set\n",
    "            The set of KOs to be evaluated for compelteness in this particular kegg expression.\n",
    "    Calls:\n",
    "        eval_kegg_bool: function\n",
    "            The workhorse of  this function - recursively evaluates each element in kegg_expr to\n",
    "            decide if it is actually true or false.\n",
    "    '''\n",
    "    n_elements=len(kegg_expr)\n",
    "    results_vec=[\"na\"]*n_elements\n",
    "    for i in xrange(0,n_elements,2):\n",
    "        current_element=kegg_expr[i]\n",
    "        if isinstance(current_element,tuple):\n",
    "            side_1_result=eval_kegg_bool(current_element,ko_set)\n",
    "        else:\n",
    "            side_1_result= len(ko_set & current_element)>0\n",
    "\n",
    "        full_result=side_1_result\n",
    "        #print full_result\n",
    "        results_vec[i]=full_result\n",
    "    #print results_vec\n",
    "    for i,element in enumerate(results_vec):\n",
    "        if not isinstance(element,bool):\n",
    "            results_vec[i]=kegg_expr[i]\n",
    "    \n",
    "    return (n_elements+1)/2,results_vec\n",
    "    \n",
    "    \n",
    "def eval_kegg_bool(kegg_expr,ko_set):\n",
    "    '''\n",
    "    Description:\n",
    "        A recursive implementation of the kegg boolean logic for evaluating based on a set of KOs if a module is complete.\n",
    "        If given a tuple it will recursively search down for more tuples and evaluate them at the lowest level to move up and\n",
    "        finally finish evaluating the complete block. \n",
    "    Input: \n",
    "        kegg_expr: List of sets\n",
    "            A kegg expression consting of KOs in nested tuples. eg, (KO1 ((KO2,KO3-KO4),KO5).\n",
    "            The separators represent the kegg boolean separators.\n",
    "        ko_set: set\n",
    "            The set of KOs to be evaluated for compelteness in this particular kegg expression.\n",
    "    Calls:\n",
    "        eval_kegg_bool: function\n",
    "            Evalutes logical KEGG blocks.\n",
    "    '''\n",
    "    n_elements=len(kegg_expr)\n",
    "    #vector=np.array([\"na\"]*((n_element+1)/2)-1)\n",
    "    for i in xrange(0,n_elements-1,2):\n",
    "        #print \"THe current kegg expression getting evaluated\", kegg_expr[i:i+3]\n",
    "        side_1,log_op,side_2=kegg_expr[i:i+3]\n",
    "        #print \"This is the logical operater being used\",log_op\n",
    "        if log_op==\" \" or log_op==\"+\":\n",
    "            #print \"Entering +  recursion\"\n",
    "            if isinstance(side_1,tuple):\n",
    "                side_1_result=eval_kegg_bool(side_1,ko_set)\n",
    "            else:\n",
    "                side_1_result= len(ko_set & side_1)>0\n",
    "            if isinstance(side_2,tuple):\n",
    "                side_2_result=eval_kegg_bool(side_2,ko_set)\n",
    "            else:\n",
    "                side_2_result=len(ko_set & side_2)>0\n",
    "            full_result=side_1_result and side_2_result\n",
    "            \n",
    "        elif \",\" in log_op:\n",
    "            #print \"Entering , recursion\"\n",
    "            if isinstance(side_1,tuple):\n",
    "                side_1_result=eval_kegg_bool(side_1,ko_set)\n",
    "            else:\n",
    "                side_1_result= len(ko_set & side_1)>0\n",
    "            if isinstance(side_2,tuple):\n",
    "                side_2_result=eval_kegg_bool(side_2,ko_set)\n",
    "            else:\n",
    "                side_2_result=len(ko_set & side_2)>0     \n",
    "            full_result=side_1_result or side_2_result\n",
    "        elif \"-\" in log_op:\n",
    "            #print \"Entering - recursion\"\n",
    "            if isinstance(side_1,tuple):\n",
    "                side_1_result=eval_kegg_bool(side_1,ko_set)\n",
    "            else:\n",
    "                side_1_result= len(ko_set & side_1)>0\n",
    "            if isinstance(side_2,tuple):\n",
    "                side_2_result=eval_kegg_bool(side_2,ko_set)\n",
    "            else:\n",
    "                side_2_result=len(ko_set & side_2)>0\n",
    "            full_result=side_1_result\n",
    "            \n",
    "        else:\n",
    "            print log_op, \"There seems to have been an error:\"\n",
    "        #print \"The result for side 1\", side_1_result, side_1\n",
    "        #print \"The result for side 2\", side_2_result, side_2\n",
    "    #print \"The final results being returned\", full_result\n",
    "    return full_result\n",
    "\n",
    "def block_level_completeness(results_vector,correct_partial,nested_descr,ko_set):\n",
    "    '''\n",
    "    Description:\n",
    "        Calculates the percent completness of a KEGG module in one of two ways. It either looks at the number of\n",
    "        logical blocks complete (block level completeness) or also adds a percentage adjustment for how complete the\n",
    "        incomplete blocks are.\n",
    "    Input:\n",
    "        results_vector: List of Booleans\n",
    "            A list containing the results of evaluating a kegg module KO hits as a boolean expression.\n",
    "        correct_partial: Boolean\n",
    "            Indicating whether to try and account for the partial completeness of some logical blocks.\n",
    "        nested_descr: nested tuple of sets\n",
    "            A logical grouping of KEGG blocks into tuples with sets of KOs as the lowermost elements.\n",
    "    Output:\n",
    "        completeness_perc:  float in [0,1]\n",
    "            Percent module completeness according to one of two methods.'''\n",
    "    if isinstance(nested_descr,set):\n",
    "        return len(nested_desc & ko_set) > 0\n",
    "    \n",
    "    keep_indices=True\n",
    "    log_blocks=make_logical_blocks(results_vector,keep_indices)\n",
    "    position_mapping=make_position_mapping(log_blocks)\n",
    "    if keep_indices:\n",
    "        log_blocks=extract_logical_values(log_blocks)\n",
    "    else:\n",
    "        pass\n",
    "    n_tot=len(log_blocks)\n",
    "    filled_blocks=[any(block) for block in log_blocks]\n",
    "    n_filled_blocks=sum(filled_blocks)\n",
    "    adjustment=[\"na\"]*len(log_blocks)\n",
    "    \n",
    "    if not correct_partial:\n",
    "        completeness_perc=float(n_filled_blocks)/n_tot\n",
    "        return completeness_perc\n",
    "    else:\n",
    "        for i,block in enumerate(log_blocks):\n",
    "            if not any(block):\n",
    "                n_max_hits=len(block)\n",
    "                running_total=0\n",
    "                for j,item in enumerate(block):\n",
    "                    if item:\n",
    "                        running_total+=1\n",
    "                    else:\n",
    "                        bool_index=position_mapping[i][j]\n",
    "                        #print \"The boolean index:\", bool_index\n",
    "                        #print position_mapping\n",
    "                        kegg_bool=nested_descr[bool_index]\n",
    "                        #print kegg_bool\n",
    "                        running_total+=module_completeness_proportion(kegg_bool,ko_set,correct_partial)\n",
    "                adjustment[i]=float(running_total)/n_max_hits\n",
    "            else:\n",
    "                adjustment[i]=1    \n",
    "        n_filled_blocks=sum(adjustment)\n",
    "        completeness_perc=float(n_filled_blocks)/n_tot\n",
    "        return completeness_perc\n",
    "    \n",
    "def extract_logical_values(logical_blocks):\n",
    "    return [[item[1] for item in block] for block in logical_blocks]\n",
    "\n",
    "def make_position_mapping(log_blocks):\n",
    "    mapping={}\n",
    "    for i, block in enumerate(log_blocks):\n",
    "        mapping[i]={j:item[0] for j,item in enumerate(block)}\n",
    "    #print mapping\n",
    "    return mapping\n",
    "\n",
    "def module_completeness_proportion(kegg_bool,ko_set,correct_partial):\n",
    "    '''Returns the completeness of the current kegg_boolean.\n",
    "    Input:\n",
    "        \n",
    "    Output:\n",
    "        \n",
    "    Calls:\n",
    "        block_level_completeness: Calculate the % of kegg blocks which are complete.'''\n",
    "    if isinstance(kegg_bool,set):\n",
    "        return len(kegg_bool & ko_set) > 0\n",
    "    #print \"Kegg bool:\",kegg_bool\n",
    "    #print \"ko_set:\",ko_set\n",
    "    n_el,results_vector=alt_eval_kegg_bool(kegg_bool,ko_set)\n",
    "    #print \"This is the result vector:\",results_vector\n",
    "    completeness_perc=block_level_completeness(results_vector,correct_partial,kegg_bool,ko_set)\n",
    "    \n",
    "    return completeness_perc\n",
    "    \n",
    "\n",
    "def make_logical_blocks(results_vector,keep_indices):\n",
    "    '''\n",
    "    Description:\n",
    "        Turn the uppermost level of results from a KEGG boolean into a series of logical blocks. I.e if I had \n",
    "        a vector [T and F and T or F or T] then the blocks formed will be [[T],[F],[T,F,T]]. \n",
    "    Input:\n",
    "        results_vector: List of Bools\n",
    "            A list containing the results of evaluating a kegg module KO hits as a boolean expression.\n",
    "    Output:\n",
    "        log_block: list of lists of bools\n",
    "            A list composed of the logical blocks needed to decide if a boolean is \"complete\".'''\n",
    "    \n",
    "    operator_set=set([\" \",\"-\",\",\",\"+\"])\n",
    "    log_blocks=[]\n",
    "    current_block=[]\n",
    "    previous_logical=\"\"\n",
    "    log_operators=[\" \",\",\",\"+\",\"-\"]\n",
    "    for i,item in enumerate(results_vector):\n",
    "        if item not in log_operators:\n",
    "            if not current_block:\n",
    "                if keep_indices:\n",
    "                    current_block.append((i,item))\n",
    "                else:\n",
    "                    current_block.append(item)\n",
    "#            elif i==(len(results_vector)-1):\n",
    "#                log_blocks.append(current_block)\n",
    "            else:\n",
    "                if previous_logical==\" \" or previous_logical==\"+\":\n",
    "                    log_blocks.append(current_block)\n",
    "                    if keep_indices:\n",
    "                        current_block=[(i,item)]\n",
    "                    else:\n",
    "                        current_block=[item]\n",
    "                elif previous_logical==\",\":\n",
    "                    #print item\n",
    "                    if keep_indices:\n",
    "                        current_block.append((i,item))\n",
    "                    else:\n",
    "                        current_block.append(item)\n",
    "                    #print current_block\n",
    "                elif previous_logical==\"-\":\n",
    "                    pass\n",
    "        else:\n",
    "            previous_logical=item\n",
    "    log_blocks.append(current_block)\n",
    "            \n",
    "    return log_blocks\n",
    "\n",
    "def test_all_local_modules(database_dir):\n",
    "    #758 comparisons are to be made.\n",
    "    completeness_dict={}\n",
    "    #Load all possible KOs\n",
    "    MO_KO_pairs=load_local_kegg_database_pairings(database_dir,[(\"Module\",\"orthology\")], False)[(\"Module\",\"orthology\")]\n",
    "    MO_KO_pairs={MO:set(KOs) for MO, KOs in MO_KO_pairs.iteritems()}\n",
    "    #Use this as the comparison set.\n",
    "    log_kegg_exprs=load_local_cleaned_definition_db(database_dir)\n",
    "    #Screen every single module for compelteness (should all be 1.0)\n",
    "    for module,expression in log_kegg_exprs.iteritems():\n",
    "        completeness_dict[module]=module_completeness_proportion(expression,MO_KO_pairs[module],True)\n",
    "        \n",
    "    \n",
    "    failures={Module:completeness for Module,completeness in completeness_dict.iteritems() if completeness<1}\n",
    "    print failures\n",
    "    \n",
    "    return completeness_dict\n",
    "\n",
    "genome_taxonomy=load_bin_names(tax_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kegg Item Enrichment analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bonferroni_correction(p,n):\n",
    "    '''Returns a new Bonferroni corrected p-value threshold for significance.'''\n",
    "    return p/n\n",
    "\n",
    "def flat_bonf_correction(ps,n,p):\n",
    "    '''Applies a simple bonferonni correccted signifiance threshold to all of the observed data\n",
    "    to determine signifances.'''\n",
    "    p_val=p/n\n",
    "    sig_values={(genome_1,genome_2):{PTH:(p_value,exp_val,obs_val) for PTH, (p_value,exp_val,obs_val,completeness) in pathway_scores.iteritems() if p_value <=p_val} for (genome_1,genome_2),pathway_scores in ps.iteritems()}\n",
    "    return sig_values\n",
    "\n",
    "def flat_sidak_correction(ps,n,p):\n",
    "    '''Applies a simple sidak corrected significance threshold to all of the observed data\n",
    "    to determine significance.'''\n",
    "    p_val=1-(1-p)**(float(1)/n)\n",
    "    sig_values={(genome_1,genome_2):{PTH:(p_value,exp_val,obs_val,completeness) for PTH, (p_value,exp_val,obs_val,completeness) in pathway_scores.iteritems() if p_value <=p_val} for (genome_1,genome_2),pathway_scores in ps.iteritems()}\n",
    "    return sig_values\n",
    "\n",
    "def Holm_bonferonni_correction(ps,n,p):\n",
    "    '''Apply a Holm_bonferonni_corrections to a list of p-values with specific\n",
    "    familywise error rate and total sample size. This an application of Holm's\n",
    "    method for familywise error rate control Holm et al. ().'''\n",
    "    list_data=ps.items()\n",
    "    expanded_list_data=[(genome_1,genome_2,PTH,p_value,exp_val,obs_val,completeness) for (genome_1,genome_2),path_dict in ps.iteritems() for PTH, (p_value,exp_val,obs_val,completeness) in path_dict.iteritems()]\n",
    "    p_values=sorted(expanded_list_data,key=lambda x: x[3])\n",
    "    N=n\n",
    "    significant_values=[]\n",
    "    for (genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness) in p_values:\n",
    "        if p_value<=p/N:\n",
    "            significant_values.append((genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness))\n",
    "            N=N-1\n",
    "        else:\n",
    "            break\n",
    "    sig_vals=defaultdict(dict)\n",
    "    #print significant_values\n",
    "    for (genome_1,genome_2, pathway,p_value,exp_val,obs_val,completeness) in significant_values:\n",
    "        sig_vals[(genome_1,genome_2)][pathway]=(p_value,exp_val,obs_val,completeness)\n",
    "    return sig_vals\n",
    "\n",
    "def Holm_sidak_correction(ps,n,p):\n",
    "    '''Apply a Holm_sidak_corrections to a list of p-values with specific\n",
    "    familywise error rate and total sample size. This an application of Holm's\n",
    "    method for familywise error rate control Holm et al. ().'''\n",
    "    list_data=ps.items()\n",
    "    expanded_list_data=[(genome_1,genome_2,PTH,p_value,exp_val,obs_val,completeness) for (genome_1,genome_2),path_dict in ps.iteritems() for PTH, (p_value,exp_val,obs_val,completeness) in path_dict.iteritems()]\n",
    "    p_values=sorted(expanded_list_data,key=lambda x: x[3])\n",
    "    N=n\n",
    "    significant_values=[]\n",
    "    for (genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness) in p_values:\n",
    "        if p_value<=1-(1-p)**(float(1)/N):\n",
    "            significant_values.append((genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness))\n",
    "            N=N-1\n",
    "        else:\n",
    "            break\n",
    "    sig_vals=defaultdict(dict)\n",
    "    for (genome_1,genome_2, pathway,p_value,exp_val,obs_val,completeness) in significant_values:\n",
    "        sig_vals[(genome_1,genome_2)][pathway]=(p_value,exp_val,obs_val,completeness)\n",
    "    return sig_vals        \n",
    "def sidak_correction(p,n):\n",
    "    '''Sidak correction as described by Sidak et al. ----'''\n",
    "    return 1-(1-p)**(float(1)/n)\n",
    "\n",
    "def False_Discovery_Rate_correction(ps,n,p):\n",
    "    '''Control the false discovery rate for a list of p-values with specific\n",
    "    familywise error rate and total sample size as described by _____ et al. (19__)'''\n",
    "    list_data=ps.items()\n",
    "    expanded_list_data=[(genome_1,genome_2,PTH,p_value,exp_val,obs_val,completeness) for (genome_1,genome_2),path_dict in ps.iteritems() for PTH, (p_value,exp_val,obs_val,completeness) in path_dict.iteritems()]\n",
    "    p_values=sorted(expanded_list_data,key=lambda x: x[3])\n",
    "    i=1\n",
    "    N=n\n",
    "    significant_values=[]\n",
    "    for (genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness) in p_values:\n",
    "        if p_value<=float(i)*p/N:\n",
    "            significant_values.append((genome_1,genome_2,pathway,p_value,exp_val,obs_val,completeness))\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    sig_vals=defaultdict(dict)\n",
    "    for (genome_1,genome_2, pathway,p_value,exp_val,obs_val,completeness) in significant_values:\n",
    "        sig_vals[(genome_1,genome_2)][pathway]=(p_value,exp_val,obs_val,completeness)\n",
    "    return sig_vals\n",
    "\n",
    "def multiple_test_correction(genome_data,p,n,correction_type=\"bonferonni\"):\n",
    "    '''Perform multiple test correction to determine the significantly enriched modules.'''\n",
    "    unrepped_mods={(genome_1,genome_2):{PTH:results for PTH, results in pathway_data.iteritems() if results[1]==0} for (genome_1,genome_2),pathway_data in genome_data.iteritems()}\n",
    "    repped_mods={(genome_1,genome_2):{PTH:results for PTH, results in pathway_data.iteritems() if results[1]!=0} for (genome_1,genome_2),pathway_data in genome_data.iteritems()}\n",
    "    sig_values=defaultdict(dict)\n",
    "    if correction_type==\"bonferonni\":\n",
    "        sig_values=flat_bonf_correction(repped_mods,n,p)\n",
    "    elif correction_type==\"Holm-bonferonni\":\n",
    "        sig_values=Holm_bonferonni_correction(repped_mods,n,p)\n",
    "    elif correction_type==\"Holm-Sidak\":\n",
    "        sig_values=Holm_sidak_correction(repped_mods,n,p)\n",
    "    elif correction_type==\"Sidak\":\n",
    "        sig_values=flat_sidak_correction(repped_mods,n,p)\n",
    "    elif correction_type==\"FDR\" or correction_type==\"False_Discovery_Rate\":\n",
    "        sig_values=False_Discovery_Rate_correction(repped_mods,n,p)\n",
    "    else:\n",
    "        print \"None of the multiple test corrections were chosen. Please choose \\\n",
    "        one of bonferonni, Holm-bonferonni, Holm-Sidak, Sidak, FDR or False Discovery Rate\"\n",
    "        \n",
    "    for (genome_1,genome_2), pathway_data in unrepped_mods.iteritems():\n",
    "        for PTH,results in pathway_data.iteritems():\n",
    "            sig_values[(genome_1,genome_2)][PTH]=results\n",
    "        \n",
    "    return sig_values\n",
    "\n",
    "def measure_completeness(PTH,target_KOs,KO_PTH_structure):\n",
    "    '''Ensures that completenss is only calculated for modules.'''\n",
    "    if not PTH.startswith(\"M\"):\n",
    "        return 0\n",
    "    else:\n",
    "        if KO_PTH_structure==():#empty tuple\n",
    "            return 0\n",
    "        else:\n",
    "            perc_completeness=module_completeness_proportion(KO_PTH_structure,target_KOs,True)\n",
    "            return perc_completeness\n",
    "\n",
    "def new_measure_completeness(PTH,target_KOs,KO_PTH_structure,is_module):\n",
    "    if is_module:\n",
    "        if KO_PTH_structure==():#empty tuple\n",
    "            return 0\n",
    "        else:\n",
    "            perc_completeness=module_completeness_proportion(KO_PTH_structure,target_KOs,True)\n",
    "            return perc_completeness\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "    \n",
    "        \n",
    "def import_KO_hits(file_name):  \n",
    "    #Needs to detect counts file and rewrite it.\n",
    "    KO_hits={}\n",
    "    with open(file_name) as KO_hits_file:\n",
    "        header_line=next(KO_hits_file)\n",
    "        if len(header_line.split(\"\\t\"))>2:\n",
    "            dataframe=True\n",
    "        else:\n",
    "            dataframe=False\n",
    "    if not dataframe:\n",
    "        with open(file_name) as KO_hits_file:\n",
    "            for line in KO_hits_file:\n",
    "                genome,KOs=line.strip().split(\"\\t\")\n",
    "                KOs=KOs.split(\";\")\n",
    "                #print genome,KOs\n",
    "                KO_hits[genome]=KOs\n",
    "        #print \"THE KO HITS\", KO_hits\n",
    "        KO_hits_dup=KO_hits\n",
    "        for genome, KOs in KO_hits.iteritems():\n",
    "            KO_hits[genome]=Counter(KOs)\n",
    "        KO_hits=pd.DataFrame.from_dict(KO_hits,orient='columns')\n",
    "        KO_hits=KO_hits.fillna(0)\n",
    "        #print \"THe Ko hits\", KO_hits\n",
    "        return KO_hits\n",
    "    elif dataframe:\n",
    "        KO_hits=convert_kegg_hits_to_occurrences(file_name)\n",
    "        #print \"THE KO HITS\", KO_hits\n",
    "        return KO_hits\n",
    "    else:\n",
    "        print \"Error\"\n",
    "        return\n",
    "    \n",
    "def convert_kegg_hits_to_occurrences(file_name):\n",
    "    counts_df=pd.read_csv(file_name,sep=\"\\t\",index_col=[0])\n",
    "    #KO_dict={}\n",
    "    #for genome in counts_df.columns:\n",
    "    #    KO_dict[genome]=[]#*n_kos\n",
    "\n",
    "    #for index,row in counts_df.iterrows():\n",
    "    #    for genome, count in row.iteritems():\n",
    "    #        #print index, count\n",
    "    #        KO_dict[genome].extend((index,)*count)\n",
    "    #\n",
    "    counts_df=counts_df.fillna(0)\n",
    "    return counts_df\n",
    "\n",
    "def load_groupings(file_name,all_members):\n",
    "    '''Loads in a tab separated files of the form: group_name\\tgenome_1|genome_2|genome_3|genome_4|etc\n",
    "    Input:\n",
    "        file_name: str\n",
    "            Name of groupings file\n",
    "    Output:\n",
    "        groupings: dict\n",
    "            Dictionary of group name and the list of component genomes'''\n",
    "    groupings={}\n",
    "    if not isinstance(file_name,type(None)):\n",
    "        if not os.path.isfile(file_name):\n",
    "            raise IOError('The specified groupings file does not exist.')\n",
    "\n",
    "        with open(file_name) as groupings_file:\n",
    "\n",
    "            next(groupings_file) #skip header\n",
    "\n",
    "            for line in groupings_file:\n",
    "                group_name,members=line.strip().split(\"\\t\")\n",
    "                list_of_members=members.split(\"|\")\n",
    "\n",
    "                groupings[group_name]=list_of_members\n",
    "    else:\n",
    "        groupings[\"all_genomes_grouped\"]=list(all_members)\n",
    "    #print 'The groupings', groupings   \n",
    "    return groupings\n",
    "\n",
    "def load_comparisons(file_name):\n",
    "    '''Loads in a tab separated files of the form: source_group\\ttarget_1|target_2|target_3|etc\n",
    "    \n",
    "    Input:\n",
    "        file_name: str\n",
    "            Name of comparisons file\n",
    "    Output:\n",
    "        comparisons: dict\n",
    "            Dictionary of baseline gorup name and the list of target group/genome_names to look\n",
    "            for enrichment in'''\n",
    "    comparisons={}\n",
    "    if not os.path.isfile(file_name):\n",
    "        raise IOError('The specified comparisons file does not exist.')\n",
    "    with open(file_name) as comparisons_file:\n",
    "        \n",
    "        next(comparisons_file) #skip header\n",
    "        \n",
    "        for line in comparisons_file:\n",
    "            source,targets=line.strip().split(\"\\t\")\n",
    "            list_of_targets=targets.split(\"|\")\n",
    "            comparisons[source]=list_of_targets\n",
    "    #print 'The comparisons', comparisons\n",
    "    return comparisons\n",
    "\n",
    "def make_comparisons_dict(KO_hits):\n",
    "    '''Makes a default comparison of each individual against the grouping of all.\n",
    "    Input: \n",
    "        KO_hits: dict\n",
    "            dictionary of all KO_hits for each genome\n",
    "    returns:\n",
    "        comparison_dict: dict\n",
    "            Dictionary with one key (all_genomes_grouped:list of genomes)'''\n",
    "    return {\"all_genomes_grouped\":KO_hits.keys()}\n",
    "\n",
    "def make_groupings_dict(KO_hits,groups, all_grouped=False):\n",
    "    '''Make a list of KOs for each group based on the KOs of group members.\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    '''\n",
    "    group_KOs={}\n",
    "    if all_grouped:\n",
    "        KO_hits[\"all_genomes_grouped\"]=KO_hits.sum(axis=1)\n",
    "        #group_KOs[\"all_genomes_grouped\"]=list(itertools.chain(*KO_hits.itervalues()))\n",
    "        print \"KO_HITS\",KO_hits\n",
    "        return KO_hits\n",
    "    else:\n",
    "        for group, members in groups.iteritems():\n",
    "            KO_hits[group]=KO_hits.loc[:,members].sum(axis=1)\n",
    "            #group_KOs[group]=list(itertools.chain(*[KO_hits[member] for member in members]))\n",
    "        #print \"KO_HITS\",KO_hits\n",
    "        return KO_hits          \n",
    "    \n",
    "\n",
    "def do_enrichment_comparisons(KO_hits, threshold, database_dir, comparisons,extras_dict,excluded_set,definition_file,overlap_dict,make_mo_comp):\n",
    "    '''Makes all of the enrichment comparisons specified in comparisons.\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    '''\n",
    "    #print \"Inside do_enrichment_comparison this is the extras_dict\", extras_dict\n",
    "    results_dict={}\n",
    "    N_comparisons={}\n",
    "    \n",
    "    if make_mo_comp:\n",
    "        #Load pairings\n",
    "        KO_KG_ITEM_PAIRS=kegg_pairs_wrapper([\"orthology\",\"Module\"],excluded_set, extras_dict,database_dir)\n",
    "        #KO_KG_ITEM_PAIRS=load_local_kegg_database_pairings(database_dir,[(\"orthology\",kegg_item)], False)[(\"orthology\",kegg_item)]\n",
    "        KO_KG_ITEM_PAIRS=defaultdict(set, KO_KG_ITEM_PAIRS)\n",
    "        #KG_ITEM_KO_PAIRS=load_local_kegg_database_pairings(database_dir,[(kegg_item,\"orthology\")], False)[(kegg_item,\"orthology\")]\n",
    "        KG_ITEM_KO_PAIRS=kegg_pairs_wrapper([\"Module\",\"orthology\"],excluded_set, extras_dict,database_dir)    \n",
    "        KG_ITEM_KO_PAIRS={MO:list(set(KOs)) for MO,KOs in KG_ITEM_KO_PAIRS.iteritems()}\n",
    "        #Must be MODULES\n",
    "        KO_PTH_structure=logical_loading_wrapper(database_dir, definition_file, extras_dict)\n",
    "        #KO_PTH_structure=load_local_cleaned_definition_db(database_dir)\n",
    "        KO_PTH_structure=defaultdict(tuple,KO_PTH_structure)\n",
    "\n",
    "        total_KO_hits=KO_hits.sum(axis=0)\n",
    "        #print total_KO_hits\n",
    "        new_MO_hits_matrix=construct_MO_matrix(KO_hits, KG_ITEM_KO_PAIRS)\n",
    "        #print \"NEw extreme values\", new_MO_hits.ix[(new_MO_hits>total_KO_hits).any(axis=1),:]\n",
    "        #print \"weird value\", new_MO_hits_matrix.loc['Msuper_duper',:]\n",
    "    else:\n",
    "        KO_KG_ITEM_PAIRS=None\n",
    "        KG_ITEM_KO_PAIRS=None  \n",
    "        KO_PTH_structure=None\n",
    "        total_KO_hits=KO_hits.sum(axis=0)\n",
    "        #print total_KO_hits\n",
    "        new_MO_hits_matrix=KO_hits\n",
    "        #print \"NEw extreme values\", new_MO_hits.ix[(new_MO_hits>total_KO_hits).any(axis=1),:]\n",
    "        #print \"weird value\", new_MO_hits_matrix.loc['Msuper_duper',:]\n",
    "\n",
    "    for source, targets in comparisons.iteritems():\n",
    "        for target in targets:\n",
    "            result,n_comparisons=adjusted_enrichment_test(target,source,threshold, new_MO_hits_matrix,database_dir,KO_KG_ITEM_PAIRS,KG_ITEM_KO_PAIRS,KO_PTH_structure,total_KO_hits,KO_hits,overlap_dict)\n",
    "            if len(result)>0:\n",
    "                results_dict[(target,source)]=result\n",
    "                N_comparisons[(target,source)]=n_comparisons\n",
    "    \n",
    "    #Turn results_dict into a dataframe\n",
    "    #results_dict={(target,source,pathway) for (target,source),results in}\n",
    "    return results_dict,N_comparisons\n",
    "\n",
    "def construct_MO_matrix(KO_hits, KG_ITEM_KO_PAIRS):\n",
    "    new_module_counts={}\n",
    "    for Module, KOs in KG_ITEM_KO_PAIRS.iteritems():\n",
    "        #print KOs\n",
    "        hits_per_module=KO_hits.ix[KOs,:].sum(axis=0)\n",
    "        #print hits_per_module\n",
    "        #print \"Module\", Module, hits_per_module['coral']\n",
    "        new_module_counts[Module]=hits_per_module\n",
    "    #print \"weird_coral_stuff\",sum(KO_hits['coral']), KO_hits['coral']\n",
    "    new_module_df=pd.DataFrame.from_dict(new_module_counts,orient='index')\n",
    "    #print new_module_df\n",
    "    return new_module_df\n",
    "\n",
    "\n",
    "def load_bin_taxa(bin_file):\n",
    "    bin_names={}\n",
    "    \n",
    "    with open(bin_file) as taxonomy:\n",
    "        next(taxonomy) #skip header\n",
    "        for line in taxonomy:\n",
    "            \n",
    "            taxa,ID=line.strip().split(\"\\t\")\n",
    "            bin_names[ID]=taxa\n",
    "            \n",
    "    bin_taxa=defaultdict(lambda:\"No_Associated_Taxonomy\" ,bin_names)\n",
    "    \n",
    "    return bin_taxa\n",
    "\n",
    "def load_excluded_items(excluded_file):\n",
    "    excluded_items=[]\n",
    "    with open(excluded_file) as ignored:\n",
    "        for line in ignored:\n",
    "            excluded_items.append(line.strip())\n",
    "    return set(excluded_items)\n",
    "\n",
    "def load_extra_items(extras_file):\n",
    "    extra_items={}\n",
    "    with open(extras_file) as extras:\n",
    "        for line in extras:\n",
    "            ID, KOs=line.strip().split(\"\\t\")\n",
    "            extra_items[ID]=KOs.split(\";\")\n",
    "    return extra_items\n",
    "\n",
    "def make_extras_logical(extra_def_file,extras_dict,database_dir):\n",
    "    definition_dict={}\n",
    "    if extra_def_file==None:\n",
    "        rename_logical=os.path.join(database_dir,\"module_extra_kegg_log_expr.tsv\")\n",
    "        for key,KOs in extras_dict.iteritems():\n",
    "            n_KOs=len(KOs)\n",
    "            new_def=[' ']*(2*n_KOs-1)\n",
    "            for i,KO in enumerate(KOs):\n",
    "                new_def[2*i]=set([KO])\n",
    "                #if i==(n_KOs-1):\n",
    "                    #pass\n",
    "                #else:\n",
    "                    #new_def[2*i+1]=' '\n",
    "            definition_dict[key]=tuple(new_def)\n",
    "        pd_df=pd.DataFrame([\n",
    "                [module,definition] for module, definition in definition_dict.iteritems()\n",
    "            ])\n",
    "        pd_df.columns=[\"Module\",\"KEGG_Boolean\"]\n",
    "        pd_df.to_csv(rename_logical,header=True,sep=\"\\t\",index=False)\n",
    "        extra_def_file=rename_logical\n",
    "        \n",
    "    else:\n",
    "        pd_df=[]\n",
    "        core,file_ending=os.path.splitext(extra_def_file)\n",
    "        rename_logical=core+\"KEGG_bool\"+file_ending\n",
    "        with open(extra_def_file) as kegg_defs:\n",
    "            for line in kegg_defs:\n",
    "                module, definition=line.strip().split()\n",
    "                new_def=replacement(definition)\n",
    "                pd_df.append([module,new_def])\n",
    "        pd_df=pd.DataFrame(pd_df)\n",
    "        pd_df.columns=[\"Module_Name\",\"Logical_definition\"]\n",
    "        pd_df.to_csv(rename_logical,header=True,sep=\"\\t\")\n",
    "        extra_def_file=rename_logical\n",
    "        \n",
    "    return extra_def_file\n",
    "\n",
    "   \n",
    "    \n",
    "def kegg_pairs_wrapper(kegg_items,excluded_items, extra_items,database_dir):\n",
    "    '''\n",
    "    ********************************************************************************************************\n",
    "    This function acts as a wrapper to load in the local pairs databases.\n",
    "    It also excludes those items mentioned in the excluded items list and adds the user defined extra items.\n",
    "    ********************************************************************************************************\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    Calls:\n",
    "    \n",
    "    '''\n",
    "    #print \"THese are the excluded items\", excluded_items\n",
    "    kegg_item_1,kegg_item_2=kegg_items\n",
    "    if kegg_item_1==\"orthology\":\n",
    "        if isinstance(extra_items,type(None)):\n",
    "            KO_KG_ITEM_PAIRS=load_local_kegg_database_pairings(database_dir,[(\"orthology\",kegg_item_2)], False)[(\"orthology\",kegg_item_2)]\n",
    "            if excluded_items!=None:\n",
    "                #valid_PAIRS=set(KO_KG_ITEM_PAIRS.keys())-set(excluded_items)\n",
    "                #print \"These are the excluded items\", excluded_items\n",
    "                KO_KG_ITEM_PAIRS={key:set(value)-set(excluded_items) for key,value in KO_KG_ITEM_PAIRS.iteritems()}\n",
    "            #KO_KG_ITEM_PAIRS=add_extra_items_values(KO_KG_ITEM_PAIRS,extra_items)\n",
    "        else:\n",
    "            #print \"The extra items\",extra_items\n",
    "            KO_KG_ITEM_PAIRS=load_local_kegg_database_pairings(database_dir,[(\"orthology\",kegg_item_2)], False)[(\"orthology\",kegg_item_2)]\n",
    "            if excluded_items!=None:\n",
    "                #valid_PAIRS=set(KO_KG_ITEM_PAIRS.keys())-set(excluded_items)\n",
    "                #print \"These are the excluded items\", excluded_items\n",
    "                KO_KG_ITEM_PAIRS={key:set(value)-set(excluded_items) for key,value in KO_KG_ITEM_PAIRS.iteritems()}\n",
    "            KO_KG_ITEM_PAIRS=add_extra_items_values(KO_KG_ITEM_PAIRS,extra_items)\n",
    "        return KO_KG_ITEM_PAIRS\n",
    "    \n",
    "    elif kegg_item_2==\"orthology\":\n",
    "        if isinstance(extra_items,type(None)):\n",
    "            KG_ITEM_KO_PAIRS=load_local_kegg_database_pairings(database_dir,[(kegg_item_1,\"orthology\")], False)[(kegg_item_1,\"orthology\")]\n",
    "            if excluded_items!=None:\n",
    "                valid_PAIRS=set(KG_ITEM_KO_PAIRS.keys())-set(excluded_items)\n",
    "                KG_ITEM_KO_PAIRS={key:value for key,value in KG_ITEM_KO_PAIRS.iteritems() if key in valid_PAIRS}\n",
    "        else:\n",
    "            KG_ITEM_KO_PAIRS=load_local_kegg_database_pairings(database_dir,[(kegg_item_1,\"orthology\")], False)[(kegg_item_1,\"orthology\")]\n",
    "            if excluded_items!=None:\n",
    "                valid_PAIRS=set(KG_ITEM_KO_PAIRS.keys())-set(excluded_items)\n",
    "                KG_ITEM_KO_PAIRS={key:value for key,value in KG_ITEM_KO_PAIRS.iteritems() if key in valid_PAIRS}\n",
    "            for name, KOs in extra_items.iteritems():\n",
    "                KG_ITEM_KO_PAIRS[name]=KOs\n",
    "            \n",
    "        return KG_ITEM_KO_PAIRS\n",
    "    else:\n",
    "        print \"The input kegg item pair must have at least one occurence of orthology.\"\n",
    "        \n",
    "    return\n",
    "\n",
    "def add_extra_items_values(dict_1, extra_items_dict):\n",
    "    ''' Swaps the keys and values of the dictionary. Then, add these to the orthology - kg item pair dict'''\n",
    "    reversed_dict=defaultdict(list)\n",
    "    dict_1={key:set(values) for key,values in dict_1.iteritems()}\n",
    "    dict_1=defaultdict(set,dict_1)\n",
    "    #print extra_items_dict\n",
    "    for key,values in extra_items_dict.iteritems():\n",
    "        for value in values:\n",
    "            reversed_dict[value].append(key)\n",
    "    reversed_dict={key:list(set(values)) for key,values in reversed_dict.iteritems()}\n",
    "    #print \"THe reversed_dictionary\",reversed_dict\n",
    "    \n",
    "    for key,item in reversed_dict.iteritems():\n",
    "        #print item\n",
    "        dict_1[key].update(item)\n",
    "\n",
    "    dict_1={key:list(set(values)) for key,values in dict_1.iteritems()}\n",
    "    return dict_1\n",
    "\n",
    "def readable_kegg_wrapper(kegg_item,extra_items,database_dir):\n",
    "    '''Adds the user specified extras to the existing readable database after it is loaded into python.'''\n",
    "    \n",
    "    readable_names=load_readable_names(database_dir,[kegg_item],False)[kegg_item]\n",
    "    if extra_items==None:\n",
    "        pass\n",
    "    else:\n",
    "        for key in extra_items.iterkeys():\n",
    "            readable_names[key]=key    \n",
    "    return readable_names\n",
    "\n",
    "def standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, output_dir, bin_file, mult_adjust_type,extras_dict,excluded_set,extra_defs_file,account_for_overlap,make_mo_comps):\n",
    "    '''A workflow for calculating the enrichments of modules in target genomes/groups against other groups as based on \n",
    "    the comparisons and groupings file.\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    bin_taxa=load_bin_taxa(bin_file)\n",
    "    \n",
    "    #print bin_taxa\n",
    "\n",
    "    KO_hits=import_KO_hits(KO_file)\n",
    "    #print groupings_file\n",
    "    #print comparisons_file\n",
    "    if isinstance(groupings_file,type(None)):\n",
    "        print \"No groupings file specified.\"\n",
    "        groupings=load_groupings(groupings_file,KO_hits.columns)\n",
    "        groupings_dict=make_groupings_dict(KO_hits,None,all_grouped=True)\n",
    "    else:\n",
    "        groupings=load_groupings(groupings_file,KO_hits.columns)\n",
    "        groupings_dict=make_groupings_dict(KO_hits,groupings,all_grouped=False)\n",
    "        \n",
    "    if isinstance(comparisons_file,type(None)):\n",
    "        print \"No comparisons file specified.\"\n",
    "        comparisons_dict=make_comparisons_dict(KO_hits)\n",
    "    else:\n",
    "        comparisons=load_comparisons(comparisons_file)\n",
    "        comparisons_dict=comparisons\n",
    "    #print \"The comparisons to be made\",comparisons_dict\n",
    "    #print \"The groups made\", groupings_dict\n",
    "    #for source, targets in comparisons.iteritems():\n",
    "        #print \"These are the comparison to be made: [{0}]X[{1}]\".format(source,targets)\n",
    "    #KO_hits_matrix=construct_KO_matrix(KO_hits)\n",
    "    \n",
    "    #for group, KOs in groupings_dict.iteritems():\n",
    "    #    KO_hits[group]=KOs\n",
    "    if account_for_overlap:\n",
    "        overlap_file=construct_overlap_file(comparisons_dict, groupings)\n",
    "    else:\n",
    "        overlap_file=None\n",
    "    #print \"This is the overlap for each comparison being made\", overlap_file\n",
    "    if not isinstance(extras_dict,type(None)):\n",
    "        print \"Processing the extras files\"\n",
    "        extras_dict=load_extra_items(extras_dict)\n",
    "        #print \"THe extra items\", extras_dict\n",
    "    if not isinstance(excluded_set,type(None)):\n",
    "        print \"Processing the excluded files\"\n",
    "        excluded_set=load_excluded_items(excluded_set)\n",
    "    \n",
    "        \n",
    "    results_dict,N_comparisons=do_enrichment_comparisons(KO_hits,threshold, database_dir, comparisons_dict,extras_dict,excluded_set,extra_defs_file,overlap_file,make_mo_comps)\n",
    "    \n",
    "    results_dict=post_hoc_significance_correction(results_dict,N_comparisons,threshold,mult_adjust_type)\n",
    "\n",
    "    dfs=write_enrichment_data(results_dict, database_dir,output_dir,bin_taxa,mult_adjust_type,extras_dict)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def construct_overlap_file(comparison_dict, groupings):\n",
    "    groupings={key: set(members) for key, members in groupings.iteritems()}\n",
    "    groupings=defaultdict(set,groupings)\n",
    "    #print groupings\n",
    "    overlap_dict={}\n",
    "    for source, targets in comparison_dict.iteritems():\n",
    "        for target in targets:\n",
    "            if target in groupings:\n",
    "                if source in groupings:\n",
    "                    overlap_dict[(target,source)]=list(groupings[source] & groupings[target])\n",
    "                else:\n",
    "                    overlap_dict[(target,source)]=list(set([source]) & groupings[target])\n",
    "            else:\n",
    "                if source in groupings:\n",
    "                    overlap_dict[(target,source)]=list(groupings[source] & set([target]))\n",
    "                else:\n",
    "                    overlap_dict[(target,source)]=list(set([source]) & set([target]))\n",
    "                    \n",
    "        \n",
    "    return overlap_dict\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "def write_enrichment_data(enrichment_results_dict,database_dir,output_dir,bin_taxa,mult_adjust,extras_items):\n",
    "    '''Writes the Results_dict from the all_comparisons function after turning them into a pandas\n",
    "    dataframe. '''\n",
    "    pandas_dataframes={}\n",
    "    out_frame={}\n",
    "    #readable_orthology=readable_kegg_wrapper(\"orthology\",extra_items,database_dir)\n",
    "    readable_orthology=load_readable_names(database_dir,[\"orthology\"],False)[\"orthology\"]\n",
    "    readable_kegg_items=readable_kegg_wrapper(\"module\",extras_items,database_dir)\n",
    "    #readable_kegg_items=load_readable_names(database_dir,[\"Module\"],False)[\"Module\"]\n",
    "    \n",
    "    #pandas_dataframes[\"Module\"]={}\n",
    "    \n",
    "\n",
    "    df=pd.DataFrame([\n",
    "            [\"Module\",target_genome,source_genome,bin_taxa[target_genome],enriched_item,readable_kegg_items[enriched_item],p_value, expected_count,observed_count,completeness]\n",
    "            for (target_genome,source_genome), enriched_kegg_items in enrichment_results_dict.iteritems() for enriched_item,(p_value,expected_count,observed_count,completeness) in enriched_kegg_items.iteritems()\n",
    "        ])\n",
    "    df.columns=[\"Kegg_item\",\"Target_genome\",\"BaselineGenome\",\"Target_taxonomy\",\"{0}_ID\".format(\"Module\"),\"Readable_{0}\".format(\"Module\"),\"p_value\",\"Expected_Count\",\"Observed_count\",\"Completeness(MO_only)\"]\n",
    "    split_frames={}\n",
    "\n",
    "    #Split the dataframe into those ovserved in both target and source and only target\n",
    "    split_frames[\"Disjoint\"]=df[:][(df.Expected_Count==0) & (df.Observed_count>0)]\n",
    "    split_frames[\"Overlapped\"]=df[:][df.Expected_Count>0]\n",
    "        \n",
    "    pandas_dataframes[\"Module\"]=split_frames\n",
    "    out_frame[\"Module\"]=df\n",
    "    \n",
    "    for kegg_item, dfs in pandas_dataframes.iteritems():\n",
    "        for rel,df in dfs.iteritems():\n",
    "            df.to_csv(os.path.join(output_dir,\"enriched_{0}_{2}_corrected_{1}_comparisons.tsv\".format(kegg_item,rel,mult_adjust)),sep=\"\\t\",index=False)\n",
    "    return out_frame\n",
    "\n",
    "\n",
    "def post_hoc_significance_correction(results_dict,N_comparisons,threshold,mult_adjust_type):\n",
    "    '''Apply the multiple test correction after analysis.'''\n",
    "    \n",
    "    n=sum(N_comparisons.itervalues())\n",
    "    print \"THe number of genome pair comparison\",len(N_comparisons)\n",
    "    print \"The number of comparisons made\",n\n",
    "    \n",
    "    significant_results=multiple_test_correction(results_dict,threshold,n,mult_adjust_type)\n",
    "\n",
    "    new_results={(target,source):{PTH:results for PTH,results in pathway_dict.iteritems()} for ((target,source),pathway_dict) in significant_results.iteritems()}\n",
    "    \n",
    "    return new_results\n",
    "\n",
    "\n",
    "\n",
    "def adjusted_enrichment_test(target, source,threshold,MO_hits,database_dir,KO_KG_ITEM_PAIRS,KG_ITEM_KO_PAIRS,KO_PTH_structure,total_KO_hits,KO_hits,overlap_dict,kegg_item=\"Module\"):\n",
    "    '''A simple test for enrichment of some kegg item in the target genome based on the baseline probabilities calculated using\n",
    "    the source genome. A simple binomial test is used to work out the probably of seeing as many genes as was present\n",
    "    in the target genome given that it has the same chance of occuring as in the source genome. All module present in the\n",
    "    target but not at all in the source are also included in the output as (0,0,observed count of kegg item,0).f\n",
    "    \n",
    "    Input: \n",
    "        target               -  Genome to investigate for enrichment\n",
    "        source               -  The genome used to calculate the baseline chance of a kegg_item occuring.\n",
    "        KO_hits              -  Dictionary of genome: KO pairs, requires a collated entry for all microorganisms\n",
    "        threshold            -  The significance threshold before corrections.\n",
    "        kegg_item            -  The kegg_item to look for enrichment of. Normally run as [module, pathway]\n",
    "        database_dir         -  The location of the linking files and file descriptions\n",
    "        abundance_adjust     -  Account for the relative abundance of organism's in the metagenome.\n",
    "        abundance_file       -  A file with the relative abundance information of the microbes in each sample\n",
    "    Output:\n",
    "        Significant_scores   -  All enriched kegg_items passing the threshold after bonferroni correction.'''\n",
    "    \n",
    "\n",
    "    shared_pathways=MO_hits.ix[(MO_hits.loc[:,source]>0) & (MO_hits.loc[:,target]>0),:].index\n",
    "\n",
    "\n",
    "    all_target_KOs=make_KO_set_from_series(KO_hits[target])\n",
    "    #print \"Number of unique KOs present for the target.\", target, len(all_target_KOs)\n",
    "    target_KOs={PTH:set(items) & all_target_KOs  for PTH, items in KG_ITEM_KO_PAIRS.iteritems()}\n",
    "    target_KOs=defaultdict(set,target_KOs)\n",
    "    \n",
    "    #print \"This is the source and target\", source, target\n",
    "    \n",
    "    N_source_KOs=total_KO_hits[source]\n",
    "    \n",
    "    N_target_KOs=total_KO_hits[target]\n",
    "    \n",
    "    enrichment_scores=defaultdict(lambda:(0,0,0,0))\n",
    "    \n",
    "    #print \"These were the overlapping organisms\", overlap_dict[(target,source)]\n",
    "\n",
    "    account_for_overlap=isinstance(overlap_dict,dict)\n",
    "    if account_for_overlap:\n",
    "        overlapped_hits=MO_hits[overlap_dict[(target,source)]].sum(axis=1)\n",
    "        overlap_free_source=MO_hits[source]-overlapped_hits\n",
    "    else:\n",
    "        overlap_free_source=MO_hits[source]\n",
    "    #print overlap_free_source\n",
    "    #print \"weird value\", MO_hits[source]['Msuper_duper']\n",
    "    #print \"weird value\", MO_hits[target]['Msuper_duper']\n",
    "    #print \"The negative values\",overlap_free_source[overlap_free_source<0]\n",
    "\n",
    "    #print \"The total number of KOs for source and target,\", N_source_KOs, N_target_KOs\n",
    "    for PTH,count in MO_hits[target].iteritems():\n",
    "        if PTH in shared_pathways:\n",
    "            cont_tab_test=scipy.stats.fisher_exact\n",
    "            N_source_PTH_hits=overlap_free_source[PTH]\n",
    "            p_PTH_source=float(N_source_PTH_hits)/N_source_KOs\n",
    "            data_table=[[count,N_source_PTH_hits],[N_target_KOs-count,N_source_KOs-N_source_PTH_hits]]\n",
    "            #print PTH, data_table,N_source_KOs, N_source_PTH_hits\n",
    "            p_val=cont_tab_test(data_table)[1]\n",
    "        else:\n",
    "            cont_tab_test=lambda x: 0\n",
    "            N_source_PTH_hits=0\n",
    "            p_PTH_source=0\n",
    "            data_table=[[count,N_source_PTH_hits],[N_target_KOs-count,N_source_KOs-N_source_PTH_hits]]\n",
    "            #print data_table\n",
    "            p_val=cont_tab_test(data_table)\n",
    "            \n",
    "        enrichment_scores[PTH]=(p_val,p_PTH_source*N_target_KOs,count,measure_completeness(PTH,target_KOs[PTH],KO_PTH_structure[PTH]))\n",
    "\n",
    "    return enrichment_scores,len(shared_pathways)\n",
    "    \n",
    "def make_KO_set_from_series(KO_series):\n",
    "    \n",
    "    return set(KO_series[KO_series>0].index)\n",
    "def enrichm_wf(args):\n",
    "    \n",
    "    KO_file=args.KO_file\n",
    "    groupings_file=args.groupings_file\n",
    "    comparisons_file=args.comparisons_file\n",
    "    threshold= args.threshold\n",
    "    database_dir=args.database_dir\n",
    "    output_dir=args.output_dir\n",
    "    bin_file=args.bin_file\n",
    "    mult_adjust_type=args.mult_test_correction\n",
    "    excluded_items=args.exclude\n",
    "    extra_file=args.extra\n",
    "    extra_defs=args.extra_defs\n",
    "    dfs=standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, output_dir, bin_file, mult_adjust_type,extra_file, excluded_items,extra_defs)\n",
    "    return dfs\n",
    "\n",
    "def completem_wf(args):\n",
    "    #Load in variables\n",
    "    KO_file=args.KO_file\n",
    "    #groupings_file=args.groupings_file\n",
    "    #comparisons_file=args.comparisons_file\n",
    "    #threshold= args.threshold\n",
    "    database_dir=args.database_dir\n",
    "    output_dir=args.output_dir\n",
    "    bin_file=args.bin_file\n",
    "    #mult_adjust_type=args.mult_test_correction\n",
    "    excluded_items=args.exclude\n",
    "    extra_items=args.extra\n",
    "    extra_defs=args.extra_defs\n",
    "    extract_core=args.extract_core\n",
    "    #process all of the genomes one by one.\n",
    "    dfs=standard_completeness_wf(KO_file,database_dir,output_dir,bin_file,excluded_items,extra_items,extra_defs,extract_core)\n",
    "    return dfs\n",
    "\n",
    "def standard_completeness_wf(KO_file,database_dir,output_dir,bin_file,excluded_set,extras_dict,extra_defs,extract_core):\n",
    "    bin_taxa=load_bin_taxa(bin_file)\n",
    "    \n",
    "    KO_hits=import_KO_hits(KO_file)\n",
    "\n",
    "    if not isinstance(extras_dict,type(None)):\n",
    "        print \"Processing the extras files\"\n",
    "        extras_dict=load_extra_items(extras_dict)\n",
    "        #print \"THe extra items\", extras_dict\n",
    "    if not isinstance(excluded_set,type(None)):\n",
    "        print \"Processing the excluded files\"\n",
    "        excluded_set=load_excluded_items(excluded_set)\n",
    "    \n",
    "    all_modules=get_module_completeness(KO_hits,database_dir,excluded_set,extras_dict,extra_defs)\n",
    "    \n",
    "    #print \"Number of genomes:\", len(all_modules)\n",
    "    \n",
    "    #print \"The results\", all_modules\n",
    "    \n",
    "    output_file=os.path.join(output_dir, \"Genome_module_completeness_matrix.tsv\")\n",
    "    \n",
    "    readable_names=readable_kegg_wrapper(\"module\",extras_dict,database_dir)\n",
    "    \n",
    "    #print \"Readable_names:\",readable_names\n",
    "    \n",
    "    df=write_module_completeness_data(all_modules,output_file,bin_taxa,extract_core,readable_names)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def get_module_completeness(KO_hits,database_dir,excluded_items,extra_items,extra_defs_file):\n",
    "    #Load pairings\n",
    "    KO_KG_ITEM_PAIRS=kegg_pairs_wrapper([\"orthology\",\"module\"],excluded_items, extra_items,database_dir)\n",
    "    \n",
    "    KO_KG_ITEM_PAIRS=defaultdict(set, KO_KG_ITEM_PAIRS)\n",
    "    \n",
    "    KG_ITEM_KO_PAIRS=kegg_pairs_wrapper([\"module\",\"orthology\"],excluded_items, extra_items,database_dir)\n",
    "    \n",
    "    KO_sets=make_sets_from_df(KO_hits)\n",
    "    \n",
    "    new_MO_hits_matrix=construct_MO_matrix(KO_hits, KG_ITEM_KO_PAIRS)\n",
    "    \n",
    "    observed_pathways=set(new_MO_hits_matrix.ix[new_MO_hits_matrix.apply(any_hits,axis=1),].index)\n",
    "    print \"The number of observed modules\", len(observed_pathways)\n",
    "    #genome_KO_PTH={genome:set(itertools.chain(*[itertools.chain(*[KO_KG_ITEM_PAIRS[KO] for KO in KOs])])) for genome,KOs in KO_hits.iteritems()}\n",
    "    is_module=True\n",
    "    #observed_pathways=set(itertools.chain(*[KO_KG_ITEM_PAIRS[KO] for KO in itertools.chain(*[KOs for ID, KOs in KO_hits.iteritems()])]))\n",
    "\n",
    "    #Must be MODULES\n",
    "    KO_PTH_structure=logical_loading_wrapper(database_dir, extra_defs_file, extra_items)            \n",
    "    KO_PTH_structure=defaultdict(tuple,KO_PTH_structure)\n",
    "   \n",
    "    complete_data=defaultdict(lambda: defaultdict(float))\n",
    "    for genome, KOs in KO_sets.iteritems():\n",
    "\n",
    "        for module in observed_pathways:\n",
    "            completeness=new_measure_completeness(module,KOs,KO_PTH_structure[module],is_module)\n",
    "            #print \"module\", KO_PTH_structure[module]\n",
    "            complete_data[genome][module]=completeness\n",
    "    \n",
    "    return complete_data\n",
    "\n",
    "def make_sets_from_df(df):\n",
    "    ko_set={}\n",
    "    for genome, KOs in df.iteritems():\n",
    "        ko_set[genome]=make_KO_set_from_series(KOs)\n",
    "    \n",
    "    return ko_set\n",
    "\n",
    "def write_module_completeness_data(genome_module_data,output_file,bin_taxa,extract_core_MOs,readable_names):\n",
    "    '''Creates a dataframe from the genome[module]=completeness dictionary.\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    '''\n",
    "    df=pd.DataFrame.from_dict(genome_module_data,orient='columns')\n",
    "    print \"The matrix dimensions\", df.shape\n",
    "    #taxonomy\n",
    "    #if len(bin_taxa)>0:\n",
    "        #df['Taxonomy']=df.index.map(bin_taxa)\n",
    "    if extract_core_MOs:\n",
    "        df=df.ix[df.apply(all_hits,axis=1),]\n",
    "    df['module_desc']=pd.Series(df.index,index=df.index).map(readable_names)\n",
    "    #print readable_names\n",
    "    #print pd.Series(df.index).map(readable_names)\n",
    "    print df['module_desc']\n",
    "    cols=df.columns.tolist()\n",
    "    cols=cols[-1:]+cols[:-1]\n",
    "    df=df[cols]\n",
    "    df.to_csv(output_file,index=True, header=True, sep=\"\\t\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def all_hits(row):\n",
    "    return all(row>0)\n",
    "\n",
    "def any_hits(row):\n",
    "    return any(row>0)\n",
    "\n",
    "def load_definition_file(def_file):\n",
    "    def_dict={}\n",
    "    with open(def_file) as definitions:\n",
    "        for line in definitions:\n",
    "            module,definition=line.strip().split(\"\\t\")\n",
    "            def_dict[module]=definition\n",
    "    return def_dict\n",
    "\n",
    "def make_extra_definition_database(definitions_file,database_dir):\n",
    "    '''\n",
    "    Definition:\n",
    "        This function will take an entire kegg module definition file and will create\n",
    "        a new local database with the expressions written so that they can simple be\n",
    "        evaluated when loading the files.\n",
    "    Input: \n",
    "        database_dir: str\n",
    "            A directory containing the database of kegg module definitions.\n",
    "    Output:\n",
    "        None\n",
    "    Calls:\n",
    "        replacement: Turns kegg definitions in logical nested tuples of sets.\n",
    "    '''\n",
    "    old_module_def=load_definition_file(definitions_file)\n",
    "    #print \"This is the old module information\",old_module_def\n",
    "    new_pd_df=[\"\"]*len(old_module_def)\n",
    "    i=0\n",
    "    for module,definition in old_module_def.iteritems():\n",
    "        try:\n",
    "            logical_evaluation=replacement(definition,False)[1]\n",
    "            new_pd_df[i]=[module,logical_evaluation]\n",
    "            i+=1\n",
    "                \n",
    "        except TypeError:\n",
    "            print \"TypeError 2:\",module, definition\n",
    "        except SyntaxError:\n",
    "            print \"SyntaxError 2:\",module, definition\n",
    "        except NameError:\n",
    "            print \"NameError 2:\",module ,definition\n",
    "    #print new_pd_df      \n",
    "    new_pd_df=pd.DataFrame(new_pd_df)\n",
    "    #print \"The second checkpoint.\"\n",
    "    new_pd_df.columns=[\"ModuleID\",\"KEGG_log_expr\"]\n",
    "    \n",
    "    new_pd_df.to_csv(os.path.join(database_dir, \"module_extra_kegg_log_expr.tsv\"),header=True,sep=\"\\t\",index=False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_local_cleaned_definition_db(extra_def_file):\n",
    "    cleaned_db={}\n",
    "    with open(os.path.join(extra_def_file)) as paired_exprs:\n",
    "        next(paired_exprs) #Skip header\n",
    "        for line in paired_exprs:\n",
    "            module,expr=line.split(\"\\t\")\n",
    "            kegg_log=eval(expr)\n",
    "            if not isinstance(kegg_log,tuple):\n",
    "                kegg_log=tuple([kegg_log])\n",
    "            cleaned_db[module]=kegg_log\n",
    "    return cleaned_db\n",
    "\n",
    "def logical_loading_wrapper(database_dir, definitions_file, extras):\n",
    "    '''\n",
    "    Loads the kegg booleans used to determine the completeness of a module.\n",
    "    It can also handle creating a database for the user added definitions and loading them at the same time\n",
    "    as the complete kegg directory.\n",
    "    \n",
    "    Input:\n",
    "    databse_dir: str\n",
    "        location of database files\n",
    "    definitions_file: str or None\n",
    "        location of user definition definitions\n",
    "    extras: dict or None\n",
    "        The extra modules added by the user with no definition structure.\n",
    "    Output:\n",
    "        original_kegg_log : dict\n",
    "            module,kegg_boolean pairs to be used for completeness evaluations\n",
    "    \n",
    "    '''\n",
    "    if definitions_file!=None:\n",
    "        print \"Using predefined kegg booleans\"\n",
    "        make_extra_definition_database(definitions_file,database_dir)\n",
    "        original_kegg_log=load_local_cleaned_definition_db(os.path.join(database_dir,\"module_kegg_log_expr.tsv\"))\n",
    "        new_kegg_log=load_local_cleaned_definition_db(os.path.join(database_dir, \"module_extra_kegg_log_expr.tsv\"))\n",
    "        for module, kegg_bool in new_kegg_log.iteritems():\n",
    "            original_kegg_log[module]=kegg_bool\n",
    "            #print kegg_bool\n",
    "    elif definitions_file==None and extras!=None:\n",
    "        print \"Automatically creating kegg boolean from module components\"\n",
    "        make_extras_logical(definitions_file,extras,database_dir)\n",
    "        original_kegg_log=load_local_cleaned_definition_db(os.path.join(database_dir,\"module_kegg_log_expr.tsv\"))\n",
    "        new_kegg_log=load_local_cleaned_definition_db(os.path.join(database_dir, \"module_extra_kegg_log_expr.tsv\"))\n",
    "        for module, kegg_bool in new_kegg_log.iteritems():\n",
    "            original_kegg_log[module]=kegg_bool\n",
    "            #print kegg_bool\n",
    "    else:\n",
    "        print \"No extra definitions have been added.\"\n",
    "        original_kegg_log=load_local_cleaned_definition_db(os.path.join(database_dir,\"module_kegg_log_expr.tsv\"))\n",
    "        \n",
    "    return original_kegg_log\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the extras files\n",
      "Processing the excluded files\n",
      "Using predefined kegg booleans\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in get_records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "KO_file=all_kegg\n",
    "groupings_file=os.path.join(output_dir,\"enriched_hits\",\"groupings.tsv.txt\")\n",
    "#print groupings_file\n",
    "comparisons_file=os.path.join(output_dir,\"enriched_hits\",\"comparisons.tsv.txt\")\n",
    "threshold= 0.05\n",
    "#database_dir=args.database_dir\n",
    "enrich_output_dir=os.path.join(output_dir,\"enriched_hits\")\n",
    "bin_taxa=tax_file\n",
    "mult_adjust_type=\"FDR\"\n",
    "test_new=True\n",
    "extract_core=False\n",
    "account_for_overlap=False\n",
    "make_mo_comparisons=True\n",
    "if test_new:\n",
    "    excluded_items=os.path.join(output_dir,\"enriched_hits\",\"exclusion_file.txt\")\n",
    "    extra_items=os.path.join(output_dir,\"enriched_hits\",\"Extra_module_creation\",\"extras_file.txt\")#None#os.path.join(output_dir,\"enriched_hits\",\"extras_file.txt\")\n",
    "    extra_defs=os.path.join(output_dir,\"enriched_hits\",\"Extra_Module_creation\",\"extra_definitions.txt\")#None#os.path.join(output_dir,\"enriched_hits\",\"\")\n",
    "else:\n",
    "    excluded_items=None\n",
    "    extra_items=None\n",
    "    extra_defs=None\n",
    "\n",
    "#print extra_defs\n",
    "dfs=standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, enrich_output_dir, bin_taxa, mult_adjust_type,extra_items,excluded_items,extra_defs,account_for_overlap,make_mo_comparisons)\n",
    "#print import_KO_hits(KO_file).shape\n",
    "\n",
    "#comp_dfs=standard_completeness_wf(KO_file,database_dir,enrich_output_dir,bin_taxa,excluded_items,extra_items,extra_defs,extract_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the extras files\n",
      "The number of observed modules 612\n",
      "Using predefined kegg booleans\n",
      "The matrix dimensions (612, 54)\n",
      "2-Oxoglutarate=>GlutamicAcid                                                  2-Oxoglutarate=>GlutamicAcid\n",
      "Aspartate=>Asparagine                                                                Aspartate=>Asparagine\n",
      "DMS=>DMSO                                                                                        DMS=>DMSO\n",
      "DMSO=>DMS                                                                                        DMSO=>DMS\n",
      "DMSP=>3-(Methylthio)-propanoate(dmdA)                                DMSP=>3-(Methylthio)-propanoate(dmdA)\n",
      "Dimethyl-benzimidazole=>VitaminB12Coenzyme                      Dimethyl-benzimidazole=>VitaminB12Coenzyme\n",
      "Glutamate=>Glutamine                                                                  Glutamate=>Glutamine\n",
      "Glutamate=>Proline_v2                                                                Glutamate=>Proline_v2\n",
      "Glycine=>Serine                                                                            Glycine=>Serine\n",
      "Hydroxy-Pyruvate=>Serine                                                          Hydroxy-Pyruvate=>Serine\n",
      "L-Glutamate=>Uropor-phyrinogen III                                      L-Glutamate=>Uropor-phyrinogen III\n",
      "L-Threonine=>VitaminB12Coenzyme                                            L-Threonine=>VitaminB12Coenzyme\n",
      "M00001                                                   Glycolysis (Embden-Meyerhof pathway), glucose ...\n",
      "M00002                                                   Glycolysis, core module involving three-carbon...\n",
      "M00003                                                        Gluconeogenesis, oxaloacetate => fructose-6P\n",
      "M00004                                                   Pentose phosphate pathway (Pentose phosphate c...\n",
      "M00005                                                                PRPP biosynthesis, ribose 5P => PRPP\n",
      "M00006                                                   Pentose phosphate pathway, oxidative phase, gl...\n",
      "M00007                                                   Pentose phosphate pathway, non-oxidative phase...\n",
      "M00008                                                   Entner-Doudoroff pathway, glucose-6P => glycer...\n",
      "M00009                                                              Citrate cycle (TCA cycle, Krebs cycle)\n",
      "M00010                                                   Citrate cycle, first carbon oxidation, oxaloac...\n",
      "M00011                                                   Citrate cycle, second carbon oxidation, 2-oxog...\n",
      "M00012                                                                                    Glyoxylate cycle\n",
      "M00013                                                   Malonate semialdehyde pathway, propanoyl-CoA =...\n",
      "M00014                                                               Glucuronate pathway (uronate pathway)\n",
      "M00015                                                          Proline biosynthesis, glutamate => proline\n",
      "M00016                                                   Lysine biosynthesis, succinyl-DAP pathway, asp...\n",
      "M00017                                                   Methionine biosynthesis, apartate => homoserin...\n",
      "M00018                                                   Threonine biosynthesis, aspartate => homoserin...\n",
      "                                                                               ...                        \n",
      "M00774                                                   Erythromycin biosynthesis, propanoyl-CoA + met...\n",
      "M00777                                                   Avermectin biosynthesis, 2-methylbutanoyl-CoA/...\n",
      "M00778                                                   Type II polyketide backbone biosynthesis, acyl...\n",
      "M00779                                                   Dihydrokalafungin biosynthesis, octaketide => ...\n",
      "M00780                                                   Tetracycline/oxytetracycline biosynthesis, pre...\n",
      "M00781                                                   Nogalavinone/aklavinone biosynthesis, deoxynog...\n",
      "M00783                                                   Tetracenomycin C/8-demethyltetracenomycin C bi...\n",
      "M00784                                                   Elloramycin biosynthesis, 8-demethyltetracenom...\n",
      "M00786                                                   Fumitremorgin alkaloid biosynthesis, tryptopha...\n",
      "M00787                                                     Bacilysin biosynthesis, prephenate => bacilysin\n",
      "M00789                                                   Rebeccamycin biosynthesis, tryptophan => rebec...\n",
      "M00790                                                   Pyrrolnitrin biosynthesis, tryptophan => pyrro...\n",
      "M00793                                                                        dTDP-L-rhamnose biosynthesis\n",
      "M00804                                                   Complete nitrification, comammox, ammonia => n...\n",
      "M00810                                                   Nicotine degradation, pyridine pathway, nicoti...\n",
      "N-acetylgalactosamine-6-sulfatase                                        N-acetylgalactosamine-6-sulfatase\n",
      "N-acetylglucosamine-6-sulfatase                                            N-acetylglucosamine-6-sulfatase\n",
      "N-sulfoglucosamine sulfohydrolase                                        N-sulfoglucosamine sulfohydrolase\n",
      "Ornithine=>Arginine                                                                    Ornithine=>Arginine\n",
      "Ornithine=>Proline                                                                      Ornithine=>Proline\n",
      "Oxaloacetate=>Aspartate                                                            Oxaloacetate=>Aspartate\n",
      "Phenylalanine=>Tyrosine                                                            Phenylalanine=>Tyrosine\n",
      "Precorrin 2=>Cob(II)yrinatea,cdiamide via CoPrecorrin    Precorrin 2=>Cob(II)yrinatea,cdiamide via CoPr...\n",
      "Precorrin 2=>Cob(II)yrinatea,cdiamide via Precorrin      Precorrin 2=>Cob(II)yrinatea,cdiamide via Prec...\n",
      "Pyruvate=>Alanine                                                                        Pyruvate=>Alanine\n",
      "Serine=>Glycine                                                                            Serine=>Glycine\n",
      "Threonine=>Glycine                                                                      Threonine=>Glycine\n",
      "Uropor-phyrinogen III=>Precorrin 2                                      Uropor-phyrinogen III=>Precorrin 2\n",
      "arylsulfatase B                                                                            arylsulfatase B\n",
      "iduronate 2-sulfatase                                                                iduronate 2-sulfatase\n",
      "Name: module_desc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "KO_file=all_kegg\n",
    "groupings_file=os.path.join(output_dir,\"enriched_hits\",\"groupings.tsv.txt\")\n",
    "#print groupings_file\n",
    "comparisons_file=os.path.join(output_dir,\"enriched_hits\",\"comparisons.tsv.txt\")\n",
    "threshold= 0.05\n",
    "#database_dir=args.database_dir\n",
    "enrich_output_dir=os.path.join(output_dir,\"enriched_hits\")\n",
    "bin_taxa=tax_file\n",
    "mult_adjust_type=\"FDR\"\n",
    "extract_core=False\n",
    "account_for_overlap=False\n",
    "make_mo_comparisons=True\n",
    "excluded_items=None\n",
    "extra_items=os.path.join(output_dir,\"enriched_hits\",\"Extra_module_creation\",\"extras_file.txt\")#None#os.path.join(output_dir,\"enriched_hits\",\"extras_file.txt\")\n",
    "extra_defs=os.path.join(output_dir,\"enriched_hits\",\"Extra_Module_creation\",\"extra_definitions.txt\")#None#os.path.join(output_dir,\"enriched_hits\",\"\")\n",
    "\n",
    "\n",
    "#print extra_defs\n",
    "#dfs=standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, enrich_output_dir, bin_taxa, mult_adjust_type,extra_items,excluded_items,extra_defs,account_for_overlap,make_mo_comparisons)\n",
    "#print import_KO_hits(KO_file).shape\n",
    "\n",
    "comp_dfs=standard_completeness_wf(KO_file,database_dir,enrich_output_dir,bin_taxa,excluded_items,extra_items,extra_defs,extract_core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sammy's CPR genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No extra definitions have been added.\n",
      "THe number of genome pair comparison 27\n",
      "The number of comparisons made 1799\n"
     ]
    }
   ],
   "source": [
    "person_dir=os.path.join(*[core,g_drive,\"Other_Peoples_Data\",\"Sammy\",\"CPR_genomes\"])\n",
    "KO_file=os.path.join(*[person_dir,\"CPR_genomes.txt\"])\n",
    "groupings_file=os.path.join(*[person_dir,\"groupings.txt\"])\n",
    "#print groupings_file\n",
    "comparisons_file=os.path.join(*[person_dir,\"comparisons.txt\"])\n",
    "threshold= 0.05\n",
    "#database_dir=args.database_dir\n",
    "enrich_output_dir=person_dir\n",
    "#print person_dir\n",
    "bin_taxa=tax_file\n",
    "mult_adjust_type=\"FDR\"\n",
    "test_new=False\n",
    "extract_core=False\n",
    "account_for_overlap=False\n",
    "make_mo_comparisons=True\n",
    "excluded_items=None\n",
    "extra_items=None\n",
    "extra_defs=None\n",
    "                                \n",
    "dfs=standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, enrich_output_dir, bin_taxa, mult_adjust_type,extra_items,excluded_items,extra_defs,account_for_overlap,make_mo_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nitrospira Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No extra definitions have been added.\n",
      "THe number of genome pair comparison 3\n",
      "The number of comparisons made 754\n"
     ]
    }
   ],
   "source": [
    "#Changed Non-comammox to Non_comammox in the comparisons file \n",
    "person_dir=os.path.join(*[core,g_drive,\"Other_Peoples_Data\",\"Caitlin\"])\n",
    "KO_file=os.path.join(*[person_dir,\"Nitrospira_KO_kegg_matrix.tsv\"])\n",
    "groupings_file=os.path.join(*[person_dir,\"nitrospira_groups.tsv\"])\n",
    "#print groupings_file\n",
    "comparisons_file=os.path.join(*[person_dir,\"nitrospira_comparisons.txt\"])\n",
    "threshold= 0.05\n",
    "#database_dir=args.database_dir\n",
    "enrich_output_dir=person_dir\n",
    "#print person_dir\n",
    "bin_taxa=tax_file\n",
    "mult_adjust_type=\"FDR\"\n",
    "test_new=False\n",
    "extract_core=False\n",
    "account_for_overlap=False\n",
    "make_mo_comparisons=True\n",
    "excluded_items=None\n",
    "extra_items=None\n",
    "extra_defs=None\n",
    "                                \n",
    "dfs=standard_enrichment_wf(KO_file, groupings_file,comparisons_file,threshold, database_dir, enrich_output_dir, bin_taxa, mult_adjust_type,extra_items,excluded_items,extra_defs,account_for_overlap,make_mo_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os, sys\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import re\n",
    "#standard_enrichment_wf(KO_file,\\\n",
    "#        groupings_file,comparisons_file,threshold, database_dir, output_dir, bin_taxa, mult_adjust_type)\n",
    "\n",
    "def parse_args():\n",
    "    parser=argparse.ArgumentParser()\n",
    "    subparsers = parser.add_subparsers(help='Please select one of either: enrichm or completem')\n",
    "    parser.add_argument(\"-c\",\"--cpus\",help=\"**UNIMPLEMENTED** - Break each of the pair of comparisons onto a subprocess\")\n",
    "    parser.add_argument(\"-v\",\"--verbose\",help=\"**UNIMPLEMENTED** - Decided whether to have more descriptive output of current steps.\")\n",
    "    enrichm_parser=subparsers.add_parser('enrichm',description=\"A simple tool for looking for enrichment of KO hits to kegg modules\\\n",
    "    between groups of genomes.\")\n",
    "    enrichm_parser.add_argument('KO_file',help=\"A file KO counts with KO as row and source as column or genome\\tKO1;KO2;.... pairs\")\n",
    "    enrichm_parser.add_argument('-gf','--groupings_file',help=\"A file containing the genomes that should be grouped with a specific name\")\n",
    "    enrichm_parser.add_argument('-cf','--comparisons_file',help=\"A file containing the comparisons between groups to be made\")\n",
    "    enrichm_parser.add_argument('threshold',help=\"The threshold to control for in false discovery rate of familywise error rate\")\n",
    "    enrichm_parser.add_argument('database_dir',help=\"The directory containing the local kegg databases.\")\n",
    "    enrichm_parser.add_argument('output_dir',help=\"The directory to write output information.\")\n",
    "    enrichm_parser.add_argument('-b','--bin_taxa',help=\"A file containing a taxonomic pairing with some genomes\")\n",
    "    enrichm_parser.add_argument('-m','--mult_test_correction',default='FDR',help='The form of mutiple test correction to use. There are 5\\\n",
    "    options: ')\n",
    "    enrichm_parser.add_argument('--exclude',help='A list of kegg items to exclude from the analysis.')\n",
    "    enrichm_parser.add_argument('--extra',help='A file of extra kegg_item: KO pairs defined by the user.')\n",
    "    enrichm_parser.add_argument('--extra_defs',help='A file of extra kegg_item\\tKEGG definition pairs defined by the user.')\n",
    "    \n",
    "    completem_parser=subparsers.add_parser('completem',description=\"A small library of tools for evaluting kegg booleans offline.\")\n",
    "    \n",
    "    completem_parser.add_argument('KO_file',help=\"A file KO counts with KO as row and source as column or genome\\tKO1;KO2;.... pairs\")\n",
    "    completem_parser.add_argument('database_dir',help=\"The directory containing the local kegg databases.\")\n",
    "    completem_parser.add_argument('output_dir',help=\"The directory to write output information.\")\n",
    "    completem_parser.add_argument('-b','--bin_taxa',help=\"A file containing a taxonomic pairing with some genomes\")\n",
    "    completem_parser.add_argument('--exclude',help='A list of kegg items to exclude from the analysis.')\n",
    "    completem_parser.add_argument('--extra',help='A file of extra kegg_item: KO pairs defined by the user.')\n",
    "    completem_parser.add_argument('--extra_defs',help='A file of extra kegg_item\\tKEGG definition pairs defined by the user.')\n",
    "    args=parser.parse_args()\n",
    "    \n",
    "    return args\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    args=parse_args()\n",
    "    \n",
    "    if args.subparser_name=='enrichm':\n",
    "        dfs=enrichm_wf(args)\n",
    "    elif args.subparser_name=='completem':\n",
    "        dfs=completem_wd(args)\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kegg based hmm extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-24cd53c03709>, line 386)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-24cd53c03709>\"\u001b[1;36m, line \u001b[1;32m386\u001b[0m\n\u001b[1;33m    def flatten_fasta_file():\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob,subprocess,shutil\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import os,sys,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob as gb\n",
    "from collections import defaultdict\n",
    "\n",
    "def kegg_hmms_wf(hmm_dir, output_dir, group_title, opt_item_file, extras_file,database_dir,seq_dir,cpus,tax_file):\n",
    "    '''This workflow relies on having a local directory with hmms from kegg or a separate directory\n",
    "    with hmms of interest. It simply creates a directory, a hmm database, runs the hmm search and then reads the results\n",
    "    to product two counts files. One for gene with a hit per genome/searched object and one \n",
    "    with hits per contig in each searched object. It is a tool to improve my speed of using kegg hmms.\n",
    "    The modules file lets me extract all KO hmms relevant to a module for quicker searching. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if not isinstance(extras_file,type(None)):\n",
    "        print \"Processing the extras files\"\n",
    "        extras_file=load_extra_items(extras_file)\n",
    "        \n",
    "    if not isinstance(opt_item_file,type(None)):\n",
    "        opt_item_file=load_optional_items(opt_item_file,extras_file, database_dir)\n",
    "\n",
    "    new_directory=extract_local_hmms(hmm_dir,output_dir,group_title,opt_item_file)\n",
    "    hmm_database=make_hmm_database(new_directory)\n",
    "    \n",
    "    table_dir=parallel_search_hmm_database(new_directory,hmm_database,seq_dir,cpus)\n",
    "    \n",
    "    gene_hits_dir=os.path.join(new_directory, \"gene_hits\")\n",
    "    os.mkdir(gene_hits_dir)\n",
    "    N_gene_hits,motif_hits_in_gene=hmm_hits_wf(table_dir, gene_hits_dir,tax_file, 1,\"#\",None)\n",
    "    \n",
    "    return N_gene_hits,motif_hits_in_gene\n",
    "\n",
    "def load_optional_items(opt_item_file,extra_items,database_dir):\n",
    "    '''Loads the local file of KOs and modules to extract hmms for.'''\n",
    "    new_items=[]\n",
    "    with open(opt_item_file) as optional_items:\n",
    "        for line in optional_items:\n",
    "            item=line.strip()\n",
    "            new_items.append(item)\n",
    "    module_ko_pairs=kegg_pairs_wrapper([\"module\",'orthology'],None, extra_items,database_dir)\n",
    "    for item in new_items:\n",
    "        if item not in module_ko_pairs:\n",
    "            module_ko_pairs[item]=item\n",
    "    old_len=len(new_items)\n",
    "    new_items=[module_ko_pairs[item] for item in new_items]\n",
    "    new_len=len(new_items)\n",
    "    if new_len>old_len:\n",
    "        print \"Some modules were processed.\"\n",
    "    else:\n",
    "        print \"No modules were processed.\"\n",
    "    new_items=set(new_items)\n",
    "    \n",
    "    print \"{0} kos will be retrieved.\".format(len(new_items))\n",
    "    \n",
    "    return new_items\n",
    "\n",
    "def try_new_filename(file_name):\n",
    "    '''Checks if a path points to an existing object. If it does then a new file name is map\n",
    "    with a different number appended to the end.'''\n",
    "    if os.path.exists(file_name):\n",
    "        path,ext=os.path.splitext(file_name)\n",
    "        if re.match('[0-9]+$',path):\n",
    "            path=path[:-1]+str(int(path[-1])+1)\n",
    "            file_name=path+ext\n",
    "            return try_new_filename(file_name)\n",
    "        else:\n",
    "            path=path+\"0\"\n",
    "            file_name=path+ext\n",
    "            return try_new_filename(file_name)\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "def extract_local_hmms(orig_hmm_dir, output_dir,group_title, opt_items):\n",
    "    '''Copies the desired hmm's into the new output directory.'''\n",
    "    new_dir_path=os.path.join(output_dir,group_title)\n",
    "    os.mkdir(new_dir_path)\n",
    "    hmm_dir=os.path.join(new_dir_path,\"hmms\")\n",
    "    os.mkdir(hmm_dir)\n",
    "    if not isinstance(opt_items,type(None)):\n",
    "        for KO in opt_items:\n",
    "            #print \"The KO\", KO\n",
    "            ko_file=os.path.join(orig_hmm_dir,KO+\".hmm\")\n",
    "            hmm_name=KO+\".hmm\"\n",
    "            new_loc=os.path.join(hmm_dir,hmm_name)\n",
    "            shutil.copyfile(ko_file,new_loc)\n",
    "    else:\n",
    "        for file_name in glob.glob(os.path.join(orig_hmm_dir,'*.hmm')):\n",
    "            hmm_name=os.path.basename(file_name)\n",
    "            new_loc=os.path.join(hmm_dir,hmm_name)\n",
    "            shutil.copyfile(file_name,new_loc)\n",
    "        \n",
    "    return new_dir_path\n",
    "\n",
    "def create_description_file(hmm_dir,database_dir):\n",
    "    '''Creates a new KO:Readable name key from the hmms found in the directory.'''\n",
    "    readable_KOs=load_readable_names_wrappers('orthology',database_dir)\n",
    "    ko_list=[]\n",
    "    for file_name in glob.glob(hmm_dir,'*.hmm'):\n",
    "        hmm_name=os.path.basename(file_name)\n",
    "        hmm,ext=os.path.splitext(hmm_name)\n",
    "        ko_list.append(hmm)\n",
    "    ko_list=set(ko_list)\n",
    "    ko_tup=[\"\\t\".join((ko,readable_KOs[ko])) for ko in ko_list]\n",
    "    ko_file=\"\\n\".join(ko_tup)\n",
    "    with open(os.path.join(hmm_dir,\"hmm_descriptions.tsv\")) as desc_file:\n",
    "        desc_file.write(ko_file)    \n",
    "    return None\n",
    "\n",
    "def make_hmm_database(working_dir):\n",
    "    '''Creates new directory for the hmm database, a concatenated database file\n",
    "    and auxilliary hmmer files needed to process the scan quickly.'''\n",
    "    hmm_dir=os.path.join(working_dir,\"hmms\")\n",
    "    hmm_database_dir=os.path.join(working_dir,\"hmm_database\")\n",
    "    os.mkdir(hmm_database_dir)\n",
    "    #concatenate all of the hmm files.\n",
    "    key_name=os.path.split(working_dir.strip(os.sep))[-1]\n",
    "    hmm_database=os.path.join(hmm_database_dir,key_name+\"_hmm_database.hmm\")\n",
    "    with open(hmm_database,'wb+') as database:\n",
    "        for hmm_file in glob.glob(os.path.join(hmm_dir,'*.hmm')):\n",
    "            if hmm_file==hmm_database:\n",
    "                continue\n",
    "            with open(hmm_file, 'rb') as readfile:\n",
    "                shutil.copyfileobj(readfile, database)\n",
    "    #set up the local database properly - hmmer auxilliary db files\n",
    "    #Making it work on windows\n",
    "    if platform.system()==\"Windows\":\n",
    "        #needs to call Cygwin for it work.\n",
    "        subprocess.call([\"hmmpress\",hmm_database])\n",
    "    else:\n",
    "        subprocess.call([\"hmmpress\",hmm_database])\n",
    "\n",
    "    return hmm_database\n",
    "\n",
    "\n",
    "def parallel_search_hmm_database(output_working_dir,hmm_database,seq_dir,cpus):\n",
    "    '''Performs a parallel search against the hmm database using hmmer.\n",
    "    Input:\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    '''\n",
    "    table_dir=os.path.join(output_working_dir,\"results_table\")\n",
    "    os.mkdir(table_dir)\n",
    "    def search_hmm_database(seq_file):\n",
    "        '''Workhorse which calls hmmer.'''\n",
    "        file_name=os.path.basename(seq_file)\n",
    "        file_name,ext=os.path.splitext(file_name)\n",
    "        domtbl=os.path.join(table_dir,file_name)\n",
    "        subprocess.call(['hmmscan','--domtblout',domtbl,hmm_database,seq_file])\n",
    "        return\n",
    "    #Only at most as many processes as cpus\n",
    "    N_cpus=min(cpus, multiprocessing.cpu_count())\n",
    "    \n",
    "    #Open a pool of workers for running hmmscan\n",
    "    pool=ThreadPool(N_cpus)\n",
    "    \n",
    "    #All relevant files for scanning against the hmm database\n",
    "    seq_file_iterator=glob.glob(os.path.join(seq_dir,\"*.fna\"))\n",
    "    print \"Beginning multithreaded use of hmmscan to make domtbls\"\n",
    "    results=pool.map(search_hmm_database,seq_file_iterator)\n",
    "    print \"The domtbls have finished being made.\"\n",
    "    \n",
    "    return table_dir\n",
    "\n",
    "def process_domtblout_data(table_dir,taxonomy_file):\n",
    "    output_dir=os.path.join(os.path.split(table_dir)[0],\"hmms_results\")\n",
    "    os.mkdir(output_dir)\n",
    "    #I still need to work out the default comment character and the header line number. THen,\n",
    "    #I have enough to runs this.\n",
    "    N_gene_hits,motif_hits_in_gene=hmm_hits_wf(table_dir, output_dir,taxonomy_file, 1,\"#\",None)\n",
    "    \n",
    "    return N_gene_hits,motif_hits_in_gene\n",
    "\n",
    "def parse_args():\n",
    "    '''Interface for making this hmm tool command line useable.'''\n",
    "\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-c\",\"--cpus\",help=\"Cpus to use for hmm search\",default=1)\n",
    "    parser.add_argument(\"-v\",\"--verbose\",help=\"**UNIMPLEMENTED** - Decided whether to have more descriptive output of current steps.\")\n",
    "    parser.add_argument('hmm_dir',help=\"A directory of hmms to scan\")\n",
    "    parser.add_argument('seq_dir',help=\"A directory of sequence files\")\n",
    "    parser.add_argument('output_dir',help=\"THe directory to make a project dir in\")\n",
    "    parser.add_argument('group_title',help=\"The name for the project directory.\")\n",
    "    parser.add_argument('database_dir',help=\"The directory containing the local kegg databases.\")\n",
    "    parser.add_argument('-o','--opt_item_file',help=\"A optional file indicating which hmms to extract from the hmm_dir\")\n",
    "    parser.add_argument('-b','--bin_taxa',help=\"A file containing a taxonomic pairing with some genomes\")\n",
    "    parser.add_argument('-x','--extra_items',help=\"The extra items to consider when reading the optional file.\")\n",
    "    args=parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main():\n",
    "    args=parse_args()\n",
    "    \n",
    "    hmm_processing_wf(args)\n",
    "    \n",
    "def hmm_processing_wf(args):\n",
    "    cpus=args.cpus\n",
    "    hmm_dir=args.hmm_dir\n",
    "    seq_dir=args.seq_dir\n",
    "    output_dir=args.output_dir\n",
    "    group_title=args.group_title\n",
    "    database_dir=args.database_dir\n",
    "    opt_item_file=args.opt_item_file\n",
    "    tax_file=args.bin_taxa\n",
    "    extras_file=args.extra_items\n",
    "    \n",
    "    kegg_hmms_wf(hmm_dir, output_dir, group_title, opt_item_file, extras_file,database_dir,seq_dir,cpus,tax_file)\n",
    "    return\n",
    "\n",
    "def hmmer_domtblout_parser(file_path,header_line,comment_char):\n",
    "    i=0\n",
    "    header_one_space_sep=[2,20]\n",
    "    line_one_space_sep=[2,-1]\n",
    "    regex_clean=re.compile(\"\\s{2,}\")\n",
    "    with open (file_path) as hmmer_hits:\n",
    "        for line in hmmer_hits:\n",
    "            if i==header_line:\n",
    "                yield list(itertools.chain(*[fields.split(\" \", 1) if i in header_one_space_sep else [fields] for i,fields in enumerate(regex_clean.split(line.strip())) ]))\n",
    "            elif not line.startswith(comment_char):\n",
    "                #print line[0:3]\n",
    "                #30 was chosen since there are 23 columns and hence if 1 char + sep per column then 46 chars\n",
    "                part_proc=regex_clean.split(line.strip())\n",
    "                for i in line_one_space_sep:\n",
    "                    part_proc[i]=part_proc[i].split(None,2)\n",
    "                \n",
    "                yield list(itertools.chain(*[ [item] if not isinstance(item,list) else item for item in part_proc]))\n",
    "            else:\n",
    "                pass\n",
    "            i+=1\n",
    "    \n",
    "def create_hmmer_domtblout_df(file_path,header_line,comment_char):\n",
    "    hmmer_file=hmmer_domtblout_parser(file_path,header_line,comment_char)\n",
    "    header=next(hmmer_file)\n",
    "    df=pd.DataFrame([\n",
    "            line for line in hmmer_file \n",
    "        ])\n",
    "    df.columns=header\n",
    "    return df\n",
    "\n",
    "def all_domtblout_df(file_dir,header_line,comment_char,optional_reg_cut):\n",
    "    repeat_dfs={}\n",
    "    i=0\n",
    "    for file_path in gb.glob(os.path.join(file_dir, \"*\")):\n",
    "        file_name=os.path.basename(file_path)\n",
    "        #print file_name\n",
    "        if isinstance(optional_reg_cut,type(None)):\n",
    "            file_id=file_name.replace(\".tsv\",\"\")\n",
    "        else:\n",
    "            file_id=file_name.replace(\".tsv\",\"\")\n",
    "            file_id=re.sub(optional_reg_cut,\"\",file_id)\n",
    "        repeat_dfs[file_id]=create_hmmer_domtblout_df(file_path,header_line,comment_char)\n",
    "        i+=1\n",
    "        if i%10==0:\n",
    "            print \"{0} files have been processed. The last was {1}\".format(i,file_id)\n",
    "    if len(repeat_dfs)==0:\n",
    "        print \"No files were loaded\"\n",
    "    return repeat_dfs\n",
    "\n",
    "def merge_repeat_dfs(df_dict):\n",
    "    df_list=[None]*len(df_dict)\n",
    "    i=0\n",
    "    for genome_id,df in df_dict.iteritems():\n",
    "        new_df=df\n",
    "        new_df['Genome_id']=genome_id\n",
    "        #new_df.rename(columns={0:'Gene_Name'},inplace=True)\n",
    "        df_list[i]=new_df\n",
    "        i+=1\n",
    "    merged_dict=pd.concat(df_list,axis=0)\n",
    "    merged_dict.index.names=[\"Gene_name\"]\n",
    "    cols = merged_dict.columns.tolist()\n",
    "    cols=cols[-1:]+cols[0:-1]\n",
    "    merged_dict=merged_dict[cols]\n",
    "    #merged_dict['Genome_id']=merged_dict['Genome_id'].str.strip(\"_genomic\").str.strip(\"aa_genes_unfiltered_\").str.strip(\"aa_genes_filtered_\")\n",
    "    #print merged_dict\n",
    "#    print merged_dict.ix[:,0]\n",
    "    return merged_dict\n",
    "\n",
    "def merge_repeat_dfs_wf(df_dict,output_file,taxonomy_file):\n",
    "    gene_level_hits=merge_repeat_dfs(df_dict)\n",
    "    gene_level_hits['Taxonomy']=gene_level_hits['Genome_id'].map(taxonomy_file)\n",
    "    cols = gene_level_hits.columns.tolist()\n",
    "    cols=[cols[0]]+cols[-1:]+cols[1:-1]\n",
    "    gene_level_hits=gene_level_hits[cols]\n",
    "    gene_level_hits.to_csv(output_file,sep=\"\\t\",index=True)\n",
    "    \n",
    "    return gene_level_hits\n",
    "    \n",
    "def construct_n_genes_hits(df_dict,all_columns):\n",
    "    genome_ids=df_dict.keys()\n",
    "    column_names=pd.unique(itertools.chain(*df_dict.itervalues()))\n",
    "    gene_count_df=pd.DataFrame(index=genome_ids,columns=all_columns)\n",
    "    gene_count_df.index.name=\"Genome_id\"\n",
    "    \n",
    "    for file_id, df in df_dict.iteritems():\n",
    "        for repeat_motif,count in df.iteritems():\n",
    "            gene_count_df.set_value(file_id,repeat_motif,count)\n",
    "            \n",
    "    return gene_count_df\n",
    "\n",
    "def process_gene_hits(complete_df_dict,output_file,all_motifs,taxonomy_file):\n",
    "    gene_hits={file_id: make_hmm_hits_to_gene_hits(df) for file_id, df in complete_df_dict.iteritems()}\n",
    "    gene_df=construct_n_genes_hits(gene_hits,all_motifs)\n",
    "    gene_df.reset_index(level=0,inplace=True)\n",
    "    #gene_df['Genome_id']=gene_df['Genome_id'].str.strip(\"_genomic\").str.strip(\"aa_genes_unfiltered_\").str.strip(\"aa_genes_filtered_\")\n",
    "    #print gene_df.ix[:,0]\n",
    "    #print taxonomy_file\n",
    "    gene_df['Taxonomy']=gene_df['Genome_id'].map(taxonomy_file)\n",
    "    cols = gene_df.columns.tolist()\n",
    "    cols=[cols[0]]+cols[-1:]+cols[1:-1]\n",
    "    gene_df=gene_df[cols]\n",
    "    #Add taxonomy information\n",
    "    gene_df.to_csv(output_file, sep=\"\\t\",index=False)\n",
    "    \n",
    "    return gene_df\n",
    "\n",
    "def hmm_hits_in_gene(df,all_columns):\n",
    "    genes_hit=pd.unique(df['query name'][False==pd.isnull(df['query name'])])\n",
    "    repeats_found=pd.unique(df['# target name'])\n",
    "    hit_df=pd.DataFrame(index=genes_hit,columns=all_columns)\n",
    "    hit_df=hit_df.fillna(0)\n",
    "    all_counts=df.groupby(['query name','# target name']).count()['of']\n",
    "    for ((contig,repeat_motif),count) in all_counts.iteritems():\n",
    "        hit_df.set_value(contig,repeat_motif,count)\n",
    "    print hit_df\n",
    "        \n",
    "    return hit_df\n",
    "\n",
    "def make_hmm_hits_to_gene_hits(df):\n",
    "    #Check for any columns with at least one hit, add all true values\n",
    "    #to get number of genes with that motif.\n",
    "    return (df>0).sum(axis=0)\n",
    "\n",
    "def get_all_target_values(df_dict):\n",
    "    target_values=[]\n",
    "    for genome_id, df in df_dict.iteritems():\n",
    "        target_values.append(df['# target name'])\n",
    "        \n",
    "    return pd.unique(pd.concat(target_values,axis=0))\n",
    "\n",
    "def hmm_hits_wf(input_dir, output_dir,taxonomy_file, header_line,comment_char,optional_reg_cut):\n",
    "    all_dfs=all_domtblout_df(input_dir,header_line,comment_char,optional_reg_cut)\n",
    "    #print \"These are all of the domtbl dfs\", all_dfs\n",
    "    all_target_ids=get_all_target_values(all_dfs)\n",
    "    #print \"These are all of the target ids,\", all_target_ids\n",
    "    motif_hits_in_gene={file_id: hmm_hits_in_gene(df,all_target_ids) for file_id,df in all_dfs.iteritems()}\n",
    "    genome_taxonomy=load_bin_names(taxonomy_file)\n",
    "    genome_taxonomy=defaultdict(lambda: \"No_predefined_Taxonomy\",genome_taxonomy)\n",
    "    #print \"This is the output_dir\", output_dir\n",
    "    N_gene_hits_file=os.path.join(output_dir,\"N_genes_with_hits.tsv\")\n",
    "    N_gene_hits=process_gene_hits(motif_hits_in_gene,N_gene_hits_file,all_target_ids,genome_taxonomy)\n",
    "    hits_per_gene_file=os.path.join(output_dir,\"hmm_hits_per_gene_per_genome.tsv\")\n",
    "    merged_hmm_hits=merge_repeat_dfs_wf(motif_hits_in_gene,hits_per_gene_file,genome_taxonomy)\n",
    "    \n",
    "    return N_gene_hits,motif_hits_in_gene\n",
    "    \n",
    "def load_bin_names(tax_file):\n",
    "    #Load bin_ids and bins_taxonomy from file.\n",
    "    bin_names={}\n",
    "    bin_pair=[]\n",
    "    with open(tax_file,'r') as bin_tax_pair:\n",
    "        bin_tax_pair.readline()\n",
    "        for line in bin_tax_pair:\n",
    "            bin_pair.append(tuple(line.strip().split(\"\\t\")))\n",
    "\n",
    "    bin_names={bin_id:taxonomy for taxonomy, bin_id in bin_pair}\n",
    "    return bin_names\n",
    "\n",
    "def load_fasta_file():\n",
    "    \n",
    "    \n",
    "def flatten_fasta_file():\n",
    "    \n",
    "    return\n",
    "\n",
    "def extract_regions(contig, fasta, positions):\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "WindowsError",
     "evalue": "[Error 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0b819012b29b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"symbioses_test_3\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnew_directory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextract_local_hmms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmm_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt_item_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmake_hmm_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtable_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_search_hmm_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_working_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmm_database\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c1e1c86c4f87>\u001b[0m in \u001b[0;36mmake_hmm_database\u001b[1;34m(working_dir)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"Windows\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m#needs to call Cygwin for it work.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hmmpress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmm_database\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hmmpress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmm_database\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m--> 522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                                 errread, errwrite)\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    959\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mpywintypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                 \u001b[1;31m# Translate pywintypes.error to WindowsError, which is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWindowsError\u001b[0m: [Error 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "#opt_item_file=\"C:\\Users\\Baker\\Google Drive\\Honours\\HMM_searches\\HmmToolTest\\optional_items.txt\"\n",
    "opt_item_file=None\n",
    "extras_file=None\n",
    "\n",
    "hmm_dir=os.path.join(*[core,g_drive,\"HMM_searches\",\"Symbioses_test\",\"Hmms\"])#\"C:\\Users\\Baker\\Google Drive\\Honours\\HMM_searches\\Symbioses_test\\Hmms\"\n",
    "output_dir=os.path.join(*[core,g_drive,\"HMM_searches\"])#\"C:\\Users\\Baker\\Google Drive\\Honours\\HMM_searches\"\n",
    "if not isinstance(opt_item_file,type(None)):\n",
    "    opt_item_file=load_optional_items(opt_item_file,extras_file, database_dir)\n",
    "print opt_item_file\n",
    "project_name=\"symbioses_test_3\"\n",
    "new_directory=extract_local_hmms(hmm_dir,output_dir,project_name,opt_item_file)\n",
    "make_hmm_database(new_directory)\n",
    "table_dir=parallel_search_hmm_database(output_working_dir,hmm_database,seq_dir,cpus)\n",
    "\n",
    "gene_hits_dir=os.path.join(output_dir,\"gene_hits\")\n",
    "\n",
    "hmm_hits_wf(table_dir, gene_hits_dir,tax_file, 1,\"#\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of all tips in decorated tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named dendropy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3248c2a2d827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdendropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtree_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"enriched_hits\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Test_trees\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtree_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtree_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"gtdb.decorated.tree\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named dendropy"
     ]
    }
   ],
   "source": [
    "import dendropy\n",
    "\n",
    "tree_dir=os.path.join(*[output_dir, \"enriched_hits\",\"Test_trees\"])\n",
    "tree_file=os.path.join(*[tree_dir,\"gtdb.decorated.tree\"])\n",
    "\n",
    "tree=dendropy.Tree.get(path=tree_file,schema=\"newick\")\n",
    "\n",
    "def taxonomic_ranks():\n",
    "    return ['d__','p__','c__','o__','f__','g__','s__'] #temporarily removed 'k__'\n",
    "\n",
    "def taxonomic_rank(tax_id):\n",
    "    \n",
    "    return \n",
    "    \n",
    "def is_higher_rank(r1,r2):\n",
    "    return rank_relation(r1,r2,\"higher\")\n",
    "\n",
    "def rank_relation(r1,r2,rel):\n",
    "    tax_levels=taxonomic_ranks()\n",
    "    #print r1\n",
    "    #print r2\n",
    "    r1_level=None\n",
    "    r2_level=None\n",
    "    for i, rank in enumerate(tax_levels):\n",
    "        search_pat=rank+\"[^;]\"\n",
    "        #print rank\n",
    "        match_1=re.search(search_pat,r1)\n",
    "        match_2=re.search(search_pat,r2)\n",
    "        if match_1 and r1_level==None:\n",
    "            r1_level=i\n",
    "        if match_2 and r2_level==None:\n",
    "            r2_level=i\n",
    "    #print \"levels:\",r1_level,r2_level\n",
    "    if rel==\"higher\":\n",
    "        if r1_level<r2_level:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    elif rel==\"lower\":\n",
    "        if r1_level>r2_level:\n",
    "            return True\n",
    "        else:\n",
    "            return False        \n",
    "    elif rel==\"same\":\n",
    "        if r1_level==r2_level:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        print \"Not a valid relation option.\"\n",
    "        return\n",
    "    \n",
    "def is_lower_rank(r1,r2):\n",
    "    return rank_relation(r1,r2,\"lower\")\n",
    "\n",
    "def is_same_rank(r1,r2):\n",
    "    return rank_relation(r1,r2,\"same\")\n",
    "    \n",
    "def classify_all_tips(tree):\n",
    "    tax_string_dict={}\n",
    "    #cur_taxon=[]\n",
    "    cur_label=''\n",
    "    end_core=''\n",
    "    for node in tree.preorder_node_iter():\n",
    "        cur_tax=node.taxon\n",
    "        test_label=node.label\n",
    "        if isinstance(cur_tax,type(None)) and isinstance(test_label,type(None)):\n",
    "            pass\n",
    "        elif not isinstance(cur_tax,type(None)):\n",
    "            cur_tax=cur_tax.label\n",
    "            tax_string_dict[cur_tax]=tax_string(cur_tax)\n",
    "            if cur_label!='':\n",
    "                #print cur_tax\n",
    "                #print cur_label\n",
    "                tax_string_dict[cur_tax].add(cur_label)\n",
    "        elif not isinstance(test_label,type(None)):\n",
    "            if is_higher_rank(cur_label,test_label):\n",
    "                #print \"Considering higher rank\", test_label\n",
    "                cur_label=replace_tax_def(cur_label,test_label,'higher')\n",
    "                #cur_label.strip().strip(\";\").strip()\n",
    "            elif is_same_rank(cur_label,test_label):\n",
    "                #print \"Considering same rank\", test_label\n",
    "                cur_label=replace_tax_def(cur_label,test_label,'same')\n",
    "                #cur_label.strip().strip(\";\").strip()\n",
    "            elif is_lower_rank(cur_label,test_label):\n",
    "                #print \"Considering lower rank\", test_label\n",
    "                cur_label=test_label\n",
    "                #cur_label.strip().strip(\";\").strip()\n",
    "            else:\n",
    "                print \"Ah, an error. What can I do?\", cur_label, test_label\n",
    "                \n",
    "    return tax_string_dict\n",
    "\n",
    "def replace_tax_def(full_tax_string, ending_core, rel):\n",
    "    #print \"The taxa being considered\", full_tax_string\n",
    "    tax_levels=taxonomic_ranks()\n",
    "    tax_dict={rank:'' for rank in tax_levels}\n",
    "    \n",
    "    if full_tax_string==\"\":\n",
    "        obs_level=[]\n",
    "    else:\n",
    "        obs_level=full_tax_string.strip().strip(\";\").split(';')\n",
    "        #print obs_level\n",
    "        obs_level=[(det_rank(tax),tax) for tax in obs_level]\n",
    "    #obs_level=zip(obs_level[0::2],obs_level[1::2])\n",
    "    tent_level=[el.strip() for el in ending_core.strip().split(';')]\n",
    "    #print \"tentative level:\", tent_level\n",
    "    tent_level=[(det_rank(tax),tax) for tax in tent_level]\n",
    "    #tent_level=zip(tent_level[0::2],tent_level[1::2])\n",
    "    if rel==\"higher\" or rel==\"same\":\n",
    "        last_rank=None\n",
    "        for (rank, name) in obs_level:\n",
    "            #key=rank.strip(\";\").strip()+\"__\"\n",
    "            tax_dict[rank]=name.strip().strip(rank)\n",
    "        for (rank, name) in tent_level:\n",
    "            #key=rank.strip(\";\").strip()+\"__\"\n",
    "            tax_dict[rank]=name.strip().strip(rank)\n",
    "            last_rank=rank\n",
    "        for rank in lower_ranks(last_rank):\n",
    "            tax_dict[rank]=''\n",
    "\n",
    "    new_tax_string=[]\n",
    "    for rank in tax_levels:\n",
    "        new_tax_string.append(rank+tax_dict[rank])\n",
    "    return \";\".join(new_tax_string)\n",
    "\n",
    "def lower_ranks(rank):\n",
    "    ranks=taxonomic_ranks()\n",
    "    if rank not in ranks or isinstance(rank,type(None)):\n",
    "        return []\n",
    "    level=ranks.index(rank)\n",
    "    return ranks[(level+1):]\n",
    "\n",
    "def det_rank(one_tax):\n",
    "    ranks=taxonomic_ranks()\n",
    "    #print \"The is the tax which made it here,\", one_tax, type(one_tax)\n",
    "    cur_rank=[rank for rank in ranks if one_tax.startswith(rank)][0]\n",
    "    return cur_rank\n",
    "\n",
    "def fill_taxonomic_gaps(tax_file, completed_tax_strings):\n",
    "    \n",
    "    return\n",
    "\n",
    "class tax_string(object):\n",
    "    def __init__(self,taxon):\n",
    "        self.ranks=['d__','p__','c__','o__','f__','g__','s__'] #temporarily removed 'k__'\n",
    "        self.tax_string={rank:'' for rank in self.ranks}\n",
    "        self.name=taxon\n",
    "        self.tax=\";\".join(self.ranks)\n",
    "        \n",
    "    def add(self,gg_tax):\n",
    "        if not isinstance(gg_tax,type(None)) or gg_tax!='':\n",
    "            levels=[tax_rank.strip() for tax_rank in gg_tax.strip().split(\";\")]\n",
    "            for level in levels:\n",
    "                if level!='':\n",
    "                    try:\n",
    "                        cur_rank=self.det_rank(level)\n",
    "                    except:\n",
    "                        print \"The broken level:\", level, gg_tax\n",
    "                        raise\n",
    "                    if self.tax_string[cur_rank]!='':\n",
    "                        print self.name, self.tax\n",
    "                        print \"The current item:\", self.tax_string[cur_rank]\n",
    "                        print \"The new item:\", gg_tax\n",
    "                        raise TaxOverlapError('This rank has already been defined.')\n",
    "                    else:\n",
    "                        self.tax_string[cur_rank]=level\n",
    "\n",
    "                        tax_str=[]\n",
    "                        for rank in self.ranks:\n",
    "                            tax_str.append(self.tax_string[rank])\n",
    "                        self.tax=\";\".join(tax_str)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def det_rank(self,one_tax):\n",
    "        #print \"The is the tax which made it here,\", one_tax, type(one_tax)\n",
    "        cur_rank=[rank for rank in self.ranks if one_tax.startswith(rank)][0]\n",
    "        return cur_rank\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.tax\n",
    "    \n",
    "    def ret_pair(self):\n",
    "        return (self.name,self.tax)\n",
    "        \n",
    "class TaxOverlapError(Exception):\n",
    "    '''Base class error - indicates a taxonomic rank was already defined before trying to add it'''\n",
    "    pass\n",
    "\n",
    "def write_genome_taxonomies(tax_string_dict,output_file):\n",
    "    \n",
    "    df=make_tax_df(tax_string_dict)\n",
    "    df.to_csv(output_file,header=True,sep=\"\\t\",index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_tax_df(tax_string_dict):\n",
    "    df=pd.DataFrame([\n",
    "        [name, tax_string.tax] for name,tax_string in tax_string_dict.iteritems()\n",
    "    ])\n",
    "    df.columns=[\"Genome_name\",\"Tax_string\"]\n",
    "    return df\n",
    "    \n",
    "def fill_missing_taxonomies(ref_tax_file, tax_df):\n",
    "    ranks=taxonomic_ranks()\n",
    "    with open(ref_tax_file,'r') as tax_file:\n",
    "        tax=\"\\n\".join(tax_file.readlines())\n",
    "    split_df=split_taxonomy(tax_df)\n",
    "    for rank in ranks:\n",
    "        observed_ranks=pd.unique(split_df[rank])\n",
    "        for obs_rank in observed_ranks:\n",
    "            if obs_rank!=rank:\n",
    "                search_reg=\"(?:\\t).*?{0}\".format(obs_rank)\n",
    "                match=re.search(search_reg,tax)\n",
    "                if match:\n",
    "                    upper_tax=match.group()\n",
    "                    levels=[el.strip() for el in upper_tax.split(\";\")]\n",
    "                    interesting_levels=levels[:-1] #Exclude the level searched for.\n",
    "                    for tax_match in interesting_levels:\n",
    "                        match_rank=tax_match.split(\"__\")[0]+\"__\"\n",
    "                        split_df.ix[split_df[rank]==obs_rank,match_rank]=tax_match\n",
    "\n",
    "    return split_df\n",
    "\n",
    "def split_taxonomy(tax_df):\n",
    "    col_names=taxonomic_ranks()\n",
    "    new_df=tax_df.ix[:,1].str.split(\";\",expand=True)\n",
    "    #print new_df\n",
    "    new_df.columns=col_names\n",
    "    new_df=pd.concat([new_tax_df['Genome_name'],m],axis=1)\n",
    "    return new_df\n",
    "    \n",
    "def taxonomy_reclassify_wf(tree_file,output_core,reference_tax_file):\n",
    "    ranks=taxonomic_ranks()\n",
    "    ttree=dendropy.Tree.get(path=tree_file,schema=\"newick\")\n",
    "    all_taxa=classify_all_tips(tree)\n",
    "    tax_df=write_genome_taxonomies(all_taxa, output_core+\"unfilled_taxonomies.tsv\")\n",
    "    split_df=fill_missing_taxonomies(reference_tax_file, tax_df)\n",
    "    joined_df=pd.concat([split_df.ix[:,0],split_df[ranks].apply(lambda x: ';'.join(x),axis=1)],axis=1)\n",
    "    joined_df.columns=['Genome_name','Phylogeny_string']\n",
    "    \n",
    "    joined_df.to_csv(output_core+\"backfilled_taxonomies.tsv\",index=False,header=True, sep=\"\\t\")\n",
    "    \n",
    "    return joined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_name</th>\n",
       "      <th>Phylogeny_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U_35948</td>\n",
       "      <td>d__Bacteria;p__Limnochordaeota;c__SHA-98;o__;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RS_GCF_001476715.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U_35949</td>\n",
       "      <td>d__Bacteria;p__Desulfovibrionaeota;c__Syntroph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RS_GCF_000293245.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U_49765</td>\n",
       "      <td>d__Bacteria;p__Hydrogenedentes;c__;o__;f__;g__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U_49764</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Clostridia;o__Clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U_49767</td>\n",
       "      <td>d__Bacteria;p__Desulfovibrionaeota;c__Desulfob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U_49761</td>\n",
       "      <td>d__Bacteria;p__MBNT15aeota;c__MBNT15ia;o__MBNT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U_49760</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U_49763</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U_49762</td>\n",
       "      <td>d__Bacteria;p__Desulfovibrionaeota;c__Syntroph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RS_GCF_000702605.1</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Bacilli;o__Exiguo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB_GCA_001544815.1</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Actinobacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>U_47689</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RS_GCF_001466505.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RS_GCF_001278515.1</td>\n",
       "      <td>d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RS_GCF_000204255.1</td>\n",
       "      <td>d__Bacteria;p__Verrucomicrobia;c__Chlamydiia;o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RS_GCF_000236065.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RS_GCF_001017575.1</td>\n",
       "      <td>d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RS_GCF_000011025.1</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Actinobacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RS_GCF_000185985.2</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U_51415</td>\n",
       "      <td>d__Bacteria;p__GR-WP33-30aeota;c__GR-WP33-30ia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>U_51412</td>\n",
       "      <td>d__Bacteria;p__GR-WP33-30aeota;c__GR-WP33-30ia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>U_51410</td>\n",
       "      <td>d__Bacteria;p__Patescibacteria;c__Parcubacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U_51418</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Bacilli;o__Mycopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RS_GCF_000733115.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS_GCF_000816185.1</td>\n",
       "      <td>d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RS_GCF_000208565.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RS_GCF_001463465.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RS_GCF_000292915.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22035</th>\n",
       "      <td>U_52472</td>\n",
       "      <td>d__;p__;c__Gammaproteobacteria_1;o__SG8_30;f__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22036</th>\n",
       "      <td>RS_GCF_000949135.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22037</th>\n",
       "      <td>RS_GCF_001421745.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22038</th>\n",
       "      <td>RS_GCF_000185045.1</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22039</th>\n",
       "      <td>RS_GCF_000169355.1</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22040</th>\n",
       "      <td>RS_GCF_000263795.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22041</th>\n",
       "      <td>U_46222</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Actinobacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22042</th>\n",
       "      <td>RS_GCF_000429965.1</td>\n",
       "      <td>d__Bacteria;p__Desulfovibrionaeota;c__Desulfov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22043</th>\n",
       "      <td>RS_GCF_001543205.1</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22044</th>\n",
       "      <td>GB_GCA_000998135.1</td>\n",
       "      <td>d__Bacteria;p__Patescibacteria;c__Parcubacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22045</th>\n",
       "      <td>RS_GCF_000803625.1</td>\n",
       "      <td>d__Bacteria;p__Patescibacteria;c__Saccharimoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>RS_GCF_001279655.1</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Actinobacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>GB_GCA_001399705.1</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__Chloroflexia;o__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22048</th>\n",
       "      <td>RS_GCF_000702325.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22049</th>\n",
       "      <td>U_44418</td>\n",
       "      <td>d__Bacteria;p__Verrucomicrobia;c__Verrucomicro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22050</th>\n",
       "      <td>U_46484</td>\n",
       "      <td>d__Bacteria;p__Cyanobacteria;c__Oxyphotobacter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22051</th>\n",
       "      <td>U_46481</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22052</th>\n",
       "      <td>U_46480</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22053</th>\n",
       "      <td>U_46483</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22054</th>\n",
       "      <td>U_46482</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22055</th>\n",
       "      <td>U_44410</td>\n",
       "      <td>d__Bacteria;p__Cyanobacteria;c__Melainabacteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22056</th>\n",
       "      <td>U_44411</td>\n",
       "      <td>d__Bacteria;p__Spirochaetes;c__Spirochaetia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22057</th>\n",
       "      <td>U_44412</td>\n",
       "      <td>d__Bacteria;p__Spirochaetes;c__Spirochaetia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22058</th>\n",
       "      <td>U_44413</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Clostridia;o__Osc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22059</th>\n",
       "      <td>U_46489</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Clostridia;o__Lac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22060</th>\n",
       "      <td>U_44415</td>\n",
       "      <td>d__Bacteria;p__Firmicutes;c__Bacilli;o__Mycopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22061</th>\n",
       "      <td>U_44416</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22062</th>\n",
       "      <td>U_44417</td>\n",
       "      <td>d__Bacteria;p__Verrucomicrobia;c__Verrucomicro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22063</th>\n",
       "      <td>GB_GCA_001507555.1</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22064</th>\n",
       "      <td>RS_GCF_000165635.1</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Actinobacteri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Genome_name                                   Phylogeny_string\n",
       "0                 U_35948  d__Bacteria;p__Limnochordaeota;c__SHA-98;o__;f...\n",
       "1      RS_GCF_001476715.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "2                 U_35949  d__Bacteria;p__Desulfovibrionaeota;c__Syntroph...\n",
       "3      RS_GCF_000293245.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "4                 U_49765  d__Bacteria;p__Hydrogenedentes;c__;o__;f__;g__...\n",
       "5                 U_49764  d__Bacteria;p__Firmicutes;c__Clostridia;o__Clo...\n",
       "6                 U_49767  d__Bacteria;p__Desulfovibrionaeota;c__Desulfob...\n",
       "7                 U_49761  d__Bacteria;p__MBNT15aeota;c__MBNT15ia;o__MBNT...\n",
       "8                 U_49760  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "9                 U_49763  d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...\n",
       "10                U_49762  d__Bacteria;p__Desulfovibrionaeota;c__Syntroph...\n",
       "11     RS_GCF_000702605.1  d__Bacteria;p__Firmicutes;c__Bacilli;o__Exiguo...\n",
       "12     GB_GCA_001544815.1  d__Bacteria;p__Actinobacteria;c__Actinobacteri...\n",
       "13                U_47689  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "14     RS_GCF_001466505.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "15     RS_GCF_001278515.1  d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...\n",
       "16     RS_GCF_000204255.1  d__Bacteria;p__Verrucomicrobia;c__Chlamydiia;o...\n",
       "17     RS_GCF_000236065.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "18     RS_GCF_001017575.1  d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...\n",
       "19     RS_GCF_000011025.1  d__Bacteria;p__Actinobacteria;c__Actinobacteri...\n",
       "20     RS_GCF_000185985.2  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "21                U_51415  d__Bacteria;p__GR-WP33-30aeota;c__GR-WP33-30ia...\n",
       "22                U_51412  d__Bacteria;p__GR-WP33-30aeota;c__GR-WP33-30ia...\n",
       "23                U_51410  d__Bacteria;p__Patescibacteria;c__Parcubacteri...\n",
       "24                U_51418  d__Bacteria;p__Firmicutes;c__Bacilli;o__Mycopl...\n",
       "25     RS_GCF_000733115.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "26     RS_GCF_000816185.1  d__Bacteria;p__Epsilonmicrobia;c__Campylobacte...\n",
       "27     RS_GCF_000208565.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "28     RS_GCF_001463465.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "29     RS_GCF_000292915.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "...                   ...                                                ...\n",
       "22035             U_52472  d__;p__;c__Gammaproteobacteria_1;o__SG8_30;f__...\n",
       "22036  RS_GCF_000949135.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "22037  RS_GCF_001421745.1  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...\n",
       "22038  RS_GCF_000185045.1  d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactob...\n",
       "22039  RS_GCF_000169355.1  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22040  RS_GCF_000263795.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "22041             U_46222  d__Bacteria;p__Actinobacteria;c__Actinobacteri...\n",
       "22042  RS_GCF_000429965.1  d__Bacteria;p__Desulfovibrionaeota;c__Desulfov...\n",
       "22043  RS_GCF_001543205.1  d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactob...\n",
       "22044  GB_GCA_000998135.1  d__Bacteria;p__Patescibacteria;c__Parcubacteri...\n",
       "22045  RS_GCF_000803625.1  d__Bacteria;p__Patescibacteria;c__Saccharimoni...\n",
       "22046  RS_GCF_001279655.1  d__Bacteria;p__Actinobacteria;c__Actinobacteri...\n",
       "22047  GB_GCA_001399705.1  d__Bacteria;p__Chloroflexi;c__Chloroflexia;o__...\n",
       "22048  RS_GCF_000702325.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "22049             U_44418  d__Bacteria;p__Verrucomicrobia;c__Verrucomicro...\n",
       "22050             U_46484  d__Bacteria;p__Cyanobacteria;c__Oxyphotobacter...\n",
       "22051             U_46481  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22052             U_46480  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22053             U_46483  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22054             U_46482  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22055             U_44410  d__Bacteria;p__Cyanobacteria;c__Melainabacteri...\n",
       "22056             U_44411  d__Bacteria;p__Spirochaetes;c__Spirochaetia;o_...\n",
       "22057             U_44412  d__Bacteria;p__Spirochaetes;c__Spirochaetia;o_...\n",
       "22058             U_44413  d__Bacteria;p__Firmicutes;c__Clostridia;o__Osc...\n",
       "22059             U_46489  d__Bacteria;p__Firmicutes;c__Clostridia;o__Lac...\n",
       "22060             U_44415  d__Bacteria;p__Firmicutes;c__Bacilli;o__Mycopl...\n",
       "22061             U_44416  d__Bacteria;p__Bacteroidetes;c__Bacteroidia;o_...\n",
       "22062             U_44417  d__Bacteria;p__Verrucomicrobia;c__Verrucomicro...\n",
       "22063  GB_GCA_001507555.1  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
       "22064  RS_GCF_000165635.1  d__Bacteria;p__Actinobacteria;c__Actinobacteri...\n",
       "\n",
       "[22065 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_reclassify_wf(tree_file,os.path.join(*[core,g_drive,\"tools\",\"EnrichM\",\"Taxonomies\",\"new_20160821_pluteadata_\"]) ,os.path.join(*[core,g_drive,\"tools\",\"EnrichM\",\"Taxonomies\",\"20160821_gtdb_taxonomy_file.tsv\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C00001',\n",
       " 'C00002',\n",
       " 'C00003',\n",
       " 'C00004',\n",
       " 'C00005',\n",
       " 'C00006',\n",
       " 'C00007',\n",
       " 'C00008',\n",
       " 'C00009',\n",
       " 'C00010',\n",
       " 'C00011',\n",
       " 'C00013',\n",
       " 'C00014',\n",
       " 'C00015',\n",
       " 'C00020',\n",
       " 'C00022',\n",
       " 'C00023',\n",
       " 'C00027',\n",
       " 'C00034',\n",
       " 'C00035',\n",
       " 'C00038',\n",
       " 'C00044',\n",
       " 'C00050',\n",
       " 'C00054',\n",
       " 'C00055',\n",
       " 'C00060',\n",
       " 'C00063',\n",
       " 'C00068',\n",
       " 'C00070',\n",
       " 'C00075',\n",
       " 'C00076',\n",
       " 'C00080',\n",
       " 'C00081',\n",
       " 'C00104',\n",
       " 'C00105',\n",
       " 'C00112',\n",
       " 'C00144',\n",
       " 'C01330',\n",
       " 'C01342',\n",
       " 'C03028',\n",
       " 'C14818',\n",
       " 'C14819',\n",
       " 'C19610'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_db_entry(db_entry,entry_type):\n",
    "    if entry_type==\"rn:rp\":\n",
    "        db_entry=db_entry.strip()\n",
    "        values=db_entry.split()\n",
    "        RP_ID=values[0]\n",
    "        CPD_PAIRS=values[1]\n",
    "        #processed_entry=\"\\t\".join([RP_ID,CPD_PAIRS])\n",
    "        return RP_ID,CPD_PAIRS\n",
    "    elif entry_type==\"mo:rn\":\n",
    "        pass\n",
    "    elif entry_type==\"rn:rp:cpd\":\n",
    "        pass\n",
    "    return processed_entry\n",
    "\n",
    "def make_local_complete_reaction_rpair_db(database_dir):\n",
    "    '''Creates a local database of the module definitions.'''\n",
    "    all_modules=load_readable_names(database_dir,[\"reaction\"],False)[\"reaction\"].keys()\n",
    "    kc=kegg.KeggClientRest()\n",
    "    entries=defaultdict(dict)\n",
    "    max_len=10\n",
    "    print \"There are a total of {0} reactions to parse\".format(len(all_modules))\n",
    "    N_modules=len(all_modules)\n",
    "    for i in xrange(0,N_modules,max_len):\n",
    "        if N_modules-i<max_len:\n",
    "            n_entries=N_modules-i\n",
    "        else:\n",
    "            n_entries=max_len      \n",
    "        query=\"+\".join(all_modules[i:i+n_entries])\n",
    "        kegg_entries=kc.get_entry(query)\n",
    "\n",
    "        hits=re.finditer(\"(?:RPAIR\\s)((.|\\n)*?)(?:[A-Z/]{3,})\",kegg_entries)\n",
    "        hits=[hit.group(1).strip() for hit in hits] #Remove captured newline character and ensure that it is not a tuple\n",
    "        print i, i+max_len-1,\"n_hits:{0}\".format(len(hits))\n",
    "        #if len(hits)!=max_len:\n",
    "        #    print m\n",
    "        processed_hits=[]\n",
    "        for module, db_entry in itertools.izip(all_modules[i:i+10],hits):\n",
    "            #print \"The database entry\", db_entry\n",
    "            for entry in db_entry.split(\"\\n\"):\n",
    "                #print \"An individual RP entry\", entry\n",
    "                rp_id,cpd_links=process_db_entry(entry,\"rn:rp\")\n",
    "                processed_hits.append(rp_id)\n",
    "                #definition.strip().replace(\" --\",\" \").replace(\"-- \",\" \").replace(\"  \",\" \").strip()\n",
    "                entries[module][rp_id]=cpd_links\n",
    "        #These post_processed modules should be modules defined in terms of other modules.\n",
    "        if i%1000==0:\n",
    "            kc=kegg.KeggClientRest()\n",
    "            #print module\n",
    "            print hits\n",
    "            print processed_hits\n",
    "            #print kegg_entries\n",
    "    temp_entries=entries\n",
    "    print \"{0} reaction rpair info pairs were recovered\".format(len(entries))\n",
    "                \n",
    "    #df=pd.DataFrame([\n",
    "    #        [module,entry] for module,entry in entries.iteritems()\n",
    "    #    ])\n",
    "    try:\n",
    "    df=pd.DataFrame([\n",
    "            [reaction, rp_id, cpds] for reaction, rpairs in rp_pair_data.iteritems() for rp_id, cpds in entries.iteritems()\n",
    "        ])\n",
    "        df.columns=[\"Reaction_id\",\"reaction_definition\",'cpd_pairs']\n",
    "        df.to_csv(os.path.join(database_dir,\"Module_rn_rp_full_reaction_pairs.tsv\"),sep=\"\\t\",index=None)\n",
    "    except:\n",
    "        return entries\n",
    "    return df\n",
    "\n",
    "def make_local_complete_rpair_cpd_db(database_dir):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def load_local_rn_rp_cpd_db(database_dir):\n",
    "    infile=os.path.join(database_dir,\"Module_rn_rp_cpd_reaction_pairs.tsv\")\n",
    "    old_df=pd.read_csv(infile, sep=\"\\t\",index_col=[0,1])\n",
    "    return old_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame([\n",
    "        [reaction, rp_id, cpds] for reaction, rpairs in rp_pair_data.iteritems() for rp_id, cpds in rpairs.iteritems()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns=[\"Reaction_id\",\"reaction_definition\",\"compound_pair\"]\n",
    "df.to_csv(os.path.join(database_dir,\"Module_rn_rp_full_reaction_pairs.tsv\"),sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile=os.path.join(database_dir,\"Module_rn_rp_cpd_reaction_pairs.tsv\")\n",
    "old_df=pd.read_csv(infile, sep=\"\\t\",index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C00015\n"
     ]
    }
   ],
   "source": [
    "for i in old_df.loc[\"R06208\"].loc[\"C00029\"].values:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Reaction_id    cpd1    cpd2\n",
      "0      R06208  C00029  C00015\n",
      "  Reaction_id    cpd1    cpd2\n",
      "0      R06208  C00015  C00029\n"
     ]
    }
   ],
   "source": [
    "red_df=df.iloc[:,[0,2]]\n",
    "red_df[\"cpd1\"],red_df['cpd2']=zip(*df[\"compound_pair\"].str.split(\"_\").tolist())\n",
    "#print red_df\n",
    "del red_df['compound_pair']\n",
    "new_df=red_df.iloc[:,[0,2,1]]\n",
    "new_df.columns=red_df.columns\n",
    "print new_df.ix[new_df.iloc[:,0]=='R06208',]\n",
    "#print red_df.ix[red_df.iloc[:,0]=='R06208',]\n",
    "#whole_df=pd.concat([new_df,red_df])\n",
    "whole_df.to_csv(os.path.join(database_dir,\"Module_rn_rp_cpd_reaction_pairs.tsv\"),sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 10235 reactions to parse\n",
      "0 9 n_hits:2\n",
      "['RP00012  C00015_C00029 main [RC:RC00005]', 'RP00144  C00010_C00223 main [RC:RC00004]\\n            RP12154  C16312_C16351 main [RC:RC00041]']\n",
      "['RP00012', 'RP00144', 'RP12154']\n",
      "10 19 n_hits:9\n",
      "20 29 n_hits:10\n",
      "30 39 n_hits:9\n",
      "40 49 n_hits:10\n",
      "50 59 n_hits:10\n",
      "60 69 n_hits:9\n",
      "70 79 n_hits:9\n",
      "80 89 n_hits:10\n",
      "90 99 n_hits:10\n",
      "100 109 n_hits:10\n",
      "110 119 n_hits:10\n",
      "120 129 n_hits:10\n",
      "130 139 n_hits:10\n",
      "140 149 n_hits:10\n",
      "150 159 n_hits:10\n",
      "160 169 n_hits:10\n",
      "170 179 n_hits:10\n",
      "180 189 n_hits:9\n",
      "190 199 n_hits:9\n",
      "200 209 n_hits:10\n",
      "210 219 n_hits:10\n",
      "220 229 n_hits:10\n",
      "230 239 n_hits:0\n",
      "240 249 n_hits:9\n",
      "250 259 n_hits:2\n",
      "260 269 n_hits:10\n",
      "270 279 n_hits:10\n",
      "280 289 n_hits:10\n",
      "290 299 n_hits:10\n",
      "300 309 n_hits:9\n",
      "310 319 n_hits:8\n",
      "320 329 n_hits:7\n",
      "330 339 n_hits:9\n",
      "340 349 n_hits:8\n",
      "350 359 n_hits:9\n",
      "360 369 n_hits:3\n",
      "370 379 n_hits:10\n",
      "380 389 n_hits:10\n",
      "390 399 n_hits:10\n",
      "400 409 n_hits:10\n",
      "410 419 n_hits:10\n",
      "420 429 n_hits:9\n",
      "430 439 n_hits:10\n",
      "440 449 n_hits:8\n",
      "450 459 n_hits:8\n",
      "460 469 n_hits:10\n",
      "470 479 n_hits:10\n",
      "480 489 n_hits:9\n",
      "490 499 n_hits:10\n",
      "500 509 n_hits:10\n",
      "510 519 n_hits:10\n",
      "520 529 n_hits:9\n",
      "530 539 n_hits:8\n",
      "540 549 n_hits:10\n",
      "550 559 n_hits:10\n",
      "560 569 n_hits:10\n",
      "570 579 n_hits:6\n",
      "580 589 n_hits:6\n",
      "590 599 n_hits:9\n",
      "600 609 n_hits:10\n",
      "610 619 n_hits:9\n",
      "620 629 n_hits:5\n",
      "630 639 n_hits:10\n",
      "640 649 n_hits:9\n",
      "650 659 n_hits:10\n",
      "660 669 n_hits:10\n",
      "670 679 n_hits:10\n",
      "680 689 n_hits:9\n",
      "690 699 n_hits:10\n",
      "700 709 n_hits:9\n",
      "710 719 n_hits:10\n",
      "720 729 n_hits:5\n",
      "730 739 n_hits:6\n",
      "740 749 n_hits:10\n",
      "750 759 n_hits:10\n",
      "760 769 n_hits:9\n",
      "770 779 n_hits:10\n",
      "780 789 n_hits:9\n",
      "790 799 n_hits:9\n",
      "800 809 n_hits:10\n",
      "810 819 n_hits:8\n",
      "820 829 n_hits:9\n",
      "830 839 n_hits:10\n",
      "840 849 n_hits:10\n",
      "850 859 n_hits:10\n",
      "860 869 n_hits:10\n",
      "870 879 n_hits:10\n",
      "880 889 n_hits:10\n",
      "890 899 n_hits:5\n",
      "900 909 n_hits:5\n",
      "910 919 n_hits:10\n",
      "920 929 n_hits:10\n",
      "930 939 n_hits:10\n",
      "940 949 n_hits:10\n",
      "950 959 n_hits:10\n",
      "960 969 n_hits:10\n",
      "970 979 n_hits:10\n",
      "980 989 n_hits:9\n",
      "990 999 n_hits:10\n",
      "1000 1009 n_hits:4\n",
      "['RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP11591  C05668_C05989 main [RC:RC00087]', 'RP02894  C01124_C01780 main [RC:RC00893]', 'RP02893  C01124_C02140 main [RC:RC00257]', 'RP00025  C00051_C00127 cofac [RC:RC00011]\\n            RP05009  C07097_C07099 main [RC:RC01363]']\n",
      "['RP00001', 'RP11591', 'RP02894', 'RP02893', 'RP00025', 'RP05009']\n",
      "1010 1019 n_hits:9\n",
      "1020 1029 n_hits:9\n",
      "1030 1039 n_hits:10\n",
      "1040 1049 n_hits:9\n",
      "1050 1059 n_hits:10\n",
      "1060 1069 n_hits:9\n",
      "1070 1079 n_hits:10\n",
      "1080 1089 n_hits:10\n",
      "1090 1099 n_hits:10\n",
      "1100 1109 n_hits:10\n",
      "1110 1119 n_hits:10\n",
      "1120 1129 n_hits:10\n",
      "1130 1139 n_hits:10\n",
      "1140 1149 n_hits:8\n",
      "1150 1159 n_hits:10\n",
      "1160 1169 n_hits:10\n",
      "1170 1179 n_hits:10\n",
      "1180 1189 n_hits:9\n",
      "1190 1199 n_hits:9\n",
      "1200 1209 n_hits:10\n",
      "1210 1219 n_hits:10\n",
      "1220 1229 n_hits:9\n",
      "1230 1239 n_hits:10\n",
      "1240 1249 n_hits:10\n",
      "1250 1259 n_hits:10\n",
      "1260 1269 n_hits:10\n",
      "1270 1279 n_hits:8\n",
      "1280 1289 n_hits:10\n",
      "1290 1299 n_hits:10\n",
      "1300 1309 n_hits:10\n",
      "1310 1319 n_hits:10\n",
      "1320 1329 n_hits:10\n",
      "1330 1339 n_hits:10\n",
      "1340 1349 n_hits:10\n",
      "1350 1359 n_hits:10\n",
      "1360 1369 n_hits:10\n",
      "1370 1379 n_hits:10\n",
      "1380 1389 n_hits:10\n",
      "1390 1399 n_hits:10\n",
      "1400 1409 n_hits:10\n",
      "1410 1419 n_hits:3\n",
      "1420 1429 n_hits:9\n",
      "1430 1439 n_hits:10\n",
      "1440 1449 n_hits:10\n",
      "1450 1459 n_hits:10\n",
      "1460 1469 n_hits:10\n",
      "1470 1479 n_hits:10\n",
      "1480 1489 n_hits:10\n",
      "1490 1499 n_hits:10\n",
      "1500 1509 n_hits:10\n",
      "1510 1519 n_hits:10\n",
      "1520 1529 n_hits:7\n",
      "1530 1539 n_hits:10\n",
      "1540 1549 n_hits:10\n",
      "1550 1559 n_hits:10\n",
      "1560 1569 n_hits:10\n",
      "1570 1579 n_hits:9\n",
      "1580 1589 n_hits:8\n",
      "1590 1599 n_hits:9\n",
      "1600 1609 n_hits:9\n",
      "1610 1619 n_hits:10\n",
      "1620 1629 n_hits:10\n",
      "1630 1639 n_hits:7\n",
      "1640 1649 n_hits:5\n",
      "1650 1659 n_hits:9\n",
      "1660 1669 n_hits:9\n",
      "1670 1679 n_hits:10\n",
      "1680 1689 n_hits:10\n",
      "1690 1699 n_hits:10\n",
      "1700 1709 n_hits:10\n",
      "1710 1719 n_hits:9\n",
      "1720 1729 n_hits:9\n",
      "1730 1739 n_hits:10\n",
      "1740 1749 n_hits:10\n",
      "1750 1759 n_hits:10\n",
      "1760 1769 n_hits:9\n",
      "1770 1779 n_hits:10\n",
      "1780 1789 n_hits:7\n",
      "1790 1799 n_hits:4\n",
      "1800 1809 n_hits:10\n",
      "1810 1819 n_hits:10\n",
      "1820 1829 n_hits:10\n",
      "1830 1839 n_hits:9\n",
      "1840 1849 n_hits:10\n",
      "1850 1859 n_hits:8\n",
      "1860 1869 n_hits:9\n",
      "1870 1879 n_hits:10\n",
      "1880 1889 n_hits:10\n",
      "1890 1899 n_hits:10\n",
      "1900 1909 n_hits:10\n",
      "1910 1919 n_hits:9\n",
      "1920 1929 n_hits:10\n",
      "1930 1939 n_hits:10\n",
      "1940 1949 n_hits:10\n",
      "1950 1959 n_hits:10\n",
      "1960 1969 n_hits:10\n",
      "1970 1979 n_hits:2\n",
      "1980 1989 n_hits:5\n",
      "1990 1999 n_hits:10\n",
      "2000 2009 n_hits:10\n",
      "['RP04440  C05447_C05448 main [RC:RC01217]', 'RP00002  C00003_C00004 cofac [RC:RC00001]\\n            RP00614  C00376_C00777 main [RC:RC00218]', 'RP00016  C00053_C00054 main [RC:RC00007]\\n            RP13355  C17141_C17142 main [RC:RC00630]', 'RP04435  C05437_C05439 main [RC:RC00911]', 'RP00002  C00003_C00004 cofac [RC:RC00001]\\n            RP04436  C05444_C05445 main [RC:RC00099]', 'RP04437  C05444_C05452 main [RC:RC01216]', 'RP09341  C05446_C05454 main [RC:RC01216]', 'RP11117  C00376_C05918 main [RC:RC00248]', 'RP11116  C00376_C05917 main [RC:RC01826]', 'RP04434  C05434_C05435 main [RC:RC01214]']\n",
      "['RP04440', 'RP00002', 'RP00614', 'RP00016', 'RP13355', 'RP04435', 'RP00002', 'RP04436', 'RP04437', 'RP09341', 'RP11117', 'RP11116', 'RP04434']\n",
      "2010 2019 n_hits:10\n",
      "2020 2029 n_hits:9\n",
      "2030 2039 n_hits:10\n",
      "2040 2049 n_hits:10\n",
      "2050 2059 n_hits:10\n",
      "2060 2069 n_hits:10\n",
      "2070 2079 n_hits:10\n",
      "2080 2089 n_hits:10\n",
      "2090 2099 n_hits:10\n",
      "2100 2109 n_hits:9\n",
      "2110 2119 n_hits:9\n",
      "2120 2129 n_hits:9\n",
      "2130 2139 n_hits:9\n",
      "2140 2149 n_hits:10\n",
      "2150 2159 n_hits:10\n",
      "2160 2169 n_hits:8\n",
      "2170 2179 n_hits:10\n",
      "2180 2189 n_hits:10\n",
      "2190 2199 n_hits:8\n",
      "2200 2209 n_hits:9\n",
      "2210 2219 n_hits:9\n",
      "2220 2229 n_hits:10\n",
      "2230 2239 n_hits:10\n",
      "2240 2249 n_hits:10\n",
      "2250 2259 n_hits:10\n",
      "2260 2269 n_hits:10\n",
      "2270 2279 n_hits:10\n",
      "2280 2289 n_hits:9\n",
      "2290 2299 n_hits:10\n",
      "2300 2309 n_hits:9\n",
      "2310 2319 n_hits:5\n",
      "2320 2329 n_hits:10\n",
      "2330 2339 n_hits:10\n",
      "2340 2349 n_hits:10\n",
      "2350 2359 n_hits:10\n",
      "2360 2369 n_hits:10\n",
      "2370 2379 n_hits:10\n",
      "2380 2389 n_hits:10\n",
      "2390 2399 n_hits:10\n",
      "2400 2409 n_hits:8\n",
      "2410 2419 n_hits:4\n",
      "2420 2429 n_hits:9\n",
      "2430 2439 n_hits:9\n",
      "2440 2449 n_hits:10\n",
      "2450 2459 n_hits:9\n",
      "2460 2469 n_hits:10\n",
      "2470 2479 n_hits:9\n",
      "2480 2489 n_hits:10\n",
      "2490 2499 n_hits:8\n",
      "2500 2509 n_hits:9\n",
      "2510 2519 n_hits:10\n",
      "2520 2529 n_hits:10\n",
      "2530 2539 n_hits:10\n",
      "2540 2549 n_hits:10\n",
      "2550 2559 n_hits:10\n",
      "2560 2569 n_hits:8\n",
      "2570 2579 n_hits:9\n",
      "2580 2589 n_hits:10\n",
      "2590 2599 n_hits:8\n",
      "2600 2609 n_hits:10\n",
      "2610 2619 n_hits:9\n",
      "2620 2629 n_hits:10\n",
      "2630 2639 n_hits:10\n",
      "2640 2649 n_hits:10\n",
      "2650 2659 n_hits:10\n",
      "2660 2669 n_hits:10\n",
      "2670 2679 n_hits:10\n",
      "2680 2689 n_hits:10\n",
      "2690 2699 n_hits:10\n",
      "2700 2709 n_hits:10\n",
      "2710 2719 n_hits:9\n",
      "2720 2729 n_hits:10\n",
      "2730 2739 n_hits:10\n",
      "2740 2749 n_hits:10\n",
      "2750 2759 n_hits:10\n",
      "2760 2769 n_hits:10\n",
      "2770 2779 n_hits:10\n",
      "2780 2789 n_hits:10\n",
      "2790 2799 n_hits:9\n",
      "2800 2809 n_hits:10\n",
      "2810 2819 n_hits:10\n",
      "2820 2829 n_hits:10\n",
      "2830 2839 n_hits:9\n",
      "2840 2849 n_hits:9\n",
      "2850 2859 n_hits:10\n",
      "2860 2869 n_hits:10\n",
      "2870 2879 n_hits:10\n",
      "2880 2889 n_hits:9\n",
      "2890 2899 n_hits:10\n",
      "2900 2909 n_hits:10\n",
      "2910 2919 n_hits:10\n",
      "2920 2929 n_hits:8\n",
      "2930 2939 n_hits:10\n",
      "2940 2949 n_hits:10\n",
      "2950 2959 n_hits:3\n",
      "2960 2969 n_hits:9\n",
      "2970 2979 n_hits:10\n",
      "2980 2989 n_hits:10\n",
      "2990 2999 n_hits:7\n",
      "3000 3009 n_hits:9\n",
      "['RP00002  C00003_C00004 cofac [RC:RC00001]\\n            RP11812  C09848_C16462 main [RC:RC00080]', 'RP00004  C00019_C00021 main [RC:RC00003]\\n            RP11929  C14151_C14152 main [RC:RC01662]', 'RP05471  C00060_C00241 main [RC:RC01025]', 'RP10143  C01595_C14827 main [RC:RC00561]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP11577  C05440_C15778 main [RC:RC01970]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP11276  C01164_C05107 main [RC:RC00522]', 'RP11173  C00544_C15882 main [RC:RC01840]\\n            RP11557  C05427_C15882 main [RC:RC02895]', 'RP00004  C00019_C00021 main [RC:RC00003]\\n            RP12024  C15882_C15883 main [RC:RC01662]', 'RP11403  C02483_C15883 main [RC:RC01911]']\n",
      "['RP00002', 'RP11812', 'RP00004', 'RP11929', 'RP05471', 'RP10143', 'RP00001', 'RP11577', 'RP00001', 'RP11276', 'RP11173', 'RP11557', 'RP00004', 'RP12024', 'RP11403']\n",
      "3010 3019 n_hits:10\n",
      "3020 3029 n_hits:10\n",
      "3030 3039 n_hits:8\n",
      "3040 3049 n_hits:10\n",
      "3050 3059 n_hits:10\n",
      "3060 3069 n_hits:10\n",
      "3070 3079 n_hits:10\n",
      "3080 3089 n_hits:9\n",
      "3090 3099 n_hits:10\n",
      "3100 3109 n_hits:10\n",
      "3110 3119 n_hits:10\n",
      "3120 3129 n_hits:9\n",
      "3130 3139 n_hits:9\n",
      "3140 3149 n_hits:10\n",
      "3150 3159 n_hits:8\n",
      "3160 3169 n_hits:10\n",
      "3170 3179 n_hits:10\n",
      "3180 3189 n_hits:10\n",
      "3190 3199 n_hits:10\n",
      "3200 3209 n_hits:10\n",
      "3210 3219 n_hits:10\n",
      "3220 3229 n_hits:10\n",
      "3230 3239 n_hits:10\n",
      "3240 3249 n_hits:10\n",
      "3250 3259 n_hits:9\n",
      "3260 3269 n_hits:9\n",
      "3270 3279 n_hits:10\n",
      "3280 3289 n_hits:10\n",
      "3290 3299 n_hits:10\n",
      "3300 3309 n_hits:10\n",
      "3310 3319 n_hits:9\n",
      "3320 3329 n_hits:10\n",
      "3330 3339 n_hits:10\n",
      "3340 3349 n_hits:10\n",
      "3350 3359 n_hits:10\n",
      "3360 3369 n_hits:10\n",
      "3370 3379 n_hits:10\n",
      "3380 3389 n_hits:9\n",
      "3390 3399 n_hits:9\n",
      "3400 3409 n_hits:10\n",
      "3410 3419 n_hits:10\n",
      "3420 3429 n_hits:10\n",
      "3430 3439 n_hits:10\n",
      "3440 3449 n_hits:10\n",
      "3450 3459 n_hits:9\n",
      "3460 3469 n_hits:8\n",
      "3470 3479 n_hits:9\n",
      "3480 3489 n_hits:10\n",
      "3490 3499 n_hits:9\n",
      "3500 3509 n_hits:5\n",
      "3510 3519 n_hits:10\n",
      "3520 3529 n_hits:10\n",
      "3530 3539 n_hits:10\n",
      "3540 3549 n_hits:10\n",
      "3550 3559 n_hits:7\n",
      "3560 3569 n_hits:10\n",
      "3570 3579 n_hits:10\n",
      "3580 3589 n_hits:10\n",
      "3590 3599 n_hits:10\n",
      "3600 3609 n_hits:10\n",
      "3610 3619 n_hits:10\n",
      "3620 3629 n_hits:9\n",
      "3630 3639 n_hits:8\n",
      "3640 3649 n_hits:10\n",
      "3650 3659 n_hits:8\n",
      "3660 3669 n_hits:10\n",
      "3670 3679 n_hits:10\n",
      "3680 3689 n_hits:9\n",
      "3690 3699 n_hits:10\n",
      "3700 3709 n_hits:10\n",
      "3710 3719 n_hits:10\n",
      "3720 3729 n_hits:10\n",
      "3730 3739 n_hits:10\n",
      "3740 3749 n_hits:10\n",
      "3750 3759 n_hits:10\n",
      "3760 3769 n_hits:10\n",
      "3770 3779 n_hits:8\n",
      "3780 3789 n_hits:10\n",
      "3790 3799 n_hits:10\n",
      "3800 3809 n_hits:10\n",
      "3810 3819 n_hits:10\n",
      "3820 3829 n_hits:8\n",
      "3830 3839 n_hits:8\n",
      "3840 3849 n_hits:7\n",
      "3850 3859 n_hits:9\n",
      "3860 3869 n_hits:10\n",
      "3870 3879 n_hits:9\n",
      "3880 3889 n_hits:10\n",
      "3890 3899 n_hits:10\n",
      "3900 3909 n_hits:7\n",
      "3910 3919 n_hits:8\n",
      "3920 3929 n_hits:3\n",
      "3930 3939 n_hits:7\n",
      "3940 3949 n_hits:9\n",
      "3950 3959 n_hits:10\n",
      "3960 3969 n_hits:10\n",
      "3970 3979 n_hits:10\n",
      "3980 3989 n_hits:10\n",
      "3990 3999 n_hits:8\n",
      "4000 4009 n_hits:10\n",
      "['RP14424  C18263_C18265 main [RC:RC01446]', 'RP14422  C14519_C18265 main [RC:RC01445]', 'RP14421  C14519_C18267 main [RC:RC01446]', 'RP00004  C00019_C00021 main [RC:RC00003]\\n            RP14430  C14519_C18259 main [RC:RC00392]', 'RP14429  C18258_C18264 main [RC:RC01717]', 'RP14428  C18264_C18266 main [RC:RC01446]', 'RP14426  C14519_C18266 main [RC:RC01445]', 'RP14434  C18261_C18262 main [RC:RC01446]', 'RP14432  C18259_C18262 main [RC:RC01445]', 'RP03552  C01953_C05501 main [RC:RC01029]\\n            RP03553  C02373_C05501 main [RC:RC01030]']\n",
      "['RP14424', 'RP14422', 'RP14421', 'RP00004', 'RP14430', 'RP14429', 'RP14428', 'RP14426', 'RP14434', 'RP14432', 'RP03552', 'RP03553']\n",
      "4010 4019 n_hits:10\n",
      "4020 4029 n_hits:10\n",
      "4030 4039 n_hits:10\n",
      "4040 4049 n_hits:10\n",
      "4050 4059 n_hits:10\n",
      "4060 4069 n_hits:10\n",
      "4070 4079 n_hits:8\n",
      "4080 4089 n_hits:8\n",
      "4090 4099 n_hits:9\n",
      "4100 4109 n_hits:10\n",
      "4110 4119 n_hits:9\n",
      "4120 4129 n_hits:9\n",
      "4130 4139 n_hits:10\n",
      "4140 4149 n_hits:10\n",
      "4150 4159 n_hits:10\n",
      "4160 4169 n_hits:10\n",
      "4170 4179 n_hits:10\n",
      "4180 4189 n_hits:10\n",
      "4190 4199 n_hits:9\n",
      "4200 4209 n_hits:10\n",
      "4210 4219 n_hits:10\n",
      "4220 4229 n_hits:10\n",
      "4230 4239 n_hits:10\n",
      "4240 4249 n_hits:10\n",
      "4250 4259 n_hits:8\n",
      "4260 4269 n_hits:8\n",
      "4270 4279 n_hits:9\n",
      "4280 4289 n_hits:9\n",
      "4290 4299 n_hits:10\n",
      "4300 4309 n_hits:7\n",
      "4310 4319 n_hits:8\n",
      "4320 4329 n_hits:8\n",
      "4330 4339 n_hits:10\n",
      "4340 4349 n_hits:10\n",
      "4350 4359 n_hits:9\n",
      "4360 4369 n_hits:10\n",
      "4370 4379 n_hits:10\n",
      "4380 4389 n_hits:10\n",
      "4390 4399 n_hits:9\n",
      "4400 4409 n_hits:10\n",
      "4410 4419 n_hits:10\n",
      "4420 4429 n_hits:10\n",
      "4430 4439 n_hits:10\n",
      "4440 4449 n_hits:10\n",
      "4450 4459 n_hits:9\n",
      "4460 4469 n_hits:10\n",
      "4470 4479 n_hits:10\n",
      "4480 4489 n_hits:10\n",
      "4490 4499 n_hits:10\n",
      "4500 4509 n_hits:9\n",
      "4510 4519 n_hits:10\n",
      "4520 4529 n_hits:10\n",
      "4530 4539 n_hits:10\n",
      "4540 4549 n_hits:10\n",
      "4550 4559 n_hits:10\n",
      "4560 4569 n_hits:9\n",
      "4570 4579 n_hits:9\n",
      "4580 4589 n_hits:9\n",
      "4590 4599 n_hits:9\n",
      "4600 4609 n_hits:8\n",
      "4610 4619 n_hits:9\n",
      "4620 4629 n_hits:10\n",
      "4630 4639 n_hits:10\n",
      "4640 4649 n_hits:10\n",
      "4650 4659 n_hits:10\n",
      "4660 4669 n_hits:10\n",
      "4670 4679 n_hits:7\n",
      "4680 4689 n_hits:10\n",
      "4690 4699 n_hits:9\n",
      "4700 4709 n_hits:4\n",
      "4710 4719 n_hits:10\n",
      "4720 4729 n_hits:1\n",
      "4730 4739 n_hits:9\n",
      "4740 4749 n_hits:9\n",
      "4750 4759 n_hits:10\n",
      "4760 4769 n_hits:10\n",
      "4770 4779 n_hits:9\n",
      "4780 4789 n_hits:10\n",
      "4790 4799 n_hits:9\n",
      "4800 4809 n_hits:9\n",
      "4810 4819 n_hits:10\n",
      "4820 4829 n_hits:10\n",
      "4830 4839 n_hits:1\n",
      "4840 4849 n_hits:9\n",
      "4850 4859 n_hits:10\n",
      "4860 4869 n_hits:10\n",
      "4870 4879 n_hits:10\n",
      "4880 4889 n_hits:9\n",
      "4890 4899 n_hits:7\n",
      "4900 4909 n_hits:10\n",
      "4910 4919 n_hits:10\n",
      "4920 4929 n_hits:10\n",
      "4930 4939 n_hits:9\n",
      "4940 4949 n_hits:10\n",
      "4950 4959 n_hits:10\n",
      "4960 4969 n_hits:9\n",
      "4970 4979 n_hits:9\n",
      "4980 4989 n_hits:10\n",
      "4990 4999 n_hits:9\n",
      "5000 5009 n_hits:10\n",
      "['RP00016  C00053_C00054 main [RC:RC00007]\\n            RP01805  C00292_C06011 main [RC:RC00610]', 'RP01804  C00292_C00568 main [RC:RC00391]', 'RP00175  C00262_C00294 main [RC:RC00063]', 'RP01806  C00060_C01402 main [RC:RC00328]\\n            RP01807  C00292_C01402 main [RC:RC00416]', 'RP00121  C00042_C00122 cofac [RC:RC00045]\\n            RP00141  C00295_C00337 main [RC:RC00051]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP00141  C00295_C00337 main [RC:RC00051]', 'RP00012  C00015_C00029 main [RC:RC00005]', 'RP00144  C00010_C00223 main [RC:RC00004]\\n            RP11760  C08725_C16349 main [RC:RC00041]', 'RP13181  C10826_C15610 main [RC:RC02259]', 'RP00144  C00010_C00223 main [RC:RC00004]\\n            RP11753  C08639_C16350 main [RC:RC00041]']\n",
      "['RP00016', 'RP01805', 'RP01804', 'RP00175', 'RP01806', 'RP01807', 'RP00121', 'RP00141', 'RP00001', 'RP00141', 'RP00012', 'RP00144', 'RP11760', 'RP13181', 'RP00144', 'RP11753']\n",
      "5010 5019 n_hits:10\n",
      "5020 5029 n_hits:10\n",
      "5030 5039 n_hits:9\n",
      "5040 5049 n_hits:10\n",
      "5050 5059 n_hits:6\n",
      "5060 5069 n_hits:7\n",
      "5070 5079 n_hits:8\n",
      "5080 5089 n_hits:3\n",
      "5090 5099 n_hits:10\n",
      "5100 5109 n_hits:9\n",
      "5110 5119 n_hits:9\n",
      "5120 5129 n_hits:10\n",
      "5130 5139 n_hits:10\n",
      "5140 5149 n_hits:9\n",
      "5150 5159 n_hits:10\n",
      "5160 5169 n_hits:10\n",
      "5170 5179 n_hits:9\n",
      "5180 5189 n_hits:9\n",
      "5190 5199 n_hits:10\n",
      "5200 5209 n_hits:3\n",
      "5210 5219 n_hits:7\n",
      "5220 5229 n_hits:10\n",
      "5230 5239 n_hits:10\n",
      "5240 5249 n_hits:10\n",
      "5250 5259 n_hits:8\n",
      "5260 5269 n_hits:10\n",
      "5270 5279 n_hits:10\n",
      "5280 5289 n_hits:10\n",
      "5290 5299 n_hits:10\n",
      "5300 5309 n_hits:10\n",
      "5310 5319 n_hits:10\n",
      "5320 5329 n_hits:10\n",
      "5330 5339 n_hits:10\n",
      "5340 5349 n_hits:8\n",
      "5350 5359 n_hits:10\n",
      "5360 5369 n_hits:9\n",
      "5370 5379 n_hits:10\n",
      "5380 5389 n_hits:7\n",
      "5390 5399 n_hits:4\n",
      "5400 5409 n_hits:10\n",
      "5410 5419 n_hits:10\n",
      "5420 5429 n_hits:10\n",
      "5430 5439 n_hits:10\n",
      "5440 5449 n_hits:7\n",
      "5450 5459 n_hits:8\n",
      "5460 5469 n_hits:10\n",
      "5470 5479 n_hits:9\n",
      "5480 5489 n_hits:9\n",
      "5490 5499 n_hits:8\n",
      "5500 5509 n_hits:10\n",
      "5510 5519 n_hits:9\n",
      "5520 5529 n_hits:10\n",
      "5530 5539 n_hits:10\n",
      "5540 5549 n_hits:10\n",
      "5550 5559 n_hits:10\n",
      "5560 5569 n_hits:3\n",
      "5570 5579 n_hits:9\n",
      "5580 5589 n_hits:10\n",
      "5590 5599 n_hits:10\n",
      "5600 5609 n_hits:10\n",
      "5610 5619 n_hits:10\n",
      "5620 5629 n_hits:10\n",
      "5630 5639 n_hits:10\n",
      "5640 5649 n_hits:10\n",
      "5650 5659 n_hits:10\n",
      "5660 5669 n_hits:10\n",
      "5670 5679 n_hits:10\n",
      "5680 5689 n_hits:9\n",
      "5690 5699 n_hits:10\n",
      "5700 5709 n_hits:8\n",
      "5710 5719 n_hits:10\n",
      "5720 5729 n_hits:10\n",
      "5730 5739 n_hits:10\n",
      "5740 5749 n_hits:10\n",
      "5750 5759 n_hits:10\n",
      "5760 5769 n_hits:9\n",
      "5770 5779 n_hits:1\n",
      "5780 5789 n_hits:10\n",
      "5790 5799 n_hits:10\n",
      "5800 5809 n_hits:10\n",
      "5810 5819 n_hits:10\n",
      "5820 5829 n_hits:9\n",
      "5830 5839 n_hits:9\n",
      "5840 5849 n_hits:10\n",
      "5850 5859 n_hits:10\n",
      "5860 5869 n_hits:10\n",
      "5870 5879 n_hits:7\n",
      "5880 5889 n_hits:10\n",
      "5890 5899 n_hits:8\n",
      "5900 5909 n_hits:10\n",
      "5910 5919 n_hits:10\n",
      "5920 5929 n_hits:10\n",
      "5930 5939 n_hits:10\n",
      "5940 5949 n_hits:7\n",
      "5950 5959 n_hits:8\n",
      "5960 5969 n_hits:9\n",
      "5970 5979 n_hits:9\n",
      "5980 5989 n_hits:10\n",
      "5990 5999 n_hits:10\n",
      "6000 6009 n_hits:10\n",
      "['RP00028  C00015_C00167 main [RC:RC00005]\\n            RP09326  C04900_C12632 main [RC:RC00171]', 'RP00718  C00015_C02199 main [RC:RC00005]\\n            RP09311  C03951_C12630 main [RC:RC00049]', 'RP00004  C00019_C00021 main [RC:RC00003]\\n            RP09578  C12628_C12629 main [RC:RC00392]', 'RP09237  C01477_C01714 main [RC:RC01587]', 'RP00718  C00015_C02199 main [RC:RC00005]\\n            RP11506  C04608_C12627 main [RC:RC00049]', 'RP00028  C00015_C00167 main [RC:RC00005]\\n            RP09298  C03515_C12632 main [RC:RC00049]', 'RP00718  C00015_C02199 main [RC:RC00005]\\n            RP09413  C09099_C09789 main [RC:RC00049]', 'RP00051  C00010_C00083 main [RC:RC00004]\\n            RP09320  C04608_C10020 main [RC:RC00041]', 'RP09235  C01460_C01477 main [RC:RC01587]', 'RP09236  C01460_C12628 main [RC:RC00049]']\n",
      "['RP00028', 'RP09326', 'RP00718', 'RP09311', 'RP00004', 'RP09578', 'RP09237', 'RP00718', 'RP11506', 'RP00028', 'RP09298', 'RP00718', 'RP09413', 'RP00051', 'RP09320', 'RP09235', 'RP09236']\n",
      "6010 6019 n_hits:6\n",
      "6020 6029 n_hits:9\n",
      "6030 6039 n_hits:10\n",
      "6040 6049 n_hits:10\n",
      "6050 6059 n_hits:10\n",
      "6060 6069 n_hits:10\n",
      "6070 6079 n_hits:10\n",
      "6080 6089 n_hits:9\n",
      "6090 6099 n_hits:10\n",
      "6100 6109 n_hits:10\n",
      "6110 6119 n_hits:10\n",
      "6120 6129 n_hits:10\n",
      "6130 6139 n_hits:9\n",
      "6140 6149 n_hits:10\n",
      "6150 6159 n_hits:10\n",
      "6160 6169 n_hits:10\n",
      "6170 6179 n_hits:10\n",
      "6180 6189 n_hits:10\n",
      "6190 6199 n_hits:7\n",
      "6200 6209 n_hits:9\n",
      "6210 6219 n_hits:10\n",
      "6220 6229 n_hits:9\n",
      "6230 6239 n_hits:7\n",
      "6240 6249 n_hits:10\n",
      "6250 6259 n_hits:9\n",
      "6260 6269 n_hits:10\n",
      "6270 6279 n_hits:10\n",
      "6280 6289 n_hits:10\n",
      "6290 6299 n_hits:10\n",
      "6300 6309 n_hits:10\n",
      "6310 6319 n_hits:10\n",
      "6320 6329 n_hits:9\n",
      "6330 6339 n_hits:10\n",
      "6340 6349 n_hits:9\n",
      "6350 6359 n_hits:10\n",
      "6360 6369 n_hits:10\n",
      "6370 6379 n_hits:10\n",
      "6380 6389 n_hits:9\n",
      "6390 6399 n_hits:10\n",
      "6400 6409 n_hits:10\n",
      "6410 6419 n_hits:9\n",
      "6420 6429 n_hits:10\n",
      "6430 6439 n_hits:10\n",
      "6440 6449 n_hits:10\n",
      "6450 6459 n_hits:10\n",
      "6460 6469 n_hits:9\n",
      "6470 6479 n_hits:10\n",
      "6480 6489 n_hits:9\n",
      "6490 6499 n_hits:10\n",
      "6500 6509 n_hits:9\n",
      "6510 6519 n_hits:10\n",
      "6520 6529 n_hits:9\n",
      "6530 6539 n_hits:10\n",
      "6540 6549 n_hits:5\n",
      "6550 6559 n_hits:8\n",
      "6560 6569 n_hits:10\n",
      "6570 6579 n_hits:10\n",
      "6580 6589 n_hits:9\n",
      "6590 6599 n_hits:10\n",
      "6600 6609 n_hits:10\n",
      "6610 6619 n_hits:10\n",
      "6620 6629 n_hits:10\n",
      "6630 6639 n_hits:10\n",
      "6640 6649 n_hits:10\n",
      "6650 6659 n_hits:10\n",
      "6660 6669 n_hits:10\n",
      "6670 6679 n_hits:5\n",
      "6680 6689 n_hits:7\n",
      "6690 6699 n_hits:10\n",
      "6700 6709 n_hits:10\n",
      "6710 6719 n_hits:10\n",
      "6720 6729 n_hits:9\n",
      "6730 6739 n_hits:9\n",
      "6740 6749 n_hits:8\n",
      "6750 6759 n_hits:9\n",
      "6760 6769 n_hits:10\n",
      "6770 6779 n_hits:8\n",
      "6780 6789 n_hits:10\n",
      "6790 6799 n_hits:9\n",
      "6800 6809 n_hits:10\n",
      "6810 6819 n_hits:10\n",
      "6820 6829 n_hits:10\n",
      "6830 6839 n_hits:10\n",
      "6840 6849 n_hits:10\n",
      "6850 6859 n_hits:10\n",
      "6860 6869 n_hits:10\n",
      "6870 6879 n_hits:10\n",
      "6880 6889 n_hits:8\n",
      "6890 6899 n_hits:3\n",
      "6900 6909 n_hits:8\n",
      "6910 6919 n_hits:10\n",
      "6920 6929 n_hits:10\n",
      "6930 6939 n_hits:8\n",
      "6940 6949 n_hits:10\n",
      "6950 6959 n_hits:10\n",
      "6960 6969 n_hits:10\n",
      "6970 6979 n_hits:10\n",
      "6980 6989 n_hits:10\n",
      "6990 6999 n_hits:10\n",
      "7000 7009 n_hits:10\n",
      "['RP13140  C07576_C08312 main [RC:RC00151]', 'RP12969  C00398_C06535 main [RC:RC02172]', 'RP12972  C00398_C09209 main [RC:RC02175]', 'RP13894  C00398_C09089 main [RC:RC01568]', 'RP13273  C16723_C16724 main [RC:RC02289]', 'RP13274  C16723_C16725 main [RC:RC02290]', 'RP09223  C01217_C04377 main [RC:RC01583]\\n            RP10858  C00067_C04377 main [RC:RC01795]', 'RP00677  C01243_C01272 main [RC:RC00078]', 'RP00002  C00003_C00004 cofac [RC:RC00001]\\n            RP04454  C05470_C05481 main [RC:RC01219]', 'RP12697  C11173_C11376 main [RC:RC00171]\\n            RP12946  C00191_C11376 main [RC:RC00714]']\n",
      "['RP13140', 'RP12969', 'RP12972', 'RP13894', 'RP13273', 'RP13274', 'RP09223', 'RP10858', 'RP00677', 'RP00002', 'RP04454', 'RP12697', 'RP12946']\n",
      "7010 7019 n_hits:10\n",
      "7020 7029 n_hits:10\n",
      "7030 7039 n_hits:10\n",
      "7040 7049 n_hits:9\n",
      "7050 7059 n_hits:9\n",
      "7060 7069 n_hits:10\n",
      "7070 7079 n_hits:10\n",
      "7080 7089 n_hits:10\n",
      "7090 7099 n_hits:8\n",
      "7100 7109 n_hits:10\n",
      "7110 7119 n_hits:10\n",
      "7120 7129 n_hits:10\n",
      "7130 7139 n_hits:10\n",
      "7140 7149 n_hits:10\n",
      "7150 7159 n_hits:9\n",
      "7160 7169 n_hits:10\n",
      "7170 7179 n_hits:10\n",
      "7180 7189 n_hits:8\n",
      "7190 7199 n_hits:10\n",
      "7200 7209 n_hits:10\n",
      "7210 7219 n_hits:7\n",
      "7220 7229 n_hits:7\n",
      "7230 7239 n_hits:10\n",
      "7240 7249 n_hits:8\n",
      "7250 7259 n_hits:8\n",
      "7260 7269 n_hits:9\n",
      "7270 7279 n_hits:10\n",
      "7280 7289 n_hits:10\n",
      "7290 7299 n_hits:10\n",
      "7300 7309 n_hits:10\n",
      "7310 7319 n_hits:10\n",
      "7320 7329 n_hits:8\n",
      "7330 7339 n_hits:10\n",
      "7340 7349 n_hits:10\n",
      "7350 7359 n_hits:10\n",
      "7360 7369 n_hits:10\n",
      "7370 7379 n_hits:8\n",
      "7380 7389 n_hits:8\n",
      "7390 7399 n_hits:10\n",
      "7400 7409 n_hits:9\n",
      "7410 7419 n_hits:10\n",
      "7420 7429 n_hits:10\n",
      "7430 7439 n_hits:9\n",
      "7440 7449 n_hits:10\n",
      "7450 7459 n_hits:10\n",
      "7460 7469 n_hits:10\n",
      "7470 7479 n_hits:10\n",
      "7480 7489 n_hits:9\n",
      "7490 7499 n_hits:10\n",
      "7500 7509 n_hits:10\n",
      "7510 7519 n_hits:10\n",
      "7520 7529 n_hits:10\n",
      "7530 7539 n_hits:10\n",
      "7540 7549 n_hits:10\n",
      "7550 7559 n_hits:10\n",
      "7560 7569 n_hits:10\n",
      "7570 7579 n_hits:10\n",
      "7580 7589 n_hits:10\n",
      "7590 7599 n_hits:9\n",
      "7600 7609 n_hits:10\n",
      "7610 7619 n_hits:10\n",
      "7620 7629 n_hits:9\n",
      "7630 7639 n_hits:9\n",
      "7640 7649 n_hits:10\n",
      "7650 7659 n_hits:10\n",
      "7660 7669 n_hits:10\n",
      "7670 7679 n_hits:10\n",
      "7680 7689 n_hits:10\n",
      "7690 7699 n_hits:10\n",
      "7700 7709 n_hits:10\n",
      "7710 7719 n_hits:8\n",
      "7720 7729 n_hits:10\n",
      "7730 7739 n_hits:10\n",
      "7740 7749 n_hits:10\n",
      "7750 7759 n_hits:10\n",
      "7760 7769 n_hits:10\n",
      "7770 7779 n_hits:10\n",
      "7780 7789 n_hits:10\n",
      "7790 7799 n_hits:9\n",
      "7800 7809 n_hits:8\n",
      "7810 7819 n_hits:10\n",
      "7820 7829 n_hits:10\n",
      "7830 7839 n_hits:10\n",
      "7840 7849 n_hits:8\n",
      "7850 7859 n_hits:9\n",
      "7860 7869 n_hits:5\n",
      "7870 7879 n_hits:10\n",
      "7880 7889 n_hits:10\n",
      "7890 7899 n_hits:9\n",
      "7900 7909 n_hits:10\n",
      "7910 7919 n_hits:9\n",
      "7920 7929 n_hits:10\n",
      "7930 7939 n_hits:10\n",
      "7940 7949 n_hits:9\n",
      "7950 7959 n_hits:9\n",
      "7960 7969 n_hits:10\n",
      "7970 7979 n_hits:10\n",
      "7980 7989 n_hits:10\n",
      "7990 7999 n_hits:10\n",
      "8000 8009 n_hits:10\n",
      "['RP14043  C06457_C17951 main [RC:RC00064]\\n            RP14044  C00033_C17951 main [RC:RC00300]', 'RP15538  C00448_C20181 main [RC:RC02703]', 'RP00038  C00125_C00126 cofac [RC:RC00016]\\n            RP05887  C00014_C00088 main [RC:RC00176]', 'RP00012  C00015_C00029 main [RC:RC00005]\\n            RP04224  C04720_C04831 main [RC:RC00049]', 'RP12565  C02601_C03808 main [RC:RC00017]', 'RP03611  C02038_C03881 main [RC:RC00096]\\n            RP03612  C00010_C02593 main [RC:RC00004]', 'RP03612  C00010_C02593 main [RC:RC00004]\\n            RP07829  C00024_C05259 main [RC:RC00326]', 'RP00018  C00016_C01352 cofac [RC:RC00126]\\n            RP00256  C02593_C05273 main [RC:RC00052]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP03618  C02625_C02933 main [RC:RC00046]', 'RP00012  C00015_C00029 main [RC:RC00005]']\n",
      "['RP14043', 'RP14044', 'RP15538', 'RP00038', 'RP05887', 'RP00012', 'RP04224', 'RP12565', 'RP03611', 'RP03612', 'RP03612', 'RP07829', 'RP00018', 'RP00256', 'RP00001', 'RP03618', 'RP00012']\n",
      "8010 8019 n_hits:10\n",
      "8020 8029 n_hits:10\n",
      "8030 8039 n_hits:10\n",
      "8040 8049 n_hits:7\n",
      "8050 8059 n_hits:9\n",
      "8060 8069 n_hits:10\n",
      "8070 8079 n_hits:10\n",
      "8080 8089 n_hits:10\n",
      "8090 8099 n_hits:10\n",
      "8100 8109 n_hits:9\n",
      "8110 8119 n_hits:10\n",
      "8120 8129 n_hits:10\n",
      "8130 8139 n_hits:10\n",
      "8140 8149 n_hits:6\n",
      "8150 8159 n_hits:9\n",
      "8160 8169 n_hits:10\n",
      "8170 8179 n_hits:8\n",
      "8180 8189 n_hits:8\n",
      "8190 8199 n_hits:9\n",
      "8200 8209 n_hits:10\n",
      "8210 8219 n_hits:10\n",
      "8220 8229 n_hits:10\n",
      "8230 8239 n_hits:10\n",
      "8240 8249 n_hits:10\n",
      "8250 8259 n_hits:10\n",
      "8260 8269 n_hits:9\n",
      "8270 8279 n_hits:10\n",
      "8280 8289 n_hits:10\n",
      "8290 8299 n_hits:9\n",
      "8300 8309 n_hits:10\n",
      "8310 8319 n_hits:10\n",
      "8320 8329 n_hits:9\n",
      "8330 8339 n_hits:10\n",
      "8340 8349 n_hits:10\n",
      "8350 8359 n_hits:10\n",
      "8360 8369 n_hits:10\n",
      "8370 8379 n_hits:10\n",
      "8380 8389 n_hits:10\n",
      "8390 8399 n_hits:10\n",
      "8400 8409 n_hits:9\n",
      "8410 8419 n_hits:9\n",
      "8420 8429 n_hits:9\n",
      "8430 8439 n_hits:10\n",
      "8440 8449 n_hits:6\n",
      "8450 8459 n_hits:3\n",
      "8460 8469 n_hits:10\n",
      "8470 8479 n_hits:10\n",
      "8480 8489 n_hits:10\n",
      "8490 8499 n_hits:10\n",
      "8500 8509 n_hits:10\n",
      "8510 8519 n_hits:10\n",
      "8520 8529 n_hits:7\n",
      "8530 8539 n_hits:10\n",
      "8540 8549 n_hits:9\n",
      "8550 8559 n_hits:9\n",
      "8560 8569 n_hits:10\n",
      "8570 8579 n_hits:10\n",
      "8580 8589 n_hits:10\n",
      "8590 8599 n_hits:9\n",
      "8600 8609 n_hits:9\n",
      "8610 8619 n_hits:9\n",
      "8620 8629 n_hits:10\n",
      "8630 8639 n_hits:10\n",
      "8640 8649 n_hits:10\n",
      "8650 8659 n_hits:7\n",
      "8660 8669 n_hits:10\n",
      "8670 8679 n_hits:10\n",
      "8680 8689 n_hits:9\n",
      "8690 8699 n_hits:10\n",
      "8700 8709 n_hits:10\n",
      "8710 8719 n_hits:10\n",
      "8720 8729 n_hits:10\n",
      "8730 8739 n_hits:10\n",
      "8740 8749 n_hits:10\n",
      "8750 8759 n_hits:10\n",
      "8760 8769 n_hits:10\n",
      "8770 8779 n_hits:10\n",
      "8780 8789 n_hits:10\n",
      "8790 8799 n_hits:10\n",
      "8800 8809 n_hits:10\n",
      "8810 8819 n_hits:10\n",
      "8820 8829 n_hits:10\n",
      "8830 8839 n_hits:10\n",
      "8840 8849 n_hits:9\n",
      "8850 8859 n_hits:9\n",
      "8860 8869 n_hits:10\n",
      "8870 8879 n_hits:10\n",
      "8880 8889 n_hits:9\n",
      "8890 8899 n_hits:9\n",
      "8900 8909 n_hits:10\n",
      "8910 8919 n_hits:10\n",
      "8920 8929 n_hits:10\n",
      "8930 8939 n_hits:10\n",
      "8940 8949 n_hits:10\n",
      "8950 8959 n_hits:10\n",
      "8960 8969 n_hits:9\n",
      "8970 8979 n_hits:10\n",
      "8980 8989 n_hits:10\n",
      "8990 8999 n_hits:8\n",
      "9000 9009 n_hits:10\n",
      "['RP17331  C00195_C21022 main [RC:RC00917]', 'RP12710  C00129_C04146 main [RC:RC00279]', 'RP02838  C00058_C01059 main [RC:RC00876]\\n            RP02839  C01059_C01596 main [RC:RC02711]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP04924  C02593_C06736 main [RC:RC00917]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP16256  C20499_C20501 main [RC:RC01710]', 'RP00172  C00015_C00617 main [RC:RC00005]\\n            RP03955  C00470_C00470 main [RC:RC00049]', 'RP03269  C00064_C02282 main [RC:RC00523]\\n            RP03270  C01640_C02282 main [RC:RC00055]', 'RP11142  C00448_C16141 main [RC:RC02586]', 'RP11143  C00448_C16142 main [RC:RC02425]', 'RP00001  C00005_C00006 cofac [RC:RC00001]\\n            RP04925  C02593_C06737 main [RC:RC00917]']\n",
      "['RP17331', 'RP12710', 'RP02838', 'RP02839', 'RP00001', 'RP04924', 'RP00001', 'RP16256', 'RP00172', 'RP03955', 'RP03269', 'RP03270', 'RP11142', 'RP11143', 'RP00001', 'RP04925']\n",
      "9010 9019 n_hits:10\n",
      "9020 9029 n_hits:10\n",
      "9030 9039 n_hits:10\n",
      "9040 9049 n_hits:10\n",
      "9050 9059 n_hits:10\n",
      "9060 9069 n_hits:10\n",
      "9070 9079 n_hits:9\n",
      "9080 9089 n_hits:10\n",
      "9090 9099 n_hits:9\n",
      "9100 9109 n_hits:10\n",
      "9110 9119 n_hits:9\n",
      "9120 9129 n_hits:7\n",
      "9130 9139 n_hits:10\n",
      "9140 9149 n_hits:10\n",
      "9150 9159 n_hits:10\n",
      "9160 9169 n_hits:10\n",
      "9170 9179 n_hits:10\n",
      "9180 9189 n_hits:8\n",
      "9190 9199 n_hits:10\n",
      "9200 9209 n_hits:10\n",
      "9210 9219 n_hits:9\n",
      "9220 9229 n_hits:9\n",
      "9230 9239 n_hits:10\n",
      "9240 9249 n_hits:10\n",
      "9250 9259 n_hits:9\n",
      "9260 9269 n_hits:10\n",
      "9270 9279 n_hits:10\n",
      "9280 9289 n_hits:10\n",
      "9290 9299 n_hits:1\n",
      "9300 9309 n_hits:10\n",
      "9310 9319 n_hits:10\n",
      "9320 9329 n_hits:10\n",
      "9330 9339 n_hits:10\n",
      "9340 9349 n_hits:9\n",
      "9350 9359 n_hits:10\n",
      "9360 9369 n_hits:8\n",
      "9370 9379 n_hits:10\n",
      "9380 9389 n_hits:10\n",
      "9390 9399 n_hits:9\n",
      "9400 9409 n_hits:10\n",
      "9410 9419 n_hits:10\n",
      "9420 9429 n_hits:10\n",
      "9430 9439 n_hits:10\n",
      "9440 9449 n_hits:10\n",
      "9450 9459 n_hits:10\n",
      "9460 9469 n_hits:9\n",
      "9470 9479 n_hits:10\n",
      "9480 9489 n_hits:10\n",
      "9490 9499 n_hits:10\n",
      "9500 9509 n_hits:9\n",
      "9510 9519 n_hits:9\n",
      "9520 9529 n_hits:10\n",
      "9530 9539 n_hits:10\n",
      "9540 9549 n_hits:9\n",
      "9550 9559 n_hits:10\n",
      "9560 9569 n_hits:10\n",
      "9570 9579 n_hits:10\n",
      "9580 9589 n_hits:10\n",
      "9590 9599 n_hits:9\n",
      "9600 9609 n_hits:10\n",
      "9610 9619 n_hits:10\n",
      "9620 9629 n_hits:9\n",
      "9630 9639 n_hits:10\n",
      "9640 9649 n_hits:9\n",
      "9650 9659 n_hits:10\n",
      "9660 9669 n_hits:10\n",
      "9670 9679 n_hits:7\n",
      "9680 9689 n_hits:10\n",
      "9690 9699 n_hits:10\n",
      "9700 9709 n_hits:10\n",
      "9710 9719 n_hits:9\n",
      "9720 9729 n_hits:10\n",
      "9730 9739 n_hits:8\n",
      "9740 9749 n_hits:9\n",
      "9750 9759 n_hits:9\n",
      "9760 9769 n_hits:10\n",
      "9770 9779 n_hits:10\n",
      "9780 9789 n_hits:10\n",
      "9790 9799 n_hits:8\n",
      "9800 9809 n_hits:10\n",
      "9810 9819 n_hits:7\n",
      "9820 9829 n_hits:9\n",
      "9830 9839 n_hits:10\n",
      "9840 9849 n_hits:10\n",
      "9850 9859 n_hits:10\n",
      "9860 9869 n_hits:9\n",
      "9870 9879 n_hits:10\n",
      "9880 9889 n_hits:10\n",
      "9890 9899 n_hits:10\n",
      "9900 9909 n_hits:10\n",
      "9910 9919 n_hits:10\n",
      "9920 9929 n_hits:9\n",
      "9930 9939 n_hits:10\n",
      "9940 9949 n_hits:10\n",
      "9950 9959 n_hits:10\n",
      "9960 9969 n_hits:9\n",
      "9970 9979 n_hits:10\n",
      "9980 9989 n_hits:10\n",
      "9990 9999 n_hits:10\n",
      "10000 10009 n_hits:10\n",
      "['RP01810  C00295_C01103 main [RC:RC00611]', 'RP00416  C00106_C00299 main [RC:RC00063]', 'RP01814  C00299_C01368 main [RC:RC00078]', 'RP01812  C00022_C00793 main [RC:RC00382]', 'RP00025  C00051_C00127 main [RC:RC00011]\\n            RP00110  C00094_C00320 leave [RC:RC02813]\\n            RP04675  C00283_C00320 leave [RC:RC02823]', 'RP07501  C01227_C05138 main [RC:RC00607]', 'RP03017  C00033_C05138 main [RC:RC00923]\\n            RP07501  C01227_C05138 main [RC:RC00607]', 'RP00208  C00031_C00103 main [RC:RC00078]', 'RP15328  C01207_C10447 main [RC:RC02643]', 'RP13885  C15791_C17733 main [RC:RC01504]']\n",
      "['RP01810', 'RP00416', 'RP01814', 'RP01812', 'RP00025', 'RP00110', 'RP04675', 'RP07501', 'RP03017', 'RP07501', 'RP00208', 'RP15328', 'RP13885']\n",
      "10010 10019 n_hits:9\n",
      "10020 10029 n_hits:9\n",
      "10030 10039 n_hits:10\n",
      "10040 10049 n_hits:9\n",
      "10050 10059 n_hits:10\n",
      "10060 10069 n_hits:3\n",
      "10070 10079 n_hits:6\n",
      "10080 10089 n_hits:10\n",
      "10090 10099 n_hits:9\n",
      "10100 10109 n_hits:9\n",
      "10110 10119 n_hits:9\n",
      "10120 10129 n_hits:10\n",
      "10130 10139 n_hits:10\n",
      "10140 10149 n_hits:10\n",
      "10150 10159 n_hits:9\n",
      "10160 10169 n_hits:10\n",
      "10170 10179 n_hits:10\n",
      "10180 10189 n_hits:9\n",
      "10190 10199 n_hits:10\n",
      "10200 10209 n_hits:9\n",
      "10210 10219 n_hits:10\n",
      "10220 10229 n_hits:10\n",
      "10230 10239 n_hits:5\n",
      "9549 reactions were parsed\n"
     ]
    }
   ],
   "source": [
    "rp_pair_data=make_local_complete_reaction_rpair_db(database_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_links(Genome_ko_hits,output_dir):\n",
    "    KO_RN_dict = load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"orthology\",\"reaction\")], False)[(\"orthology\",\"reaction\")]\n",
    "    all_linkable_KOs = set(itertools.chain(*Genome_ko_hits.itervalues())) & set(KO_RN_dict.keys())\n",
    "    cpd_links = {KO:set(KO_RN_dict[KO]) for KO in all_linkable_KOs}\n",
    "    RN_CPD_dict = load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"reaction\",\"compound\")], False)[(\"reaction\",\"compound\")]\n",
    "    all_linkable_RNs=set(itertools.chain(*cpd_links.itervalues())) & set(RN_CPD_dict.keys())\n",
    "    RN_list={RN:set(RN_CPD_dict[RN]) for RN in all_linkable_RNs}\n",
    "    rn_cpd_gen_links={}\n",
    "    ko_rn_gen_links={}\n",
    "    for genome, kos in Genome_ko_hits.iteritems():\n",
    "        cur_kos=set(kos) & all_linkable_KOs\n",
    "        ko_rn_gen_links[genome]={ko:cpd_links[ko] for ko in cur_kos}\n",
    "        cur_rns=set(itertools.chain(*ko_rn_gen_links[genome].itervalues())) & all_linkable_RNs\n",
    "        rn_cpd_gen_links[genome]={rn: RN_list[rn] for rn in cur_rns}\n",
    "    return rn_cpd_gen_links, ko_rn_gen_links\n",
    "\n",
    "def store_rcn_graphs(Genome_ko_hits,common_cpds,reaction_dir,output_dir):\n",
    "    rn_cpd_gen_links,ko_rn_gen_links=generate_links(Genome_ko_hits,output_dir)\n",
    "    cpd_gen_graph={}\n",
    "    for genome, rn_dict in rn_cpd_gen_links.iteritems():\n",
    "        cpd_gen_graph[genome]=reaction_graph(rn_dict,common_cpds)\n",
    "    for genome, rn_graph in cpd_gen_graph.iteritems():\n",
    "        save_reaction_graph(rn_graph,os.path.join(reaction_dir,\"{0}_graph_single_genome_reactions.xml\".format(genome)))\n",
    "        \n",
    "    return cpd_gen_graph\n",
    "\n",
    "def reaction_graph(CPD_rn_links,common_cpds):\n",
    "    connected_edges={}\n",
    "    for reac_1, reac_2 in itertools.combinations(CPD_rn_links.iterkeys(),2):\n",
    "        cpds_1=CPD_rn_links[reac_1]\n",
    "        cpds_2=CPD_rn_links[reac_2]\n",
    "        link=(cpds_1 & cpds_2) - common_cpds\n",
    "        if len(link)>0:\n",
    "            connected_edges[(reac_1,reac_2)]=link\n",
    "\n",
    "    rcn_graph=nx.Graph()\n",
    "    for node,cpds in CPD_rn_links.iteritems():\n",
    "        rcn_graph.add_node(node,cpds=cpds)\n",
    "    \n",
    "    rcn_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in connected_edges.iteritems()])\n",
    "    rcn_graph=remove_self_loops(rcn_graph)\n",
    "    return rcn_graph\n",
    "\n",
    "def remove_self_loops(networkx_graph):\n",
    "    for edge in networkx_graph.edges():\n",
    "        if edge[0]==edge[1]: #self -loop\n",
    "            networkx_graph.remove_edge(*edge)\n",
    "    return networkx_graph\n",
    "\n",
    "def remove_set_data_edges(reaction_graph,item_name):\n",
    "    new_graph=reaction_graph.copy()\n",
    "    new_items={edge:\";\".join(cpd_overlap) for edge, cpd_overlap in nx.get_edge_attributes(reaction_graph,item_name).iteritems()}\n",
    "    nx.set_edge_attributes(new_graph,item_name,new_items)\n",
    "    return new_graph\n",
    "\n",
    "def remove_set_data_nodes(rcn_graph,item_name):\n",
    "    new_graph=rcn_graph.copy()\n",
    "    new_cpds={node:\";\".join(cpd_list) for node, cpd_list in nx.get_node_attributes(rcn_graph,item_name).iteritems()}\n",
    "    nx.set_node_attributes(new_graph,item_name,new_cpds)\n",
    "    return new_graph\n",
    "\n",
    "def save_reaction_graph(rcn_graph,outfile):\n",
    "    rcn_graph=remove_set_data_edges(rcn_graph,\"overlap\")\n",
    "    rcn_graph=remove_set_data_nodes(rcn_graph,\"cpds\")\n",
    "    nx.write_graphml(rcn_graph, outfile)\n",
    "    return\n",
    "\n",
    "#nx.write_graphml(rcn_graph, os.path.join(output_dir,'graphs{0}{1}_reaction_graph_single_genome.xml'.format(os.sep,\"coral\")))\n",
    "def top_k_hits(list_items,k):\n",
    "    from collections import Counter\n",
    "    return sorted(Counter(list_items).iteritems(),key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "def load_graphs(input_folder,glob_name):\n",
    "    graph_dict={}\n",
    "    for fname in glob(os.path.join(input_folder,glob_name)):\n",
    "        base=os.path.basename(fname)\n",
    "        genome_id=base.split('_graph_')[0] #Get Genome id\n",
    "        graph_=nx.read_graphml(fname)\n",
    "        string_to_set(graph_,\"overlap\",\"cpds\")\n",
    "        graph_.name=genome_id\n",
    "        graph_dict[genome_id]=graph_\n",
    "    return graph_dict\n",
    "\n",
    "def string_to_set(rcn_graph,edge_item,node_item):\n",
    "    new_edge_data={edge:set(cpds.split(\";\")) for edge, cpds in nx.get_edge_attributes(rcn_graph,edge_item).iteritems()}\n",
    "    nx.set_edge_attributes(rcn_graph,edge_item,new_edge_data)\n",
    "    new_node_data={node:set(cpds.split(\";\")) for node,cpds in nx.get_node_attributes(rcn_graph,node_item).iteritems()}\n",
    "    nx.set_node_attributes(rcn_graph,node_item,new_node_data)  \n",
    "    \n",
    "    return None\n",
    "\n",
    "def merge_graphs(rcn_graph1,rcn_graph2,commond_cpds):\n",
    "    '''Creates a merged graph from a pair of graphs. This is done by finding the reactions\n",
    "    unique to each genome and then scanning all of the reactions in the other genome to create new links.\n",
    "    Input:\n",
    "        rcn_graph1    - The first reaction graph.\n",
    "        rcn_graph2    - The second reaction graph.\n",
    "        common_cpds   - The set of uninteresting or hyperconnected compounds.\n",
    "    Output:\n",
    "        merged_graph  - A graph created from merging rcn_graph1 and rcn_graph2\n",
    "    '''\n",
    "    \n",
    "    graph_1_node_compounds=nx.get_node_attributes(rcn_graph1,\"cpds\")\n",
    "    graph_2_node_compounds=nx.get_node_attributes(rcn_graph2,\"cpds\")\n",
    "    graph_1_nodes=set(graph_1_node_compounds.keys())\n",
    "    graph_2_nodes=set(graph_2_node_compounds.keys())\n",
    "    graph_1_unique_nodes=graph_1_nodes-graph_2_nodes\n",
    "    graph_2_unique_nodes=graph_2_nodes-graph_1_nodes\n",
    "    shared_nodes=graph_1_nodes & graph_2_nodes\n",
    "    \n",
    "    graph_1_uniq_links=connect_reactions(graph_2_node_compounds,graph_1_unique_nodes,graph_1_node_compounds,common_cpds)\n",
    "    \n",
    "    graph_2_uniq_links=connect_reactions(graph_1_node_compounds,graph_2_unique_nodes,graph_2_node_compounds,common_cpds)\n",
    "    \n",
    "    merged_graph=rcn_graph1.copy()\n",
    "    merged_graph.name=rcn_graph1.name+\":\"+rcn_graph2.name\n",
    "    merged_graph.add_nodes_from([(node,{\"cpds\":graph_2_node_compounds[node]})for node in graph_2_unique_nodes],genome=rcn_graph2.name)\n",
    "    nx.set_node_attributes(merged_graph,\"genome\",{node:rcn_graph1.name+\":\"+rcn_graph2.name for node in shared_nodes})\n",
    "    nx.set_node_attributes(merged_graph,\"genome\",{node:rcn_graph1.name for node in graph_1_unique_nodes})\n",
    "    \n",
    "    merged_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in graph_1_uniq_links.iteritems()])\n",
    "    merged_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in graph_2_uniq_links.iteritems()])\n",
    "    \n",
    "    return merged_graph\n",
    "\n",
    "def connect_reactions(node_cpd_pairs_to_join,new_nodes,new_node_cpd_pairs,common_cpds):\n",
    "    '''Find the connections between reactions from two different sets of reactions or between the pairings\n",
    "    of new nodes.\n",
    "    \n",
    "    Input:\n",
    "    Output:\n",
    "    '''\n",
    "    new_rn_cpd_pairs={rn:cpds for rn,cpds in new_node_cpd_pairs.iteritems() if rn in new_nodes}\n",
    "    connected_edges={}\n",
    "    for reac_1, reac_2 in itertools.product(new_rn_cpd_pairs.iterkeys(),node_cpd_pairs_to_join.iterkeys()):\n",
    "        cpds_1=new_rn_cpd_pairs[reac_1]\n",
    "        cpds_2=node_cpd_pairs_to_join[reac_2]\n",
    "        link=(cpds_1 & cpds_2) - common_cpds\n",
    "        if len(link)>0:\n",
    "            connected_edges[(reac_1,reac_2)]=link\n",
    "            \n",
    "    for reac_1, reac_2 in itertools.combinations(new_rn_cpd_pairs.iterkeys(),2):\n",
    "        cpds_1=new_rn_cpd_pairs[reac_1]\n",
    "        cpds_2=new_rn_cpd_pairs[reac_2]\n",
    "        link=(cpds_1 & cpds_2) - common_cpds\n",
    "        if len(link)>0:\n",
    "            connected_edges[(reac_1,reac_2)]=link\n",
    "            \n",
    "    return connected_edges\n",
    "    \n",
    "def pairwise_merged_graphs(genome_reaction_graphs,to_analyse):\n",
    "    if not to_analyse:\n",
    "        pairwise_merged_genomes={}\n",
    "    else:\n",
    "        pass\n",
    "    for genome_1,genome_2 in itertools.combinations(genome_reaction_graphs.iterkeys(),2):\n",
    "        merged_genome=merge_graphs(genome_reaction_graphs[genome_1],genome_reaction_graphs[genome_2],common_cpds)\n",
    "        if to_analyse:\n",
    "            analyse_merged_graph(merged_genome)\n",
    "        else:\n",
    "            pairwise_merged_genomes[(genome_1,genome_2)]=merged_genome\n",
    "    if not to_analyse:\n",
    "        return pairwise_merged_genomes\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def analyse_merged_graph(merged_graph):\n",
    "    return None\n",
    "\n",
    "def extract_starting_ending_reactions(reaction_graph,start_cpd,end_cpd,item_name):\n",
    "    start_rns=set([])\n",
    "    end_rns=set([])\n",
    "    for reaction_data in reaction_graph.nodes_iter(data=True):\n",
    "        cpds=reaction_data[1][item_name]\n",
    "        start=cpds & set([start_cpd])\n",
    "        end=cpds & set([end_cpd])\n",
    "        if len(start)>0:\n",
    "            start_rns.add(reaction_data[0])\n",
    "        if len(end)>0:\n",
    "            end_rns.add(reaction_data[0])\n",
    "    return start_rns, end_rns\n",
    "\n",
    "def extract_all_starting_ending_reacitons(reaction_graph, start_end_pairs,item_name):\n",
    "    start_rns=defaultdict(set)\n",
    "    end_rns=defaultdict(set)\n",
    "    paired_reactions=[]\n",
    "    for reaction_data in reaction_graph.nodes_iter(data=True):\n",
    "        cpds=reaction_data[1][item_name]\n",
    "        for start_cpd, end_cpd in start_end_pairs:\n",
    "            start=cpds & set([start_cpd])\n",
    "            end=cpds & set([end_cpd])\n",
    "            if len(start)>0:\n",
    "                start_rns[start_cpd].add(reaction_data[0])\n",
    "            if len(end)>0:\n",
    "                end_rns[end_cpd].add(reaction_data[0])\n",
    "                \n",
    "    for start_cpd,end_cpd in start_end_pairs:\n",
    "        yield start_rns[start_cpd],end_rns[end_cpd]\n",
    "        \n",
    "def all_reaction_pairs(start_end_iter):\n",
    "    for start_rns, end_rns in start_end_iter:\n",
    "        for start_rn,end_rn in itertools.product(start_rns,end_rns):\n",
    "            yield start_rn, end_rn\n",
    "            \n",
    "def _unique_compounds(merged_graph,genome_id):\n",
    "    uniq_rns=set([])\n",
    "    for node_data in merged_graph.nodes_iter(data=True):\n",
    "        if node_data[1]['genome']==genome_id or genome_id not in node_data[1]['genome']:\n",
    "            uniq_rns.add(node_data[0])\n",
    "    return unique_rns\n",
    "\n",
    "def _unique_compound_pairs(merged_graph,genome_id_pair):\n",
    "    gen_1_uniq_rns=set([])\n",
    "\n",
    "    gen_2_uniq_rns=set([])\n",
    "    genome_id_1,genome_id_2=genome_id_pair\n",
    "    for node_data in merged_graph.nodes_iter(data=True):\n",
    "        if node_data[1]['genome']==genome_id_1:\n",
    "            gen_1_uniq_rns.add(node_data[0])\n",
    "        if node_data[1]['genome']==genome_id_2:\n",
    "            gen_2_uniq_rns.add(node_data[0])\n",
    "    return gen_1_uniq_rns,gen_2_uniq_rns\n",
    "\n",
    "def automatic_difference_check(pairwise_merged_graph):\n",
    "    latest_genome=pairwise_merged_graph.name.split(\":\")\n",
    "    old_name=\":\".join(latest_genome[:-1])\n",
    "    latest_genome=latest_genome[-1]\n",
    "    gen_1_reactions, gen_2_reactions=_unique_compound_pairs(pairwise_merged_graph,(old_name,latest_genome))\n",
    "    pairwise_paths={}\n",
    "    for rcn1, rcn2 in itertools.product(gen_1_reactions,gen_2_reactions):\n",
    "        pairwise_paths[rcn1,rcn2]=find_paths(pairwise_merged_graph,rcn1,rcn2)\n",
    "    return pairwise_paths\n",
    "\n",
    "def write_graph_dict(output_dir, graph_dict,pairs):\n",
    "    if pairs:\n",
    "        for genome_pair,genome in graph_dict.iteritems():\n",
    "            save_reaction_graph(genome,os.path.join(output_dir,\"{0}_graph_merged_genome_reactions.xml\".format(\"|\".join(genome_pair))))\n",
    "    else:\n",
    "        for genome, graph in graph_dict.iteritems():\n",
    "            save_reaction_graph(graph, os.path.join(\"{0}_graph_single_genome_reactions.xml\".format(genome)))\n",
    "        \n",
    "def store_local_kegg_item_keys(kegg_items,database_dir):\n",
    "    kc=kegg.KeggClientRest()\n",
    "    all_item_names={}\n",
    "    illegal_pairs=[(\"compound\",\"orthology\"),(\"orthology\",\"compound\")]\n",
    "    for kegg_item in kegg_items:\n",
    "        key_name=os.path.join(database_dir,\"{0}_readable_names.tsv\".format(kegg_item))\n",
    "        if not os.path.isfile(key_name):\n",
    "            item_names=kc.get_ids_names(kegg_item)\n",
    "            save_readable_key(key_name,item_names,kegg_item)\n",
    "            all_item_names[kegg_item]=item_names.keys()\n",
    "        else:\n",
    "            all_item_names[kegg_item]=load_readable_names(database_dir,[kegg_item],False)[kegg_item].keys()\n",
    "    for kegg_item_1, kegg_item_2 in itertools.permutations(all_item_names.iterkeys(),2):\n",
    "        print \"considering the pair: {0}, {1}\".format(kegg_item_1,kegg_item_2)\n",
    "        if (kegg_item_1,kegg_item_2) not in illegal_pairs:\n",
    "            shared_key_name=os.path.join(database_dir,\"{0}_linked_{1}_database.tsv\").format(kegg_item_1, kegg_item_2)\n",
    "            if not os.path.isfile(shared_key_name):\n",
    "                print \"The processing of pair: {0},{1} has begun.\".format(kegg_item_1,kegg_item_2)\n",
    "                kc=kegg.KeggClientRest()\n",
    "                linked_ids=kc.link_ids(kegg_item_2,all_item_names[kegg_item_1])\n",
    "                save_key_pairings(shared_key_name,linked_ids,(kegg_item_1,kegg_item_2))\n",
    "        else:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "def load_local_kegg_database_pairings(database_dir,kegg_item_pairs, process_all):\n",
    "    '''Loads the local databases of kegg_item_1, kegg_item_2 pairings and return a dictionary of\n",
    "    these pairings in the form kegg_item_1:kegg_items_2 (There can be more than one linked item). This\n",
    "    loading is based on the earlier use of mgkits kc.link_ids to store all of the pairings needed.\n",
    "    \n",
    "    Input:\n",
    "        database_dir   - The directory with the databases\n",
    "        kegg_item_pairs- A list of kegg item pairs to load\n",
    "        process_all    - A boolean decision as whether to load all existing pairs.\n",
    "        \n",
    "    Output: A dictionary linking either all existing kegg item pairs or just those specified. It has the form\n",
    "    dict[item_1,item_2]={kegg_item_1:kegg_2_items}'''\n",
    "    linking_dictionary={}\n",
    "    if process_all:\n",
    "        for file_name in glob(os.path.join(database_dir,'*database.tsv')):\n",
    "            db_file=os.basename(file_name)\n",
    "            kegg_1=db_file.split(\"_linked_\")[0]\n",
    "            kegg_2=db_file.split(\"_linked_\")[1].split(\"_database\")[0]\n",
    "            linking_dictionary[(kegg_1,kegg_2)]={}             \n",
    "            with open(file_name) as kegg_links:\n",
    "                next(kegg_links)#Skip the header\n",
    "                for line in kegg_links:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    item_2=item_2.split(\";\")\n",
    "                    linking_dictionary[kegg_item_pair][item_1]=item_2\n",
    "        return linking_dictionary\n",
    "    \n",
    "    for kegg_item_pair in kegg_item_pairs:\n",
    "        file_name=os.path.join(database_dir,\"{0}_linked_{1}_database.tsv\").format(kegg_item_pair[0], kegg_item_pair[1])\n",
    "        if os.path.isfile(file_name):\n",
    "            linking_dictionary[kegg_item_pair]={}\n",
    "            with open(file_name) as kegg_links:\n",
    "                next(kegg_links) #skip the header\n",
    "                for line in kegg_links:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    item_2=item_2.split(\";\")\n",
    "                    linking_dictionary[kegg_item_pair][item_1]=item_2\n",
    "    return linking_dictionary\n",
    "                    \n",
    "def load_readable_names(database_dir,kegg_items,process_all):\n",
    "    '''Loads in the readable names for a specified kegg item from a list of databases.\n",
    "    Input:\n",
    "        database_dir        -  The directory with the databases.\n",
    "        kegg_items          -  The kegg items to get the readable mapping for.\n",
    "        process_all         -  Boolean - Should the function retrieve all available databases.\n",
    "    Output:\n",
    "        readable_item_dict  -  A dictionary of KEGG_ID: Readable name pairs'''\n",
    "    readable_item_dict={}\n",
    "    if process_all:\n",
    "        for file_name in glob(os.path.join(database_dir,'*_readable_names.tsv')):\n",
    "            desc_file=os.basename(file_name)\n",
    "            kegg_item=desv_file.split(\"_readable_names.tsv\")[0]\n",
    "            readable_item_dict[kegg_item]={}\n",
    "            with open(file_name) as kegg_descriptions:\n",
    "                next(kegg_descriptions)\n",
    "                for line in kegg_descriptions:\n",
    "                    item_1,item_2=line.strip().split(\"\\t\")\n",
    "                    readable_item_dict[kegg_item][item_1]=item_2\n",
    "        return readable_item_dict\n",
    "    \n",
    "    for kegg_item in kegg_items:\n",
    "        file_name=os.path.join(database_dir,'{0}_readable_names.tsv'.format(kegg_item))\n",
    "        readable_item_dict[kegg_item]={}\n",
    "        with open(file_name) as kegg_descriptions:\n",
    "            next(kegg_descriptions)\n",
    "            for line in kegg_descriptions:\n",
    "                item_1,item_2=line.strip().split(\"\\t\")\n",
    "                readable_item_dict[kegg_item][item_1]=item_2\n",
    "    return readable_item_dict\n",
    "            \n",
    "            \n",
    "def save_readable_key(key_name,item_names,kegg_item):\n",
    "    df=pd.DataFrame([\n",
    "    [col1,col2] for col1,col2 in item_names.iteritems()\n",
    "                   ])\n",
    "    df.columns=[kegg_item,\"Description\"]\n",
    "    df.to_csv(key_name,sep=\"\\t\",index=None)\n",
    "    return None\n",
    "\n",
    "def save_key_pairings(shared_key_name,item_links,kegg_item_tuple):\n",
    "    df=pd.DataFrame([\n",
    "            [col1,\";\".join(col2)] for col1, col2 in item_links.iteritems()\n",
    "        ])\n",
    "    df.columns=[kegg_item_tuple[0],kegg_item_tuple[1]]\n",
    "    df.to_csv(shared_key_name,sep=\"\\t\",index=None)\n",
    "    return None\n",
    "\n",
    "def remove_ko_pth_hits(file_path):\n",
    "    \n",
    "    with open(file_path,'r') as KO_PTH_pairs:\n",
    "        out_dir=os.path.dirname(file_path)\n",
    "        temp_file=open(os.path.join(out_dir,\"temp.tsv\"),'w')\n",
    "        for line in KO_PTH_pairs:\n",
    "            KO,pathways=line.strip().split(\"\\t\")\n",
    "            pathways=pathways.split(\";\")\n",
    "            pathways=[pathway for pathway in pathways if not pathway.startswith(\"ko\")]\n",
    "            pathways=\";\".join(pathways)\n",
    "            new_line=\"{0}\\t{1}\\n\".format(KO,pathways)\n",
    "            temp_file.write(new_line)\n",
    "    temp_file.close()\n",
    "    \n",
    "#FROM NETWORKX DOCUMENTATION\n",
    "def k_shortest_paths(graph,start,end,k,weight=None):\n",
    "    '''Returns the k shorest paths going from the start node to end node base on the weight values.'''\n",
    "    return list(itertools.islice(nx.shortest_simple_paths(graph,start,end,weight=weight),k))\n",
    "\n",
    "def extract_successor_neighbours(G,node, rcn_eqn_data,eqn_pair,cpd=None):\n",
    "    if isinstance(cpd,type(None)):\n",
    "        neighbours=G.neighbors(node)\n",
    "        for neighbour in neighbours:\n",
    "            yield neighbour\n",
    "    else:\n",
    "        out_compounds=set([])\n",
    "        current_node=rcn_eqn_data[node]\n",
    "        for side_1,side_2 in eqn_pair.iteritems():\n",
    "            init_cpds=cpd & current_node[side_1]\n",
    "            if len(init_cpds)>0:\n",
    "                out_compounds.update(current_node[side_2])                \n",
    "        for edge in G.edges_iter(node,data=True):\n",
    "            new_connection=edge[2][\"overlap\"] & out_compounds\n",
    "            if len(new_connection)>0:\n",
    "                #print edge\n",
    "                yield edge[1],edge[2][\"overlap\"]\n",
    "            \n",
    "def extract_predecessor_neighbours(G,node,rcn_eqn_data,eqn_pair,cpd=None):\n",
    "    if isinstance(cpd,type(None)):\n",
    "        neighbours=G.neighbors(node)\n",
    "        for neighbour in neighbours:\n",
    "            yield neighbour\n",
    "    else:\n",
    "        out_compounds=set([])\n",
    "        current_node=rcn_eqn_data[node]\n",
    "        for side_1,side_2 in eqn_pair.iteritems():\n",
    "            init_cpds=cpd & current_node[side_1]\n",
    "            if len(init_cpds)>0:\n",
    "                out_compounds.update(current_node[side_1])            \n",
    "        for edge in G.edges_iter(node,data=True):\n",
    "            new_connection=edge[2][\"overlap\"] & out_compounds\n",
    "            if len(new_connection)>0:\n",
    "                #print edge\n",
    "                yield edge[1],edge[2][\"overlap\"]\n",
    "\n",
    "def predecessor_neighbours(G,node,rcn_eqn_data,eqn_pair,cpd):\n",
    "    return list(extract_predecessor_neighbours(G,node,rcn_eqn_data,eqn_pair,cpd))\n",
    "\n",
    "def successor_neighbours(G,node,rcn_eqn_data,eqn_pair,cpd):\n",
    "    return list(extract_successor_neighbours(G,node,rcn_eqn_data,eqn_pair,cpd))\n",
    "        \n",
    "def get_eqn_pair():\n",
    "    return {'side_2_cpds':'side_1_cpds','side_1_cpds':'side_2_cpds'}\n",
    "\n",
    "def store_unique_cpd_rn_node_graphs(Genome_ko_hits,common_cpds,reaction_dir,output_dir,database_dir,double_links):\n",
    "    rn_cpd_gen_links,ko_rn_gen_links=generate_links(Genome_ko_hits,output_dir)\n",
    "    rcn_eqn_links=load_local_rcn_eqn_database_set(database_dir)\n",
    "    \n",
    "    side_pairs={'side_2_cpds':'side_1_cpds','side_1_cpds':'side_2_cpds'}\n",
    "    \n",
    "    cpd_gen_graph={}\n",
    "    \n",
    "    against_side_spec_rn_links=make_side_specific_cpd_links(rn_cpd_gen_links,rcn_eqn_links,side_pairs,common_cpds)\n",
    "    print \"The graphs are being made.\"\n",
    "    \n",
    "    start_time=datetime.datetime.now()\n",
    "    for genome, rn_dict in against_side_spec_rn_links.iteritems():\n",
    "        current_time=datetime.datetime.now()\n",
    "        print \"{1} has started being processed at: {0}\".format(current_time,genome)\n",
    "        print \"Duration since start: {0}\".format(current_time-start_time)\n",
    "        file_name=os.path.join(reaction_dir,\"{0}_graph_side_specific_single_genome_reactions.xml\".format(genome))\n",
    "        if not os.path.isfile(file_name):\n",
    "            current_graph=create_unique_reaction_graph(rn_dict,common_cpds,double_links)\n",
    "            save_reaction_graph(current_graph,file_name)\n",
    "            print \"Duration of making graph {0}\".format(datetime.datetime.now()-current_time)\n",
    "        \n",
    "    return\n",
    "\n",
    "def make_side_specific_cpd_links(rn_cpd_links,rcn_eqn_links,opposing_sides,common_cpds):\n",
    "    all_viable_rns=set(rcn_eqn_links.keys())\n",
    "    side_spec_gen_rns={}\n",
    "\n",
    "    for genome, rn_cpds in rn_cpd_links.iteritems():\n",
    "        side_spec_gen_rns[genome]={}\n",
    "        linkable_RNs=all_viable_rns & set(rn_cpds.keys())\n",
    "        for RN in linkable_RNs:\n",
    "            for side, cpds in rcn_eqn_links[RN].iteritems():\n",
    "                cleaned_cpds=cpds-common_cpds\n",
    "                if len(cleaned_cpds)>0:\n",
    "                    for cpd in cleaned_cpds:\n",
    "                        side_spec_gen_rns[genome][\";\".join([RN,cpd])]=rcn_eqn_links[RN][opposing_sides[side]]\n",
    "    return side_spec_gen_rns\n",
    "\n",
    "\n",
    "def create_unique_reaction_graph(against_rn_links,common_cpds,double_links):\n",
    "    connected_edges={}\n",
    "    N_double_links=0\n",
    "    for reac_1, reac_2 in itertools.combinations(against_rn_links.iterkeys(),2):\n",
    "        \n",
    "        both=0\n",
    "        node_name_1=reac_1.split(\";\")\n",
    "        node_name_2=reac_2.split(\";\")\n",
    "        \n",
    "        if node_name_1[0]!=node_name_2[0]:\n",
    "            cpds_1=against_rn_links[reac_1]\n",
    "            cpd_2=set([node_name_2[1]])\n",
    "            link=(cpds_1 & cpd_2)\n",
    "            if len(link)>0:\n",
    "                connected_edges[(reac_1,reac_2)]=link\n",
    "                both+=1\n",
    "\n",
    "            cpds_1=against_rn_links[reac_2]\n",
    "            cpd_2=set([node_name_1[1]])\n",
    "            link=(cpds_1 & cpd_2)-common_cpds\n",
    "            if len(link)>0:\n",
    "                connected_edges[(reac_2,reac_1)]=link\n",
    "                both+=1\n",
    "\n",
    "            if both==2:\n",
    "                if not double_links:\n",
    "                    connected_edges.pop((reac_1,reac_2))\n",
    "                    connected_edges.pop((reac_2,reac_1))\n",
    "                else:\n",
    "                    connected_edges[(reac_1,reac_2)]=connected_edges[(reac_1,reac_2)]|connected_edges.pop((reac_2,reac_1))\n",
    "                N_double_links+=1\n",
    "                \n",
    "    print \"There were {0} doubly linked reactions in this set of comparisons.\".format(N_double_links)\n",
    "    \n",
    "    rcn_graph=nx.DiGraph()\n",
    "    for node,cpds in against_rn_links.iteritems():\n",
    "        rcn_graph.add_node(node,cpds=cpds)\n",
    "    \n",
    "    rcn_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in connected_edges.iteritems()])\n",
    "    rcn_graph=remove_self_loops(rcn_graph)\n",
    "    return rcn_graph\n",
    "\n",
    "\n",
    "def merge_directed_input_specific_rn_graphs(rcn_graph1, rcn_graph2, common_cpds):\n",
    "    '''Creates a merged graph from a pair of graphs. This is done by finding the reactions\n",
    "    unique to each genome and then scanning all of the reactions in the other genome to create new links.\n",
    "    Input:\n",
    "        rcn_graph1    - The first reaction graph.\n",
    "        rcn_graph2    - The second reaction graph.\n",
    "        common_cpds   - The set of uninteresting or hyperconnected compounds.\n",
    "    Output:\n",
    "        merged_graph  - A graph created from merging rcn_graph1 and rcn_graph2\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    graph_1_node_compounds=nx.get_node_attributes(rcn_graph1,\"cpds\")\n",
    "    graph_2_node_compounds=nx.get_node_attributes(rcn_graph2,\"cpds\")\n",
    "    graph_1_nodes=set(graph_1_node_compounds.keys())\n",
    "    graph_2_nodes=set(graph_2_node_compounds.keys())\n",
    "    graph_1_unique_nodes=graph_1_nodes-graph_2_nodes\n",
    "    graph_2_unique_nodes=graph_2_nodes-graph_1_nodes\n",
    "    shared_nodes=graph_1_nodes & graph_2_nodes\n",
    "    \n",
    "    graph_1_uniq_links=connect_reactions(graph_2_node_compounds,graph_1_unique_nodes,graph_1_node_compounds,common_cpds)\n",
    "    \n",
    "    graph_2_uniq_links=connect_reactions(graph_1_node_compounds,graph_2_unique_nodes,graph_2_node_compounds,common_cpds)\n",
    "    \n",
    "    merged_graph=rcn_graph1.copy()\n",
    "    merged_graph.name=rcn_graph1.name+\":\"+rcn_graph2.name\n",
    "    merged_graph.add_nodes_from([(node,{\"cpds\":graph_2_node_compounds[node]})for node in graph_2_unique_nodes],genome=rcn_graph2.name)\n",
    "    nx.set_node_attributes(merged_graph,\"genome\",{node:rcn_graph1.name+\":\"+rcn_graph2.name for node in shared_nodes})\n",
    "    nx.set_node_attributes(merged_graph,\"genome\",{node:rcn_graph1.name for node in graph_1_unique_nodes})\n",
    "    \n",
    "    merged_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in graph_1_uniq_links.iteritems()])\n",
    "    merged_graph.add_edges_from([edge+({\"overlap\":overlap,\"weight\":0.5},) for edge, overlap in graph_2_uniq_links.iteritems()])\n",
    "    \n",
    "    return merged_graph\n",
    "\n",
    "def connect_directed_reactions(graph_1_node_compounds,unique_nodes,graph_2_node_compounds ,common_cpds):\n",
    "    \n",
    "    return\n",
    "\n",
    "def unique_cpds_graph_pair(graph_1,graph_2):\n",
    "    \n",
    "    all_cpds_g1=set(itertools.chain(*nx.get_node_attributes(graph_1,\"cpds\").itervalues()))\n",
    "    all_cpds_g2=set(itertools.chain(*nx.get_node_attributes(graph_2,\"cpds\").itervalues()))\n",
    "    uniq_g1=all_cpds_g1- all_cpds_g2\n",
    "    uniq_g2=all_cpds_g2- all_cpds_g1\n",
    "    \n",
    "    unique_cpds={graph_1.name:uniq_g1,graph_2.name:uniq_g2}\n",
    "    \n",
    "    return unique_cpds\n",
    "\n",
    "def pairwise_unique_cpds(genome_graph_dict):\n",
    "    unique_cpds={}\n",
    "    for genome_1, genome_2 in itertools.combinations(genome_graph_dict.iterkeys(),2):\n",
    "        unique_cpds[(genome_1,genome_2)]=unique_cpds_graph_pair(genome_graph_dict[genome_1],genome_graph_dict[genome_2])\n",
    "    \n",
    "    return unique_cpds\n",
    "\n",
    "def write_uniq_compounds(output_file,uniq_cpds):\n",
    "    return\n",
    "\n",
    "def get_starting_nodes(rn_graph,cpd):\n",
    "    '''Extract all nodes matching the specific compound in the graph. This extracts that compound as the starting\n",
    "    compound for the reaction.\n",
    "    '''\n",
    "    node_names=np.array(rn_graph.nodes())\n",
    "    matching_nodes=[]\n",
    "    for element in node_names:\n",
    "        if element.endswith(cpd):\n",
    "            matching_nodes.append(element)\n",
    "    return matching_nodes\n",
    "\n",
    "def get_ending_nodes(rn_graph,cpd):\n",
    "    '''Extract all nodes where the cpd is an end product.'''\n",
    "    cpd_data=nx.get_node_attributes(rn_graph,\"cpds\")\n",
    "    matching_nodes=[]\n",
    "    for node, cpds in cpd_data.iteritems():\n",
    "        if cpd in cpds:\n",
    "            matching_nodes.append(node)\n",
    "    return  matching_nodes\n",
    "\n",
    "def extract_node_pairs(rn_graph,starting_cpds,ending_cpds):\n",
    "    start_cpd_nodes={}\n",
    "    end_cpd_nodes={}\n",
    "    failures={}\n",
    "    failures[\"starts\"]=[]\n",
    "    failures[\"ends\"]=[]\n",
    "    for cpd_1 in starting_cpds:\n",
    "        cpd_1_nodes=get_starting_nodes(rn_graph,cpd_1)\n",
    "        if len(cpd_1_nodes)>0:\n",
    "            start_cpd_nodes[cpd_1]=cpd_1_nodes\n",
    "        else:\n",
    "            failures[\"starts\"].append(cpd_1)\n",
    "    for cpd_2 in ending_cpds:\n",
    "        cpd_2_nodes=get_ending_nodes(rn_graph,cpd_2)\n",
    "        if len(cpd_2_nodes)>0:\n",
    "            end_cpd_nodes[cpd_2]=cpd_2_nodes\n",
    "        else:\n",
    "            failures[\"ends\"].append(cpd_2)\n",
    "    return start_cpd_nodes,end_cpd_nodes,failures\n",
    "\n",
    "#FROM NETWORKX DOCUMENTATION\n",
    "def k_shortest_paths(graph,start,end,k,weight=None):\n",
    "    return list(itertools.islice(nx.shortest_simple_paths(graph,start,end,weight=weight),k))\n",
    "##############################\n",
    "def extract_pathways(graph, cpd_pairs,output_file):\n",
    "    start_cpds,end_cpds=zip(*cpd_pairs)\n",
    "    start_cpd_nodes,end_cpd_nodes, failures=extract_node_pairs(graph, start_cpds,end_cpds)\n",
    "    path_data={}\n",
    "    for (cpd_1,cpd_2) in cpd_pairs:\n",
    "        path_data[(cpd_1,cpd_2)]={}\n",
    "        start_nodes=start_cpd_nodes[cpd_1]\n",
    "        end_nodes=end_cpd_nodes[cpd_2]\n",
    "        for node_1,node_2 in itertools.product(start_nodes,end_nodes):\n",
    "            path_data[(cpd_1,cpd_2)][(node_1,node_2)]=k_shortest_paths(graph,node_1,node_2,k)\n",
    "    return path_data\n",
    "\n",
    "def make_pd_dataframe(genome_path_data):\n",
    "    pd.df([\n",
    "            []\n",
    "        ])\n",
    "    return\n",
    "\n",
    "def save_path_data(path_data,outfile):\n",
    "        \n",
    "    return\n",
    "\n",
    "def networkx_k_shortest_paths(graph,cpds1,cpds2,k):\n",
    "    if len(cpds1)!=len(cpds2):\n",
    "        print \"The cpds must came as start, end pairs. There must be the same number of starting nodes as finishing nodes\"\n",
    "        return None\n",
    "    cpd_pair_k_shortest_paths={}\n",
    "    graph_cpds=graph.nodes()\n",
    "    for (start,end) in itertools.izip(cpds1,cpds2):\n",
    "        if start in graph_cpds and end in graph_cpds:\n",
    "            cpd_pair_k_shortest_paths[(start,end)]=k_shortest_paths(graph,start,end,k)\n",
    "        else:\n",
    "            cpd_pair_k_shortest_paths[(start,end)]=[[]]\n",
    "    return cpd_pair_k_shortest_paths\n",
    "\n",
    "def shortest_path_to_pd_dataframe(shortest_paths,database_dir):\n",
    "    cpd_names =load_readable_names(database_dir,[\"compound\"],False)[\"compound\"]\n",
    "    rn_names  = load_readable_names(database_dir,[\"reaction\"],False)[\"reaction\"]\n",
    "    \n",
    "    df=pd.DataFrame([\n",
    "            [cpd1, cpd2, cpd_names[cpd1],cpd_names[cpd2],\"||\".join(clean_path(path,cpd_names,rn_names,readable=False)), \"||\".join(clean_path(path,cpd_names,rn_names,readable=True))] for (cpd1, cpd2), path in shortest_paths.iteritems() \n",
    "        ])\n",
    "    df.columns=[\"Start_CPD_ID\",\"End_CPD_ID\",'Start_CPD',\"End_compound\",\"CPD_PATH\",\"READABLE_CPD_PATH\"]\n",
    "    return df\n",
    "\n",
    "def clean_path(path,readable=False,cpd_names=None,rn_names=None):\n",
    "    #cpd_names =load_readable_names(database_dir,[\"compound\"],False)[\"compound\"]\n",
    "    #rn_names  = load_readable_names(database_dir,[\"reaction\"],False)[\"reaction\"]\n",
    "    cleaned_path=[]\n",
    "    for node in path:\n",
    "        rn,cpd=node.split(\";\")\n",
    "        if readable:\n",
    "            rn=rn_names[rn]\n",
    "            cpd=cpd_names[cpd]\n",
    "        cleaned_node=\"{0}({1})\".format(rn,cpd)\n",
    "        cleaned_path.append(cleaned_node)\n",
    "    return cleaned_path\n",
    "\n",
    "def save_output(pd_path_dataframe,output_file):\n",
    "    pd_path_dataframe.to_csv(output_file,sep=\"\\t\",header=True,index=False)\n",
    "    return None\n",
    "\n",
    "def shortest_paths_pd_dataframe(k_shortest_paths):\n",
    "    kc = kegg.KeggClientRest()\n",
    "    cpd_names = kc.get_ids_names('compound')\n",
    "    df=pd.DataFrame([\n",
    "            [cpd1, cpd2, cpd_names[cpd1],cpd_names[cpd2],\"||\".join(path), \"||\".join([cpd_names[cpd] for cpd in path])] for (cpd1, cpd2), paths in k_shortest_paths.iteritems() for path in paths \n",
    "        ])\n",
    "    df.columns=[\"KEGGCpd1ID\",\"KEGGCpd2ID\",'CPD1_readable',\"CPD2_readable\",\"CPD_PATH\",\"READABLE_CPD_PATH\"]\n",
    "    return df\n",
    "\n",
    "def is_biological(path,rcn_eqn_pairs):\n",
    "    '''Does a simple screen for whether a path makes biological sense.\n",
    "    One of this key criteria is that if a compound was used as an auxilliary input\n",
    "    then it should not later be a key ongoing compound. Using the same compound to \n",
    "    produce itself later is inefficient and doesn't make sense.\n",
    "    Input:\n",
    "        path    -    list\n",
    "            List of nodes representing a path through the graph.\n",
    "        rcn_eqn_pairs    -    dict\n",
    "            A dictionary of reactions paired with there equation information, i.e\n",
    "            the compounds which are products and reactants separately based on \n",
    "            context.\n",
    "    Output:\n",
    "        isbiological    -    Boolean\n",
    "            Does the path make biological sense.'''\n",
    "    \n",
    "    in_cpds=[]\n",
    "    extra_in_cpds=[]\n",
    "    for node in path:\n",
    "        rn,cpd=node.split(\";\")\n",
    "        in_cpds.append(cpd)\n",
    "        extras=rcn_eqn_pairs[rn]\n",
    "        in_side=which_side_rcn(cpd,extras)\n",
    "        extra_in_cpds.extend(extras[in_side]-set([cpd]))\n",
    "    in_cpds=set(in_cpds)\n",
    "    extra_in_cpds=set(extra_in_cpds)\n",
    "    shared_cpds= in_cpds & extra_in_cpds\n",
    "    if len(shared_cpds)>0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def which_side_rcn(cpd, eqn_rcn_pair):\n",
    "    '''Decides which side of the reaction you are on based on the cpd.'''\n",
    "    sides=\"\"\n",
    "    for side,cpds in eqn_rcn_pair.iteritems():\n",
    "        if cpd in cpds:\n",
    "            sides=side\n",
    "    return sides\n",
    "\n",
    "def k_shortest_biological_paths(graph,start,end,k,rcn_eqn_pairs,weight=None):\n",
    "    '''Ignore paths which don't make at least a little biological sense.'''\n",
    "    biological_paths=[]\n",
    "    N_biol_paths=0\n",
    "    for path in nx.shortest_simple_paths(graph,start,end,weight=weight):\n",
    "        if is_biological(path,rcn_eqn_pairs):\n",
    "            biological_paths.append(path)\n",
    "            N_biol_paths+=1\n",
    "            if N_biol_paths>=k:\n",
    "                return biological_paths\n",
    "    return biological_paths\n",
    "\n",
    "\n",
    "def network_graph_prep_wd():\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "def generate_biological_links(Genome_ko_hits,output_dir):\n",
    "    KO_RN_dict = load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"orthology\",\"reaction\")], False)[(\"orthology\",\"reaction\")]\n",
    "    all_linkable_KOs = set(itertools.chain(*Genome_ko_hits.itervalues())) & set(KO_RN_dict.keys())\n",
    "    cpd_links = {KO:set(KO_RN_dict[KO]) for KO in all_linkable_KOs}\n",
    "    return\n",
    "\n",
    "#def network_analysis_wf(,):\n",
    "    \n",
    "#    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reaction_graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c23e8b241a4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrcn_eqn_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_local_rcn_eqn_database_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreaction_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"U_52098\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reaction_graphs' is not defined"
     ]
    }
   ],
   "source": [
    "rcn_eqn_pairs=load_local_rcn_eqn_database_set(database_dir)\n",
    "\n",
    "G=reaction_graphs[\"U_52098\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0754f085a39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "G.nodes()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NetworkXNoPath",
     "evalue": "No path between R00475;C00160 and R04199;C03972.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNetworkXNoPath\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-8a3f54e257b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_shortest_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'R00475;C00160'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'R04199;C03972'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-11fccb79ea6b>\u001b[0m in \u001b[0;36mk_shortest_paths\u001b[1;34m(graph, start, end, k, weight)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;31m#FROM NETWORKX DOCUMENTATION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mk_shortest_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortest_simple_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;31m##############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_pathways\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpd_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/networkx/algorithms/simple_paths.pyc\u001b[0m in \u001b[0;36mshortest_simple_paths\u001b[1;34m(G, source, target, weight)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mprev_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshortest_path_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mlistB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/networkx/algorithms/simple_paths.pyc\u001b[0m in \u001b[0;36m_bidirectional_shortest_path\u001b[1;34m(G, source, target, ignore_nodes, ignore_edges, weight)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \"\"\"\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m# call helper to do the real work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bidirectional_pred_succ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_edges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msucc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/networkx/algorithms/simple_paths.pyc\u001b[0m in \u001b[0;36m_bidirectional_pred_succ\u001b[1;34m(G, source, target, ignore_nodes, ignore_edges)\u001b[0m\n\u001b[0;32m    447\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msucc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXNoPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No path between %s and %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNetworkXNoPath\u001b[0m: No path between R00475;C00160 and R04199;C03972."
     ]
    }
   ],
   "source": [
    "m=k_shortest_paths(G,'R00475;C00160','R04199;C03972',10,weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24488496780395508, 0.2435619831085205, 0.17296099662780762]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.repeat(\"nx.has_path(G,'R00475;C00160','R04199;C03972')\",'from __main__ import nx, G',number=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R00258;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R00093;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R04475;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R01214;C00026',\n",
       "  'R01213;C00141',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R00248;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R01214;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R05085;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R02199;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R03243;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R00114;C00026',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14593982696533203, 0.10733604431152344, 0.11613011360168457]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.repeat(\"k_shortest_biological_paths(G,'R00475;C00160','R04199;C03972',10,rcn_eqn_pairs)\",'from __main__ import G, rcn_eqn_pairs,k_shortest_biological_paths',number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=k_shortest_biological_paths(G,'R00475;C00160','R04199;C03972',10,rcn_eqn_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R01214;C00026',\n",
       "  'R01213;C00141',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00369;C00048',\n",
       "  'R00945;C00037',\n",
       "  'R02287;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00588;C00048',\n",
       "  'R00945;C00037',\n",
       "  'R02287;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00369;C00048',\n",
       "  'R00945;C00037',\n",
       "  'R03189;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00588;C00048',\n",
       "  'R00945;C00037',\n",
       "  'R03189;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00369;C00048',\n",
       "  'R08701;C00037',\n",
       "  'R02287;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R09099;C00037',\n",
       "  'R00585;C00065',\n",
       "  'R03210;C00041',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00588;C00048',\n",
       "  'R08701;C00037',\n",
       "  'R02287;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00369;C00048',\n",
       "  'R08701;C00037',\n",
       "  'R03189;C00101',\n",
       "  'R00259;C00025',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972'],\n",
       " ['R00475;C00160',\n",
       "  'R00372;C00048',\n",
       "  'R00945;C00037',\n",
       "  'R00585;C00065',\n",
       "  'R03210;C00041',\n",
       "  'R04364;C00010',\n",
       "  'R04199;C03972']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.270888090133667, 2.2284109592437744, 2.1088790893554688]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.repeat(\"k_shortest_paths(G,'R00475;C00160','R09773;C17556',10,weight=None)\",'from __main__ import G,k_shortest_paths',number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniq_cpds=pairwise_unique_cpds(reaction_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graphs are being made.\n",
      "U_52270 has started being processed at: 2016-07-28 13:55:56.648621\n",
      "Duration since start: 0:00:00.000074\n",
      "There were 1644 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:25.297256\n",
      "U_52098 has started being processed at: 2016-07-28 13:56:21.947452\n",
      "Duration since start: 0:00:25.298905\n",
      "There were 1209 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.205901\n",
      "SymbC15 has started being processed at: 2016-07-28 13:56:41.153752\n",
      "Duration since start: 0:00:44.505205\n",
      "There were 14138 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:02:22.333221\n",
      "U_52448 has started being processed at: 2016-07-28 13:59:03.487425\n",
      "Duration since start: 0:03:06.838878\n",
      "There were 1619 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:22.513843\n",
      "U_52425 has started being processed at: 2016-07-28 13:59:26.001678\n",
      "Duration since start: 0:03:29.353131\n",
      "There were 1954 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:34.001152\n",
      "U_52423 has started being processed at: 2016-07-28 14:00:00.003239\n",
      "Duration since start: 0:04:03.354692\n",
      "There were 2406 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:30.482643\n",
      "U_52420 has started being processed at: 2016-07-28 14:00:30.486273\n",
      "Duration since start: 0:04:33.837726\n",
      "There were 1939 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.690296\n",
      "U_52180 has started being processed at: 2016-07-28 14:00:50.176983\n",
      "Duration since start: 0:04:53.528436\n",
      "There were 1054 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:07.882563\n",
      "U_51892 has started being processed at: 2016-07-28 14:00:58.060327\n",
      "Duration since start: 0:05:01.411780\n",
      "There were 1777 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:25.210238\n",
      "U_52403 has started being processed at: 2016-07-28 14:01:23.271196\n",
      "Duration since start: 0:05:26.622649\n",
      "There were 1353 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.561596\n",
      "U_52582 has started being processed at: 2016-07-28 14:01:38.833572\n",
      "Duration since start: 0:05:42.185025\n",
      "There were 1684 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.683207\n",
      "U_52505 has started being processed at: 2016-07-28 14:01:52.517511\n",
      "Duration since start: 0:05:55.868964\n",
      "There were 1275 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.033095\n",
      "U_52368 has started being processed at: 2016-07-28 14:02:11.551778\n",
      "Duration since start: 0:06:14.903231\n",
      "There were 1496 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.318470\n",
      "U_52266 has started being processed at: 2016-07-28 14:02:28.870969\n",
      "Duration since start: 0:06:32.222422\n",
      "There were 1937 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:21.429120\n",
      "U_41432 has started being processed at: 2016-07-28 14:02:50.301552\n",
      "Duration since start: 0:06:53.653005\n",
      "There were 1471 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.162079\n",
      "U_52401 has started being processed at: 2016-07-28 14:03:09.464491\n",
      "Duration since start: 0:07:12.815944\n",
      "There were 1004 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.475439\n",
      "U_52366 has started being processed at: 2016-07-28 14:03:23.940542\n",
      "Duration since start: 0:07:27.291995\n",
      "There were 1063 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:08.997529\n",
      "U_52529 has started being processed at: 2016-07-28 14:03:32.938719\n",
      "Duration since start: 0:07:36.290172\n",
      "There were 2248 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:34.426343\n",
      "U_52528 has started being processed at: 2016-07-28 14:04:07.365841\n",
      "Duration since start: 0:08:10.717294\n",
      "There were 1786 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.338933\n",
      "U_52544 has started being processed at: 2016-07-28 14:04:27.705106\n",
      "Duration since start: 0:08:31.056559\n",
      "There were 936 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:11.414137\n",
      "U_51873 has started being processed at: 2016-07-28 14:04:39.119653\n",
      "Duration since start: 0:08:42.471106\n",
      "There were 2876 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:40.990785\n",
      "U_52661 has started being processed at: 2016-07-28 14:05:20.111023\n",
      "Duration since start: 0:09:23.462476\n",
      "There were 1072 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:10.413268\n",
      "U_52380 has started being processed at: 2016-07-28 14:05:30.524979\n",
      "Duration since start: 0:09:33.876432\n",
      "There were 1189 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:09.776060\n",
      "U_52525 has started being processed at: 2016-07-28 14:05:40.302018\n",
      "Duration since start: 0:09:43.653471\n",
      "There were 1645 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:22.020707\n",
      "U_52524 has started being processed at: 2016-07-28 14:06:02.323453\n",
      "Duration since start: 0:10:05.674906\n",
      "There were 1357 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:22.314351\n",
      "U_52087 has started being processed at: 2016-07-28 14:06:24.640346\n",
      "Duration since start: 0:10:27.991799\n",
      "There were 1292 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.731593\n",
      "U_52452 has started being processed at: 2016-07-28 14:06:38.372734\n",
      "Duration since start: 0:10:41.724187\n",
      "There were 1098 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.121817\n",
      "U_52338 has started being processed at: 2016-07-28 14:06:55.495487\n",
      "Duration since start: 0:10:58.846940\n",
      "There were 1248 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.227441\n",
      "U_52375 has started being processed at: 2016-07-28 14:07:12.723622\n",
      "Duration since start: 0:11:16.075075\n",
      "There were 1415 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.871648\n",
      "U_52478 has started being processed at: 2016-07-28 14:07:29.596127\n",
      "Duration since start: 0:11:32.947580\n",
      "There were 1287 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.391455\n",
      "U_51962 has started being processed at: 2016-07-28 14:07:48.990610\n",
      "Duration since start: 0:11:52.342063\n",
      "There were 1433 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.015692\n",
      "U_51963 has started being processed at: 2016-07-28 14:08:09.006628\n",
      "Duration since start: 0:12:12.358081\n",
      "There were 1224 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.114649\n",
      "U_52459 has started being processed at: 2016-07-28 14:08:23.121878\n",
      "Duration since start: 0:12:26.473331\n",
      "There were 1305 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.103985\n",
      "U_51967 has started being processed at: 2016-07-28 14:08:43.226234\n",
      "Duration since start: 0:12:46.577687\n",
      "There were 1170 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.601294\n",
      "U_52472 has started being processed at: 2016-07-28 14:08:58.828255\n",
      "Duration since start: 0:13:02.179708\n",
      "There were 1918 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:25.537569\n",
      "U_52439 has started being processed at: 2016-07-28 14:09:24.366356\n",
      "Duration since start: 0:13:27.717809\n",
      "There were 1449 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.192059\n",
      "U_52520 has started being processed at: 2016-07-28 14:09:44.558847\n",
      "Duration since start: 0:13:47.910300\n",
      "There were 1399 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.955886\n",
      "U_52123 has started being processed at: 2016-07-28 14:09:59.515731\n",
      "Duration since start: 0:14:02.867184\n",
      "There were 1416 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.043409\n",
      "U_52517 has started being processed at: 2016-07-28 14:10:19.560098\n",
      "Duration since start: 0:14:22.911551\n",
      "There were 972 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.057654\n",
      "U_52514 has started being processed at: 2016-07-28 14:10:32.618354\n",
      "Duration since start: 0:14:35.969807\n",
      "There were 2046 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:27.390330\n",
      "U_52278 has started being processed at: 2016-07-28 14:11:00.009424\n",
      "Duration since start: 0:15:03.360877\n",
      "There were 899 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:11.908363\n",
      "coral has started being processed at: 2016-07-28 14:11:11.918634\n",
      "Duration since start: 0:15:15.270087\n",
      "There were 3713 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:01:05.298677\n",
      "U_52105 has started being processed at: 2016-07-28 14:12:17.218499\n",
      "Duration since start: 0:16:20.569952\n",
      "There were 1346 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.398108\n",
      "U_52271 has started being processed at: 2016-07-28 14:12:31.616987\n",
      "Duration since start: 0:16:34.968440\n",
      "There were 2306 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:29.636239\n",
      "U_52410 has started being processed at: 2016-07-28 14:13:01.253555\n",
      "Duration since start: 0:17:04.605008\n",
      "There were 1661 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.379180\n",
      "U_52637 has started being processed at: 2016-07-28 14:13:17.633554\n",
      "Duration since start: 0:17:20.985007\n",
      "There were 2026 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:25.090140\n",
      "U_52290 has started being processed at: 2016-07-28 14:13:42.724553\n",
      "Duration since start: 0:17:46.076006\n",
      "There were 1301 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:18.734397\n",
      "U_51863 has started being processed at: 2016-07-28 14:14:01.460027\n",
      "Duration since start: 0:18:04.811480\n",
      "There were 1191 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.655105\n",
      "U_52615 has started being processed at: 2016-07-28 14:14:19.115898\n",
      "Duration since start: 0:18:22.467351\n",
      "There were 1213 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.569610\n",
      "U_52530 has started being processed at: 2016-07-28 14:14:33.686517\n",
      "Duration since start: 0:18:37.037970\n",
      "There were 1943 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:21.585341\n",
      "U_52531 has started being processed at: 2016-07-28 14:14:55.272677\n",
      "Duration since start: 0:18:58.624130\n",
      "There were 1334 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.258593\n",
      "U_52532 has started being processed at: 2016-07-28 14:15:10.532058\n",
      "Duration since start: 0:19:13.883511\n",
      "There were 1343 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:12.444121\n",
      "U_52536 has started being processed at: 2016-07-28 14:15:22.977048\n",
      "Duration since start: 0:19:26.328501\n",
      "There were 1392 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.584395\n",
      "U_52434 has started being processed at: 2016-07-28 14:15:37.562308\n",
      "Duration since start: 0:19:40.913761\n",
      "There were 1947 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:27.376435\n"
     ]
    }
   ],
   "source": [
    "store_unique_cpd_rn_node_graphs(KO_genome_hits,common_cpds,os.path.join(output_dir,\"graphs/Reaction_links\",\"Side_spec\"),output_dir,database_dir,double_links=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graphs are being made.\n",
      "U_52270 has started being processed at: 2016-07-28 14:16:08.833647\n",
      "Duration since start: 0:00:00.000046\n",
      "There were 1644 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.718796\n",
      "U_52098 has started being processed at: 2016-07-28 14:16:28.553064\n",
      "Duration since start: 0:00:19.719463\n",
      "There were 1209 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:18.304732\n",
      "SymbC15 has started being processed at: 2016-07-28 14:16:46.858502\n",
      "Duration since start: 0:00:38.024901\n",
      "There were 14138 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:01:58.074109\n",
      "U_52448 has started being processed at: 2016-07-28 14:18:44.933713\n",
      "Duration since start: 0:02:36.100112\n",
      "There were 1619 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.929159\n",
      "U_52425 has started being processed at: 2016-07-28 14:19:05.863472\n",
      "Duration since start: 0:02:57.029871\n",
      "There were 1954 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:32.141183\n",
      "U_52423 has started being processed at: 2016-07-28 14:19:38.005497\n",
      "Duration since start: 0:03:29.171896\n",
      "There were 2406 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:27.724124\n",
      "U_52420 has started being processed at: 2016-07-28 14:20:05.730393\n",
      "Duration since start: 0:03:56.896792\n",
      "There were 1939 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.848535\n",
      "U_52180 has started being processed at: 2016-07-28 14:20:26.579662\n",
      "Duration since start: 0:04:17.746061\n",
      "There were 1054 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:07.910832\n",
      "U_51892 has started being processed at: 2016-07-28 14:20:34.491234\n",
      "Duration since start: 0:04:25.657633\n",
      "There were 1777 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:23.894214\n",
      "U_52403 has started being processed at: 2016-07-28 14:20:58.386266\n",
      "Duration since start: 0:04:49.552665\n",
      "There were 1353 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.781045\n",
      "U_52582 has started being processed at: 2016-07-28 14:21:13.169149\n",
      "Duration since start: 0:05:04.335548\n",
      "There were 1684 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.474537\n",
      "U_52505 has started being processed at: 2016-07-28 14:21:26.644454\n",
      "Duration since start: 0:05:17.810853\n",
      "There were 1275 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.405453\n",
      "U_52368 has started being processed at: 2016-07-28 14:21:42.050984\n",
      "Duration since start: 0:05:33.217383\n",
      "There were 1496 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.383514\n",
      "U_52266 has started being processed at: 2016-07-28 14:22:02.434860\n",
      "Duration since start: 0:05:53.601259\n",
      "There were 1937 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:21.043009\n",
      "U_41432 has started being processed at: 2016-07-28 14:22:23.478423\n",
      "Duration since start: 0:06:14.644822\n",
      "There were 1471 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.551415\n",
      "U_52401 has started being processed at: 2016-07-28 14:22:39.030232\n",
      "Duration since start: 0:06:30.196631\n",
      "There were 1004 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.450950\n",
      "U_52366 has started being processed at: 2016-07-28 14:22:55.481836\n",
      "Duration since start: 0:06:46.648235\n",
      "There were 1063 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:08.768498\n",
      "U_52529 has started being processed at: 2016-07-28 14:23:04.251295\n",
      "Duration since start: 0:06:55.417694\n",
      "There were 2248 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:34.251288\n",
      "U_52528 has started being processed at: 2016-07-28 14:23:38.503053\n",
      "Duration since start: 0:07:29.669452\n",
      "There were 1786 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.868926\n",
      "U_52544 has started being processed at: 2016-07-28 14:23:54.372470\n",
      "Duration since start: 0:07:45.538869\n",
      "There were 936 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.747581\n",
      "U_51873 has started being processed at: 2016-07-28 14:24:08.120492\n",
      "Duration since start: 0:07:59.286891\n",
      "There were 2876 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:36.926131\n",
      "U_52661 has started being processed at: 2016-07-28 14:24:45.047033\n",
      "Duration since start: 0:08:36.213432\n",
      "There were 1072 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:09.986823\n",
      "U_52380 has started being processed at: 2016-07-28 14:24:55.034506\n",
      "Duration since start: 0:08:46.200905\n",
      "There were 1189 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:09.288416\n",
      "U_52525 has started being processed at: 2016-07-28 14:25:04.324112\n",
      "Duration since start: 0:08:55.490511\n",
      "There were 1645 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:24.555962\n",
      "U_52524 has started being processed at: 2016-07-28 14:25:28.880458\n",
      "Duration since start: 0:09:20.046857\n",
      "There were 1357 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.129907\n",
      "U_52087 has started being processed at: 2016-07-28 14:25:46.010754\n",
      "Duration since start: 0:09:37.177153\n",
      "There were 1292 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.310359\n",
      "U_52452 has started being processed at: 2016-07-28 14:25:59.321594\n",
      "Duration since start: 0:09:50.487993\n",
      "There were 1098 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.640690\n",
      "U_52338 has started being processed at: 2016-07-28 14:26:15.963200\n",
      "Duration since start: 0:10:07.129599\n",
      "There were 1248 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.792752\n",
      "U_52375 has started being processed at: 2016-07-28 14:26:35.756438\n",
      "Duration since start: 0:10:26.922837\n",
      "There were 1415 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.352427\n",
      "U_52478 has started being processed at: 2016-07-28 14:26:49.109605\n",
      "Duration since start: 0:10:40.276004\n",
      "There were 1287 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:18.664295\n",
      "U_51962 has started being processed at: 2016-07-28 14:27:07.774657\n",
      "Duration since start: 0:10:58.941056\n",
      "There were 1433 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:21.337968\n",
      "U_51963 has started being processed at: 2016-07-28 14:27:29.114313\n",
      "Duration since start: 0:11:20.280712\n",
      "There were 1224 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:13.745310\n",
      "U_52459 has started being processed at: 2016-07-28 14:27:42.860704\n",
      "Duration since start: 0:11:34.027103\n",
      "There were 1305 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.412508\n",
      "U_51967 has started being processed at: 2016-07-28 14:27:59.274010\n",
      "Duration since start: 0:11:50.440409\n",
      "There were 1170 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.393491\n",
      "U_52472 has started being processed at: 2016-07-28 14:28:14.668359\n",
      "Duration since start: 0:12:05.834758\n",
      "There were 1918 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:27.906373\n",
      "U_52439 has started being processed at: 2016-07-28 14:28:42.575518\n",
      "Duration since start: 0:12:33.741917\n",
      "There were 1449 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.664633\n",
      "U_52520 has started being processed at: 2016-07-28 14:28:59.240979\n",
      "Duration since start: 0:12:50.407378\n",
      "There were 1399 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.778107\n",
      "U_52123 has started being processed at: 2016-07-28 14:29:14.020002\n",
      "Duration since start: 0:13:05.186401\n",
      "There were 1416 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:19.643326\n",
      "U_52517 has started being processed at: 2016-07-28 14:29:33.664151\n",
      "Duration since start: 0:13:24.830550\n",
      "There were 972 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:12.633360\n",
      "U_52514 has started being processed at: 2016-07-28 14:29:46.298160\n",
      "Duration since start: 0:13:37.464559\n",
      "There were 2046 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:26.917113\n",
      "U_52278 has started being processed at: 2016-07-28 14:30:13.215948\n",
      "Duration since start: 0:14:04.382347\n",
      "There were 899 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:11.444206\n",
      "coral has started being processed at: 2016-07-28 14:30:24.660534\n",
      "Duration since start: 0:14:15.826933\n",
      "There were 3713 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:01:04.327116\n",
      "U_52105 has started being processed at: 2016-07-28 14:31:28.988368\n",
      "Duration since start: 0:15:20.154767\n",
      "There were 1346 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.860637\n",
      "U_52271 has started being processed at: 2016-07-28 14:31:43.849660\n",
      "Duration since start: 0:15:35.016059\n",
      "There were 2306 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:28.505981\n",
      "U_52410 has started being processed at: 2016-07-28 14:32:12.356403\n",
      "Duration since start: 0:16:03.522802\n",
      "There were 1661 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.793160\n",
      "U_52637 has started being processed at: 2016-07-28 14:32:28.150204\n",
      "Duration since start: 0:16:19.316603\n",
      "There were 2026 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:24.219630\n",
      "U_52290 has started being processed at: 2016-07-28 14:32:52.370579\n",
      "Duration since start: 0:16:43.536978\n",
      "There were 1301 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:16.334429\n",
      "U_51863 has started being processed at: 2016-07-28 14:33:08.705997\n",
      "Duration since start: 0:16:59.872396\n",
      "There were 1191 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:20.040649\n",
      "U_52615 has started being processed at: 2016-07-28 14:33:28.747478\n",
      "Duration since start: 0:17:19.913877\n",
      "There were 1213 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.291128\n",
      "U_52530 has started being processed at: 2016-07-28 14:33:43.039299\n",
      "Duration since start: 0:17:34.205698\n",
      "There were 1943 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:17.717899\n",
      "U_52531 has started being processed at: 2016-07-28 14:34:00.757980\n",
      "Duration since start: 0:17:51.924379\n",
      "There were 1334 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.914754\n",
      "U_52532 has started being processed at: 2016-07-28 14:34:15.673306\n",
      "Duration since start: 0:18:06.839705\n",
      "There were 1343 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:15.247426\n",
      "U_52536 has started being processed at: 2016-07-28 14:34:30.921352\n",
      "Duration since start: 0:18:22.087751\n",
      "There were 1392 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:14.393236\n",
      "U_52434 has started being processed at: 2016-07-28 14:34:45.315327\n",
      "Duration since start: 0:18:36.481726\n",
      "There were 1947 doubly linked reactions in this set of comparisons.\n",
      "Duration of making graph 0:00:24.279750\n"
     ]
    }
   ],
   "source": [
    "store_unique_cpd_rn_node_graphs(KO_genome_hits,common_cpds,os.path.join(output_dir,\"graphs/Reaction_links\",\"Side_spec_no_double_links\"),output_dir,database_dir,double_links=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reaction_graphs=load_graphs(os.path.join(output_dir,\"graphs\",\"Reaction_links\",\"Side_spec_no_double_links\"),'*.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxidative_phosphorylation ['map00190'] Blues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two-component ['map02020'] Greens\n",
      "vitamins&cofactors ['map00730', 'map00740', 'map00750', 'map00760', 'map00770', 'map00780', 'map00785', 'map00790', 'map00670', 'map00830', 'map00860', 'map00130'] Oranges\n",
      "AminoAcidMetabolism ['map00250', 'map00270', 'map00260', 'map00280', 'map00290', 'map00300', 'map00310', 'map00220', 'map00330', 'map00340', 'map00350', 'map00360', 'map00380', 'map00400'] Purples\n",
      "nitrogen-sulfur-fatty_acid-photosynthesis ['map00910', 'map00920', 'map01212', 'map00195'] Reds\n",
      "carbon ['map01200'] Greys\n",
      "amino-acids ['map01230'] Blues\n",
      "oxidative_phosphorylation ['map00190'] Blues\n",
      "two-component ['map02020'] Greens\n",
      "vitamins&cofactors ['map00730', 'map00740', 'map00750', 'map00760', 'map00770', 'map00780', 'map00785', 'map00790', 'map00670', 'map00830', 'map00860', 'map00130'] Oranges\n",
      "AminoAcidMetabolism ['map00250', 'map00270', 'map00260', 'map00280', 'map00290', 'map00300', 'map00310', 'map00220', 'map00330', 'map00340', 'map00350', 'map00360', 'map00380', 'map00400'] Purples\n",
      "nitrogen-sulfur-fatty_acid-photosynthesis ['map00910', 'map00920', 'map01212', 'map00195'] Reds\n",
      "carbon ['map01200'] Greys\n",
      "amino-acids ['map01230'] Blues\n"
     ]
    }
   ],
   "source": [
    "def plot_heatmap_proportion(path_id, path_name, KO_genome_files, cmap,output_dir,database_dir,bin_names):\n",
    "\n",
    "    PTH_MO_pairs = load_local_kegg_database_pairings(database_dir,[(\"pathway\",\"module\")], False)[(\"pathway\",\"module\")]\n",
    "    linkable_base_paths=set(PTH_MO_pairs.iterkeys()) & set(path_id)\n",
    "    base_mod= set(itertools.chain(*[PTH_MO_pairs[pathway] for pathway in linkable_base_paths]))\n",
    "    \n",
    "    MO_KO_pairs  = load_local_kegg_database_pairings(database_dir,[(\"module\",\"orthology\")], False)[(\"module\",\"orthology\")]\n",
    "    all_modules = {MO:MO_KO_pairs[MO] for MO in base_mod} #kc.link_ids('ko', base_mod)\n",
    "    module_totals = pd.Series(\n",
    "        {\n",
    "            mod_id: len(ko_ids)\n",
    "            for mod_id, ko_ids in all_modules.iteritems()\n",
    "        }\n",
    "    )\n",
    "    rev_modules = dictionary.reverse_mapping(all_modules)\n",
    "    \n",
    "    module_names=load_readable_names(database_dir,[\"module\"],False)[\"module\"]\n",
    "    \n",
    "    mod_prop = {}\n",
    "    for genome_id, KOs in KO_genome_files.iteritems():\n",
    "        mod_prop[genome_id] = {}\n",
    "        genome_ko_ids = KOs\n",
    "        for mod_id, ko_ids in all_modules.iteritems():\n",
    "            mod_prop[genome_id][mod_id] = len(set(ko_ids) & genome_ko_ids)\n",
    "    \n",
    "    mod_prop = pd.DataFrame(mod_prop).fillna(0)\n",
    "    mod_prop = mod_prop[mod_prop.sum(axis=1) > 0].divide(module_totals, axis='index').dropna()\n",
    "    mod_prop = mod_prop.rename(index=module_names, columns=bin_names)\n",
    "    mod_prop=mod_prop.sort_index(axis='columns')\n",
    "    \n",
    "    h2 = sns.clustermap(mod_prop, col_cluster=False, method='complete', cmap=cmap)\n",
    "    h2.ax_heatmap.set_title(path_name)\n",
    "    for text in h2.ax_heatmap.get_yticklabels():\n",
    "        text.set_rotation('horizontal')\n",
    "    for text in h2.ax_heatmap.get_xticklabels():\n",
    "        text.set_rotation('vertical')\n",
    "    h2.savefig(os.path.join(output_dir,'{}-modules_proportion.pdf'.format(path_name)))\n",
    "\n",
    "colors = ['Blues', 'Greens', 'Oranges', 'Purples', 'Reds', 'Greys','Blues','Blues']\n",
    "for (path_name, path_id), palette in zip(pathways.iteritems(), colors):\n",
    "    print path_name, path_id, palette\n",
    "    plot_heatmap_proportion(path_id, path_name, KO_genome_hits, palette,output_dir,os.path.join(output_dir,\"Databases\"),bin_names)\n",
    "\n",
    "\n",
    "\n",
    "def group_micro_plot_heatmap_proprtion(path_id, path_name, KO_genome_files, cmap,output_dir,database_dir,bin_names):\n",
    "    PTH_MO_pairs = load_local_kegg_database_pairings(database_dir,[(\"pathway\",\"module\")], False)[(\"pathway\",\"module\")]\n",
    "    linkable_base_paths=set(PTH_MO_pairs.iterkeys()) & set(path_id)\n",
    "    base_mod= set(itertools.chain(*[PTH_MO_pairs[pathway] for pathway in linkable_base_paths]))\n",
    "    \n",
    "    MO_KO_pairs  = load_local_kegg_database_pairings(database_dir,[(\"module\",\"orthology\")], False)[(\"module\",\"orthology\")]\n",
    "    all_modules = {MO:MO_KO_pairs[MO] for MO in base_mod} #kc.link_ids('ko', base_mod)\n",
    "    module_totals = pd.Series(\n",
    "        {\n",
    "            mod_id: len(ko_ids)\n",
    "            for mod_id, ko_ids in all_modules.iteritems()\n",
    "        }\n",
    "    )\n",
    "    rev_modules = dictionary.reverse_mapping(all_modules)\n",
    "    \n",
    "    module_names=load_readable_names(database_dir,[\"module\"],False)[\"module\"]\n",
    "    \n",
    "    mod_prop = {}\n",
    "    for genome_id, KOs in KO_genome_files.iteritems():\n",
    "        mod_prop[genome_id] = {}\n",
    "        genome_ko_ids = KOs\n",
    "        for mod_id, ko_ids in all_modules.iteritems():\n",
    "            mod_prop[genome_id][mod_id] = len(set(ko_ids) & genome_ko_ids)\n",
    "            \n",
    "    euk_names=[\"coral\",\"SymbC15\"]\n",
    "    \n",
    "    bacteria=set(mod_prop.keys()) - set(euk_names)\n",
    "    \n",
    "    new_mod_prop={}\n",
    "    new_mod_prop[\"microorganisms\"]={}\n",
    "    for module in mod_prop[\"coral\"].iterkeys():\n",
    "        new_mod_prop[\"microorganisms\"][module]=0\n",
    "    for euk in euk_names:\n",
    "        new_mod_prop[euk]=mod_prop[euk]\n",
    "    for genome, module_counts in mod_prop.iteritems():\n",
    "        if genome not in euk_names:\n",
    "            for module, count in module_counts.iteritems():\n",
    "                new_mod_prop[\"microorganisms\"][module]=max(new_mod_prop[\"microorganisms\"][module],count)\n",
    "                \n",
    "    new_bin_names={gen_id:gen_name for gen_id,gen_name in bin_names.iteritems() if gen_id in euk_names}\n",
    "    new_bin_names[\"microorganisms\"]=\"microorganisms\"\n",
    "    bin_names=new_bin_names\n",
    "    \n",
    "    mod_prop = pd.DataFrame(new_mod_prop).fillna(0)\n",
    "    mod_prop = mod_prop[mod_prop.sum(axis=1) > 0].divide(module_totals, axis='index').dropna()\n",
    "    mod_prop = mod_prop.rename(index=module_names, columns=bin_names)\n",
    "    mod_prop=mod_prop.sort_index(axis='columns')\n",
    "    \n",
    "        \n",
    "    h2 = sns.clustermap(mod_prop, col_cluster=False, method='complete', cmap=cmap)\n",
    "    h2.ax_heatmap.set_title(path_name)\n",
    "    for text in h2.ax_heatmap.get_yticklabels():\n",
    "        text.set_rotation('horizontal')\n",
    "    for text in h2.ax_heatmap.get_xticklabels():\n",
    "        text.set_rotation('vertical')\n",
    "    h2.savefig(os.path.join(output_dir,'{}_grouped_microbes_modules_proportion.pdf'.format(path_name)))\n",
    "    \n",
    "    \n",
    "colors = ['Blues', 'Greens', 'Oranges', 'Purples', 'Reds', 'Greys','Blues','Blues']\n",
    "for (path_name, path_id), palette in zip(pathways.iteritems(), colors):\n",
    "    print path_name, path_id, palette\n",
    "    group_micro_plot_heatmap_proprtion(path_id, path_name, KO_genome_hits, palette,output_dir,os.path.join(output_dir,\"Databases\"),bin_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path searching algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def networkx_shortest_path(graph,cpds1,cpds2):\n",
    "    if len(cpds1)!=len(cpds2):\n",
    "        print \"The cpds must came as start, end pairs. There must be the same number of starting nodes as finishing nodes\"\n",
    "        return None\n",
    "    shortest_paths={}\n",
    "    graph_cpds=graph.nodes()\n",
    "    for (start,end) in itertools.izip(cpds1,cpds2):\n",
    "        if start in graph_cpds and end in graph_cpds:\n",
    "            shortest_paths[(start,end)]=nx.astar_path(graph,start,end)\n",
    "        else:\n",
    "            shortest_paths[(start,end)]=[]\n",
    "    return shortest_paths\n",
    "\n",
    "#FROM NETWORKX DOCUMENTATION\n",
    "def k_shortest_paths(graph,start,end,k,weight=None):\n",
    "    return list(itertools.islice(nx.shortest_simple_paths(graph,start,end,weight=weight),k))\n",
    "##############################\n",
    "\n",
    "\n",
    "def networkx_k_shortest_paths(graph,cpds1,cpds2,k):\n",
    "    if len(cpds1)!=len(cpds2):\n",
    "        print \"The cpds must came as start, end pairs. There must be the same number of starting nodes as finishing nodes\"\n",
    "        return None\n",
    "    cpd_pair_k_shortest_paths={}\n",
    "    graph_cpds=graph.nodes()\n",
    "    for (start,end) in itertools.izip(cpds1,cpds2):\n",
    "        if start in graph_cpds and end in graph_cpds:\n",
    "            cpd_pair_k_shortest_paths[(start,end)]=k_shortest_paths(graph,start,end,k)\n",
    "        else:\n",
    "            cpd_pair_k_shortest_paths[(start,end)]=[[]]\n",
    "    return cpd_pair_k_shortest_paths\n",
    "\n",
    "def shortest_path_to_pd_dataframe(shortest_paths):\n",
    "    kc = kegg.KeggClientRest()\n",
    "    cpd_names = kc.get_ids_names('compound')\n",
    "    df=pd.DataFrame([\n",
    "            [cpd1, cpd2, cpd_names[cpd1],cpd_names[cpd2],\"||\".join(path), \"||\".join([cpd_names[cpd] for cpd in path])] for (cpd1, cpd2), path in shortest_paths.iteritems() \n",
    "        ])\n",
    "    df.columns=[\"KEGGCpd1ID\",\"KEGGCpd2ID\",'CPD1_readable',\"CPD2_readable\",\"CPD_PATH\",\"READABLE_CPD_PATH\"]\n",
    "    return df\n",
    "\n",
    "def save_output(pd_path_dataframe,output_file):\n",
    "    pd_path_dataframe.to_csv(output_file,sep=\"\\t\",header=True,index=False)\n",
    "    return None\n",
    "\n",
    "def shortest_paths_pd_dataframe(k_shortest_paths):\n",
    "    kc = kegg.KeggClientRest()\n",
    "    cpd_names = kc.get_ids_names('compound')\n",
    "    df=pd.DataFrame([\n",
    "            [cpd1, cpd2, cpd_names[cpd1],cpd_names[cpd2],\"||\".join(path), \"||\".join([cpd_names[cpd] for cpd in path])] for (cpd1, cpd2), paths in k_shortest_paths.iteritems() for path in paths \n",
    "        ])\n",
    "    df.columns=[\"KEGGCpd1ID\",\"KEGGCpd2ID\",'CPD1_readable',\"CPD2_readable\",\"CPD_PATH\",\"READABLE_CPD_PATH\"]\n",
    "    return df\n",
    "\n",
    "def genome_shortest_paths_pd_dataframe(genome_cpd_pairs):\n",
    "    kc = kegg.KeggClientRest()\n",
    "    cpd_names = kc.get_ids_names('compound')\n",
    "    df=pd.DataFrame([\n",
    "            [genome, cpd1, cpd2, cpd_names[cpd1],cpd_names[cpd2],\"||\".join(path), \"||\".join([cpd_names[cpd] for genome, k_shortest_paths in genome_cpd_pairs.iteritems() for cpd in path])] \\\n",
    "            for (cpd1, cpd2), paths in k_shortest_paths.iteritems() for path in paths \n",
    "        ])\n",
    "    df.columns=[\"Genome\",\"KEGGCpd1ID\",\"KEGGCpd2ID\",'CPD1_readable',\"CPD2_readable\",\"CPD_PATH\",\"READABLE_CPD_PATH\"]\n",
    "    return df\n",
    "\n",
    "def investigate_within_genome_paths(genome_graph_dict,output_dir,n_shortest_paths,n_pruned_nodes,cpds1,cpds2):\n",
    "    pruned_graphs={}\n",
    "    genome_cpd_paths={}\n",
    "    for genome, graph in genome_graph_dict.iteritems():\n",
    "        pruned_graphs[genome]=prune_graph_abundant_nodes(graph,n_pruned_nodes)\n",
    "    for genome, pruned_graph in pruned_graphs.iteritems():\n",
    "        genome_cpd_paths[genome]=networkx_k_shortest_paths(pruned_graph,cpds1,cpds2,n_shortest_paths)\n",
    "    df=genome_shortest_paths_pd_dataframe(genome_cpd_paths)\n",
    "    save_output(df,os.path.join(output_dir,\"{0}paths_{1}pruned_nodes_genome_cpd_pair_data.tsv\"))\n",
    "    return df\n",
    "\n",
    "def investigate_between_genome_paths(genome_graph_dict,output_dir,n_shortest_paths,n_pruned_nodes,cpds1,cpds2):\n",
    "    merged_genomes={}\n",
    "    genome_differences={}\n",
    "    for genome_1,genome_2 in itertools.combination(genome_graph_dict.iterkeys(),2):\n",
    "        genome_differences=analyse_genome_differences(genome_1,genome_2)\n",
    "        merged_genomes[genome_1,genome_2]=merge_genomes(genome_graph_dict[genome_1],genome_graph_dict[genome_2])\n",
    "    for (genome_1,genome_2),merged_graph in merged_genomes:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    return\n",
    "\n",
    "def pairwise_merged_graphs_individually(genome_reaction_graphs,output_dir):\n",
    "    for genome_1,genome_2 in itertools.combinations(genome_reaction_graphs.iterkeys(),2):\n",
    "        merged_genome=merge_graphs(genome_reaction_graphs[genome_1],genome_reaction_graphs[genome_2],common_cpds)\n",
    "        save_reaction_graph(merged_genome,os.path.join(output_dir,\"{0}_paired_{1}_graph_merged_genome_reactions.xml\".format(genome_1,genome_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single degree comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_one_degree_nodes(graph,thresh):\n",
    "    one_degree={}\n",
    "    for cpd, deg in graph.degree().iteritems():\n",
    "        if deg<=thresh:\n",
    "            one_degree[cpd]=deg\n",
    "    return one_degree\n",
    "\n",
    "def all_one_degree(graph_dict):\n",
    "    one_degree_genome={}\n",
    "    for genome, graph in graph_dict.iteritems():\n",
    "        one_degree_genome[genome]=get_one_degree_nodes(graph,1)\n",
    "    return one_degree_genome\n",
    "\n",
    "def set_conversion(graph_dict):\n",
    "    cpd_sets={}\n",
    "    for genome, cpd_dict in graph_dict.iteritems():\n",
    "        cpd_sets[genome]=set(cpd_dict.iterkeys())\n",
    "    return cpd_sets        \n",
    "\n",
    "def get_one_degree_overlap(one_degree_genomes):\n",
    "    paired_compounds={}\n",
    "    for genome_1, genome_2 in itertools.combinations(one_degree_genomes.iterkeys(),2):\n",
    "        paired_compounds_init=one_degree_genomes[genome_1] & one_degree_genomes[genome_2]\n",
    "        if len(paired_compounds_init)>0:\n",
    "            paired_compounds[(genome_1,genome_2)]=paired_compounds_init\n",
    "    return paired_compounds\n",
    "\n",
    "def get_one_degree_joins(graph_dict,item_name,common_cpds):\n",
    "    one_degree_nodes=all_one_degree(graph_dict)\n",
    "    one_degree_nodes=set_conversion(one_degree_nodes)\n",
    "    linked_cpds={}\n",
    "    for genome_1,genome_2 in itertools.combinations(one_degree_nodes.iterkeys(),2):\n",
    "        genome_1_iso_nodes=one_degree_nodes[genome_1]\n",
    "        genome_2_iso_nodes=one_degree_nodes[genome_2]\n",
    "        gen_1_n_attr=nx.get_node_attributes(graph_dict[genome_1],item_name)\n",
    "        gen_2_n_attr=nx.get_node_attributes(graph_dict[genome_2],item_name)\n",
    "        genome_1_connections=connect_reactions(gen_2_n_attr,genome_1_iso_nodes,gen_1_n_attr,common_cpds)\n",
    "        genome_2_connections=connect_reactions(gen_1_n_attr,genome_2_iso_nodes,gen_2_n_attr,common_cpds)\n",
    "        linked_cpds[genome_1,genome_2]=genome_1_connections\n",
    "        linked_cpds[genome_2,genome_1]=genome_2_connections\n",
    "    return linked_cpds\n",
    "        \n",
    "def make_one_node_rcn_pd_df(linked_cpds,database_dir):\n",
    "    readable_names=load_readable_names(database_dir,[\"reaction\",\"compound\"],False)\n",
    "    rn_pth_pairs=load_local_kegg_database_pairings(database_dir,[(\"reaction\",\"compound\")], False)\n",
    "    df=pd.DataFrame([\n",
    "            [col1,col2,col3,col4,readable_names[\"reaction\"][col3],\\\n",
    "             readable_names[\"reaction\"][col4],\";\".join(overlap),\";\".join([readable_names[\"compound\"][cpd] for cpd in overlap]),\\\n",
    "             \";\".join(rn_pth_pairs[col3]),\";\".join(rn_pth_pairs[col4])] \\\n",
    "             for (col1,col2),d in linked_cpds.iteritems() for (col3, col4),overlap in d.iteritems()\n",
    "        ])\n",
    "    df.columns=[\"Genome_1\",\"Genome_2\",\"KEGG_Reaction1_ID\",\"KEGG_Reaction2_ID\",\"KEGG_Reaction1_readable\",\"KEGG_Reaction2_readable\",\"CPD_Overlap\",\"Readable_Overlap\",\"PathwaysR1\",\"PathwaysR2\"]\n",
    "    return df\n",
    "\n",
    "def save_output(pd_df,output_file):\n",
    "    pd_df.to_csv(output_file,sep=\"\\t\",index=False)\n",
    "    return None\n",
    "\n",
    "def one_degree_rcn_wf(genome_graphs,item_name,common_cpds,output_dir):\n",
    "    shared_cpd_genome=get_one_degree_joins(genome_graphs,item_name,common_cpds)\n",
    "    new_df=make_one_node_rcn_pd_df(shared_cpd_genome,os.path.join(output_dir,\"Databases\"))\n",
    "    save_output(new_df,os.path.join(output_dir,\"Reaction_graphs_isolated_node_comparisons.tsb\"))\n",
    "    return new_df\n",
    "\n",
    "def one_degree_wf(genome_graphs):\n",
    "    shared_cpd_genome=all_one_degree(genome_graphs)\n",
    "    shared_cpd_genome=set_conversion(shared_cpd_genome)\n",
    "    shared_cpd_genome=get_one_degree_overlap(shared_cpd_genome)\n",
    "    return shared_cpd_genome\n",
    "\n",
    "def cpd_shared_count(shared_cpds):\n",
    "    cpd=[]\n",
    "    for genome, cpds in shared_cpds.iteritems():\n",
    "        cpd+=list(cpds)\n",
    "    return cpd\n",
    "\n",
    "def make_one_node_pd_dataframe(overlapping_cpds):\n",
    "    kc=kegg.KeggClientRest()\n",
    "    cpd_path_pairings=kc.link_ids('pathway',set(itertools.chain(*overlapping_cpds.itervalues())))\n",
    "    cpd_names = kc.get_ids_names('compound')\n",
    "    pathway_names = kc.get_ids_names('pathway')\n",
    "    \n",
    "    df=pd.DataFrame([\n",
    "        [col1,col2,col3,cpd_names[col3],\";\".join(cpd_path_pairings[col3])] for (col1,col2), d in pairwise_comparison.iteritems() for col3 in d\n",
    "    ])\n",
    "    \n",
    "    df.columns=[\"Genome_1\",\"Genome_2\",\"KEGGCompoundID\",\"Readable_cpd_name\",\"KEGGPathway_ID\"]#,\"Readable_pathway_commound\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within module overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def missing_KO_in_modules(genome_KO_hits,output_dir):\n",
    "    '''Return a dictionary with a dictionary of modules and missing KOs for each\n",
    "    genome. For simplicity all modules with no hits are ignored.'''\n",
    "    missing_KOs={}\n",
    "    genome_module_KO_hits={}\n",
    "    kc=kegg.KeggClientRest()\n",
    "    all_kos=set(itertools.chain(*genome_KO_hits.itervalues()))\n",
    "    \n",
    "    #All modules with at least one hit across the entire dataset\n",
    "    prelinked_module=load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"orthology\",\"module\")], False)[(\"orthology\",\"module\")]\n",
    "    all_kegg_kos=set(itertools.chain(prelinked_module.iterkeys()))\n",
    "    observed_linkable_kos=all_kegg_kos & all_kos\n",
    "    observed_modules=set(itertools.chain(*[prelinked_module[ko] for ko in observed_linkable_kos]))\n",
    "    #The module pairings with their associated KO ids.\n",
    "    MO_KO_pair=load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"module\",\"orthology\")], False)[(\"module\",\"orthology\")]\n",
    "    \n",
    "    KO_with_modules = {MO:MO_KO_pair[MO] for MO in observed_modules} \n",
    "    \n",
    "    #KO misses for each genome and module.\n",
    "    for genome_id, ko_hits in genome_KO_hits.iteritems():\n",
    "        missing_KOs[genome_id]={}\n",
    "        genome_module_KO_hits[genome_id]={}\n",
    "        for mod_id, ko_ids in KO_with_modules.iteritems():\n",
    "            present_KOs=(set(ko_ids) & ko_hits)\n",
    "            #exclusion of intersection from module set\n",
    "            missing_KOs[genome_id][mod_id]=set(ko_ids) - present_KOs\n",
    "            #Intersection of sets - KOs present in module\n",
    "            genome_module_KO_hits[genome_id][mod_id]=present_KOs\n",
    "        \n",
    "    return missing_KOs,genome_module_KO_hits,KO_with_modules\n",
    "\n",
    "def pairwise_compare(genome_KO_hits,genome_missing_KOs,KO_with_modules,min_diff,min_completeness):\n",
    "    '''Return a dictionary of modules for each genome pair if the complementation of the module passes\n",
    "    some criteria.\n",
    "    '''\n",
    "    pairwise_complement_dict={}\n",
    "    for genome_1, genome_2, in itertools.combinations(genome_KO_hits.iterkeys(),2):\n",
    "        pairwise_complement_dict[(genome_1,genome_2)]={}\n",
    "        pairwise_complement_dict[(genome_2,genome_1)]={}\n",
    "        for mod_id, KO_set in KO_with_modules.iteritems():\n",
    "            \n",
    "            mod_tot=len(KO_set)\n",
    "            \n",
    "            genome_1_module_hits=genome_KO_hits[genome_1][mod_id]\n",
    "            genome_2_module_hits=genome_KO_hits[genome_2][mod_id]\n",
    "            \n",
    "            com_1=genome_missing_KOs[genome_2][mod_id] & genome_1_module_hits # (A-C) cap B\n",
    "            com_2=genome_missing_KOs[genome_1][mod_id] & genome_2_module_hits #(A-B) cap C\n",
    "            \n",
    "            N_com1=len(com_1)\n",
    "            N_com2=len(com_2)\n",
    "            \n",
    "            if N_com1>1 and N_com1/float(mod_tot)>=min_diff:\n",
    "                complemented_set=com_1.union(genome_1_module_hits)\n",
    "                new_completeness=len(complemented_set)/float(mod_tot)\n",
    "                if new_completeness>=min_completeness:\n",
    "                    pairwise_complement_dict[(genome_1,genome_2)][mod_id]=(new_completeness,N_com1/float(mod_tot),genome_2_module_hits,com_1)\n",
    "            if N_com2>1 and N_com2/float(mod_tot)>=min_diff:\n",
    "                complemented_set=com_2.union(genome_2_module_hits)\n",
    "                new_completeness=len(complemented_set)/float(mod_tot)\n",
    "                if new_completeness>=min_completeness:\n",
    "                    pairwise_complement_dict[(genome_2,genome_1)][mod_id]=(new_completeness,N_com2/float(mod_tot),genome_1_module_hits,com_2)\n",
    "    return pairwise_complement_dict\n",
    "\n",
    "def clean_pairs(dict_of_dicts):\n",
    "    cleaned_dict={}\n",
    "    for genome_pair, module_dict in dict_of_dicts.iteritems():\n",
    "        if len(module_dict)>0:\n",
    "            cleaned_dict[genome_pair]=module_dict\n",
    "        else:\n",
    "            pass\n",
    "            #print module_dict\n",
    "    return cleaned_dict\n",
    "            \n",
    "def make_complement_dataframe(pairwise_comparison):\n",
    "    ###############\n",
    "    df=pd.DataFrame([\n",
    "        [col1,col2,col3,col4,col5,col6,col7] for (col1,col2), d in pairwise_comparison.iteritems() for col3,(col4,col5,col6,col7) in d.iteritems()\n",
    "    ])\n",
    "    df.columns=[\"Genome_1(Giver)\",\"Genome_2(Receiver)\",\"KEGGModuleID\",\"ComplementedCompleteness\",\"GiverContribution\",\"Orig_KOs\",\"Given_KOs\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def threshold_reduce(df,orig_contrib):\n",
    "    return df[(df[\"ComplementedCompleteness\"]-df[\"GiverContribution\"])>=orig_contrib]\n",
    "\n",
    "def save_output(complement_dataframe, orig_contrib,output_dir):\n",
    "    full_file=os.path.join(output_dir,\"entire_overlap_file.tsv\")\n",
    "    complement_dataframe=readable_names(complement_dataframe,'KEGGModuleID','module','ReadableModuleNames',output_dir)\n",
    "    complement_dataframe=add_mapping(complement_dataframe,\"KEGGModuleID\",'pathway','KEGGPathwayID',output_dir)\n",
    "    complement_dataframe.to_csv(full_file,sep=\"\\t\",index=None)\n",
    "    reduced_file=os.path.join(output_dir,\"orig_contrib_thresh{0}_red_comp.tsv\".format(orig_contrib))\n",
    "    less_dataframe=threshold_reduce(complement_dataframe,orig_contrib)\n",
    "    less_dataframe.to_csv(reduced_file,sep=\"\\t\",index=None)\n",
    "    return less_dataframe\n",
    "\n",
    "def readable_names(dataframe,column_name,kegg_object,new_column_name,output_dir):\n",
    "    kc = kegg.KeggClientRest()\n",
    "    module_names = load_readable_names(os.path.join(output_dir,\"Databases\"),[kegg_object],False)[kegg_object]\n",
    "    idx=dataframe.columns.get_loc(column_name)+1 #To be after module IDs\n",
    "    new_df=dataframe.copy()\n",
    "    new_df.insert(idx,new_column_name,dataframe[column_name].map(module_names))\n",
    "    return new_df\n",
    "\n",
    "def add_mapping(dataframe,column_name,kegg_object,new_column_name,output_dir,human_readable=True):\n",
    "    #print [(\"module\",kegg_object)]\n",
    "    MO_PA_pairs=load_local_kegg_database_pairings(os.path.join(output_dir,\"Databases\"),[(\"module\",kegg_object)], False)[(\"module\",kegg_object)]\n",
    "    linkable_modules=set(itertools.chain(MO_PA_pairs.iterkeys())) & set(dataframe[column_name])\n",
    "    \n",
    "    mod_path_pairings={module:MO_PA_pairs[module] for module in linkable_modules}\n",
    "    #print len(mod_path_pairings)\n",
    "    comp_pair={module:\";\".join(pathways) for module, pathways in mod_path_pairings.iteritems()}\n",
    "    pathway_names=load_readable_names(os.path.join(output_dir,\"Databases\"),[kegg_object],False)[kegg_object]\n",
    "    new_df=dataframe.copy()\n",
    "    idx=dataframe.columns.get_loc(column_name)+2\n",
    "    new_df.insert(idx,new_column_name,dataframe[column_name].map(comp_pair))\n",
    "    if human_readable:\n",
    "        readable={module:\";\".join(pathway_names[pathway] for pathway in pathways) for module, pathways in mod_path_pairings.iteritems()}\n",
    "        new_df.insert(idx+1,new_column_name+\"HuReadable\",dataframe[column_name].map(readable))\n",
    "    return new_df\n",
    "\n",
    "def module_complement_workflow(KO_genome_hits,output_dir,orig_contrib,min_completeness, min_diff,return_all=False):\n",
    "    \n",
    "    missing_module_info,present_KOs_module,KO_module_pairs=missing_KO_in_modules(KO_genome_hits,output_dir)\n",
    "    pairwise_complement_dict=pairwise_compare(present_KOs_module,missing_module_info,KO_module_pairs,min_diff,min_completeness)\n",
    "    clean_pair_comp_subset=clean_pairs(pairwise_complement_dict)\n",
    "    metab_comp_df=make_complement_dataframe(clean_pair_comp_subset)\n",
    "    reduced_df=save_output(metab_comp_df,orig_contrib,output_dir)\n",
    "    if return_all:\n",
    "        return metab_comp_df\n",
    "    else:\n",
    "        return reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within Module Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=module_complement_workflow(KO_genome_hits,output_dir,0.4,0.8,0.4,return_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Node Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_degree_rcn_wf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ece71d350ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_degree_rcn_wf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreaction_graphs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"cpds\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcommon_cpds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'one_degree_rcn_wf' is not defined"
     ]
    }
   ],
   "source": [
    "one_degree_rcn_wf(reaction_graphs,\"cpds\",common_cpds,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in previously made graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reaction_graphs=load_graphs(os.path.join(output_dir,\"graphs\",\"Reaction_links\",\"Side_ambiguous\"),'*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=reaction_graphs['U_52423']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing graph merging and the new cpd to reaction path tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pair=(reaction_graphs['coral'],reaction_graphs['SymbC15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_graph=merge_graphs(test_pair[0],test_pair[1],common_cpds)\n",
    "#looks like the graph merging works. Yay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.15104389190674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "timeit.timeit(\"merge_graphs(test_pair[0],test_pair[1],common_cpds)\",\"from __main__ import merge_graphs, common_cpds, test_pair\",number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split=merged_graph.name.split(\":\")\n",
    "first=split[0]\n",
    "last=split[1]\n",
    "gen_1_reactions, gen_2_reactions=_unique_compound_pairs(merged_graph,(first,last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 314\n"
     ]
    }
   ],
   "source": [
    "print len(gen_1_reactions), len(gen_2_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpds': {u'C00001', u'C00014', u'C00299', u'C00475'}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_temp={rcn:data for rcn, data in reaction_graphs['coral'].nodes(data=True)}\n",
    "new_temp['R01878']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['R04893', 'R04930', 'R04907', 'R04890', 'R01168', 'R03909', 'R01001', 'R08348', 'R00277', 'R04908', 'R01676', 'R01230', 'R04674', 'R00131', 'R01579', 'R02540', 'R02529', 'R00485', 'R02408', 'R04025', 'R00220', 'R05590', 'R07700', 'R00348', 'R00269', 'R00248', 'R00689', 'R05551', 'R00084', 'R00748', 'R02613', 'R00243', 'R00571', 'R03096', 'R00253', 'R00648', 'R01663', 'R04666', 'R02382', 'R01878', 'R00729', 'R02485', 'R00181', 'R01134', 'R00359', 'R04300', 'R02908', 'R01560', 'R04125', 'R02302', 'R04770', 'R00677', 'R00996', 'R10949', 'R01221', 'R03180', 'R02532', 'R02150', 'R00765', 'R00256', 'R02556', 'R00357', 'R09366', 'R00905', 'R08221', 'R01710', 'R01151', 'R02173', 'R02197', 'R08228', 'R00782']) set([])\n"
     ]
    }
   ],
   "source": [
    "test_start,test_end=extract_starting_ending_reactions(reaction_graphs['coral'],\"C00014\",\"C01289\",\"cpds\")\n",
    "print test_start,test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([]) set(['R04893', 'R04930', 'R04907', 'R04890', 'R01168', 'R03909', 'R01001', 'R08348', 'R00277', 'R04908', 'R01676', 'R01230', 'R04674', 'R00131', 'R01579', 'R02540', 'R02529', 'R00485', 'R02408', 'R04025', 'R00220', 'R05590', 'R07700', 'R00348', 'R00269', 'R00248', 'R00689', 'R05551', 'R00084', 'R00748', 'R02613', 'R00243', 'R00571', 'R03096', 'R00253', 'R00648', 'R01663', 'R04666', 'R02382', 'R01878', 'R00729', 'R02485', 'R00181', 'R01134', 'R00359', 'R04300', 'R02908', 'R01560', 'R04125', 'R02302', 'R04770', 'R00677', 'R00996', 'R10949', 'R01221', 'R03180', 'R02532', 'R02150', 'R00765', 'R00256', 'R02556', 'R00357', 'R09366', 'R00905', 'R08221', 'R01710', 'R01151', 'R02173', 'R02197', 'R08228', 'R00782'])\n",
      "set([]) set([])\n",
      "set([]) set(['R02521', 'R03342', 'R00734', 'R00729'])\n"
     ]
    }
   ],
   "source": [
    "iter_pairs=extract_all_starting_ending_reacitons(reaction_graphs['coral'], [(\"C01289\",\"C00014\"),(\"C01289\",\"C01289\"),(\"C15547\",\"C01179\")],\"cpds\")\n",
    "for pair,second in iter_pairs:\n",
    "    print pair, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['R04893', 'R04930', 'R04907', 'R04890', 'R01168', 'R03909', 'R01001', 'R08348', 'R00277', 'R04908', 'R01676', 'R01230', 'R04674', 'R00131', 'R01579', 'R02540', 'R02529', 'R00485', 'R02408', 'R04025', 'R00220', 'R05590', 'R07700', 'R00348', 'R00269', 'R00248', 'R00689', 'R05551', 'R00084', 'R00748', 'R02613', 'R00243', 'R00571', 'R03096', 'R00253', 'R00648', 'R01663', 'R04666', 'R02382', 'R01878', 'R00729', 'R02485', 'R00181', 'R01134', 'R00359', 'R04300', 'R02908', 'R01560', 'R04125', 'R02302', 'R04770', 'R00677', 'R00996', 'R10949', 'R01221', 'R03180', 'R02532', 'R02150', 'R00765', 'R00256', 'R02556', 'R00357', 'R09366', 'R00905', 'R08221', 'R01710', 'R01151', 'R02173', 'R02197', 'R08228', 'R00782']) set(['R02521', 'R03342', 'R00734', 'R00729'])\n"
     ]
    }
   ],
   "source": [
    "iter_pairs=extract_all_starting_ending_reacitons(reaction_graphs['coral'], [(\"C00014\",\"C01179\")],\"cpds\")\n",
    "for pair,second in iter_pairs:\n",
    "    print pair, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "for path in nx.all_simple_paths(reaction_graphs['coral'],'R01878','R00734'):\n",
    "    i+=1\n",
    "    if i>=10:\n",
    "        break\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pairwise_merging=pairwise_merged_graphs(reaction_graphs,False)\n",
    "write_graph_dict(os.path.join(output_dir,\"graphs/Pairwise_reaction_links\"),test_pairwise_merging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairwise_merged_graphs_individually(reaction_graphs,os.path.join(output_dir,\"graphs/Pairwise_reaction_links\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-07-22 09:44:19,706 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-both-final.gff)\n",
      "2016-07-22 09:44:19,706 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-both-final.gff)\n",
      "2016-07-22 09:44:20,299 -    INFO - mgkit.io.gff->parse_gff: Read 2762 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-both-final.gff)\n",
      "2016-07-22 09:44:20,299 -    INFO - mgkit.io.gff->parse_gff: Read 2762 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-both-final.gff)\n",
      "2016-07-22 09:44:20,332 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-both-final.gff)\n",
      "2016-07-22 09:44:20,332 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-both-final.gff)\n",
      "2016-07-22 09:44:21,129 -    INFO - mgkit.io.gff->parse_gff: Read 3761 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-both-final.gff)\n",
      "2016-07-22 09:44:21,129 -    INFO - mgkit.io.gff->parse_gff: Read 3761 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-both-final.gff)\n",
      "2016-07-22 09:44:21,152 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-both-final.gff)\n",
      "2016-07-22 09:44:21,152 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,107 -    INFO - mgkit.io.gff->parse_gff: Read 5521 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,107 -    INFO - mgkit.io.gff->parse_gff: Read 5521 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,140 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,140 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,971 -    INFO - mgkit.io.gff->parse_gff: Read 2560 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,971 -    INFO - mgkit.io.gff->parse_gff: Read 2560 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,998 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-both-final.gff)\n",
      "2016-07-22 09:44:22,998 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-both-final.gff)\n",
      "2016-07-22 09:44:23,784 -    INFO - mgkit.io.gff->parse_gff: Read 3784 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-both-final.gff)\n",
      "2016-07-22 09:44:23,784 -    INFO - mgkit.io.gff->parse_gff: Read 3784 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-both-final.gff)\n",
      "2016-07-22 09:44:23,815 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-both-final.gff)\n",
      "2016-07-22 09:44:23,815 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-both-final.gff)\n",
      "2016-07-22 09:44:24,582 -    INFO - mgkit.io.gff->parse_gff: Read 2916 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-both-final.gff)\n",
      "2016-07-22 09:44:24,582 -    INFO - mgkit.io.gff->parse_gff: Read 2916 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-both-final.gff)\n",
      "2016-07-22 09:44:24,609 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-both-final.gff)\n",
      "2016-07-22 09:44:24,609 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-both-final.gff)\n",
      "2016-07-22 09:44:25,945 -    INFO - mgkit.io.gff->parse_gff: Read 3603 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-both-final.gff)\n",
      "2016-07-22 09:44:25,945 -    INFO - mgkit.io.gff->parse_gff: Read 3603 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-both-final.gff)\n",
      "2016-07-22 09:44:25,966 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-both-final.gff)\n",
      "2016-07-22 09:44:25,966 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,416 -    INFO - mgkit.io.gff->parse_gff: Read 1524 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,416 -    INFO - mgkit.io.gff->parse_gff: Read 1524 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,433 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,433 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,994 -    INFO - mgkit.io.gff->parse_gff: Read 3584 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-both-final.gff)\n",
      "2016-07-22 09:44:26,994 -    INFO - mgkit.io.gff->parse_gff: Read 3584 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,015 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,015 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,533 -    INFO - mgkit.io.gff->parse_gff: Read 2772 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,533 -    INFO - mgkit.io.gff->parse_gff: Read 2772 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,559 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-both-final.gff)\n",
      "2016-07-22 09:44:27,559 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,036 -    INFO - mgkit.io.gff->parse_gff: Read 1702 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,036 -    INFO - mgkit.io.gff->parse_gff: Read 1702 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,057 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,057 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,656 -    INFO - mgkit.io.gff->parse_gff: Read 2422 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,656 -    INFO - mgkit.io.gff->parse_gff: Read 2422 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,673 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-both-final.gff)\n",
      "2016-07-22 09:44:28,673 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,196 -    INFO - mgkit.io.gff->parse_gff: Read 2458 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,196 -    INFO - mgkit.io.gff->parse_gff: Read 2458 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,222 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,222 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,626 -    INFO - mgkit.io.gff->parse_gff: Read 1446 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,626 -    INFO - mgkit.io.gff->parse_gff: Read 1446 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,655 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-both-final.gff)\n",
      "2016-07-22 09:44:29,655 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,276 -    INFO - mgkit.io.gff->parse_gff: Read 2332 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,276 -    INFO - mgkit.io.gff->parse_gff: Read 2332 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,301 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,301 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,998 -    INFO - mgkit.io.gff->parse_gff: Read 2131 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-both-final.gff)\n",
      "2016-07-22 09:44:30,998 -    INFO - mgkit.io.gff->parse_gff: Read 2131 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,034 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,034 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,604 -    INFO - mgkit.io.gff->parse_gff: Read 1976 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,604 -    INFO - mgkit.io.gff->parse_gff: Read 1976 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,633 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-both-final.gff)\n",
      "2016-07-22 09:44:31,633 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,111 -    INFO - mgkit.io.gff->parse_gff: Read 1749 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,111 -    INFO - mgkit.io.gff->parse_gff: Read 1749 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,135 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,135 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,834 -    INFO - mgkit.io.gff->parse_gff: Read 2914 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,834 -    INFO - mgkit.io.gff->parse_gff: Read 2914 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,861 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-both-final.gff)\n",
      "2016-07-22 09:44:32,861 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,175 -    INFO - mgkit.io.gff->parse_gff: Read 1967 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,175 -    INFO - mgkit.io.gff->parse_gff: Read 1967 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,201 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,201 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,646 -    INFO - mgkit.io.gff->parse_gff: Read 3033 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,646 -    INFO - mgkit.io.gff->parse_gff: Read 3033 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,667 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,667 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,881 -    INFO - mgkit.io.gff->parse_gff: Read 1431 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,881 -    INFO - mgkit.io.gff->parse_gff: Read 1431 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,900 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-both-final.gff)\n",
      "2016-07-22 09:44:33,900 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,145 -    INFO - mgkit.io.gff->parse_gff: Read 1795 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,145 -    INFO - mgkit.io.gff->parse_gff: Read 1795 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,159 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,159 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,586 -    INFO - mgkit.io.gff->parse_gff: Read 3209 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,586 -    INFO - mgkit.io.gff->parse_gff: Read 3209 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,602 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-both-final.gff)\n",
      "2016-07-22 09:44:34,602 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,111 -    INFO - mgkit.io.gff->parse_gff: Read 3519 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,111 -    INFO - mgkit.io.gff->parse_gff: Read 3519 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,125 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,125 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,511 -    INFO - mgkit.io.gff->parse_gff: Read 3574 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,511 -    INFO - mgkit.io.gff->parse_gff: Read 3574 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,531 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,531 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,923 -    INFO - mgkit.io.gff->parse_gff: Read 4331 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,923 -    INFO - mgkit.io.gff->parse_gff: Read 4331 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,940 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-both-final.gff)\n",
      "2016-07-22 09:44:35,940 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,317 -    INFO - mgkit.io.gff->parse_gff: Read 3905 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,317 -    INFO - mgkit.io.gff->parse_gff: Read 3905 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,330 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,330 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,654 -    INFO - mgkit.io.gff->parse_gff: Read 3198 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,654 -    INFO - mgkit.io.gff->parse_gff: Read 3198 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,685 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-both-final.gff)\n",
      "2016-07-22 09:44:36,685 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,155 -    INFO - mgkit.io.gff->parse_gff: Read 4031 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,155 -    INFO - mgkit.io.gff->parse_gff: Read 4031 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,179 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,179 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,697 -    INFO - mgkit.io.gff->parse_gff: Read 2555 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,697 -    INFO - mgkit.io.gff->parse_gff: Read 2555 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,726 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-both-final.gff)\n",
      "2016-07-22 09:44:37,726 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-both-final.gff)\n",
      "2016-07-22 09:44:38,483 -    INFO - mgkit.io.gff->parse_gff: Read 3424 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-both-final.gff)\n",
      "2016-07-22 09:44:38,483 -    INFO - mgkit.io.gff->parse_gff: Read 3424 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-both-final.gff)\n",
      "2016-07-22 09:44:38,503 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-both-final.gff)\n",
      "2016-07-22 09:44:38,503 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,221 -    INFO - mgkit.io.gff->parse_gff: Read 3673 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,221 -    INFO - mgkit.io.gff->parse_gff: Read 3673 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,235 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,235 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,890 -    INFO - mgkit.io.gff->parse_gff: Read 2965 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,890 -    INFO - mgkit.io.gff->parse_gff: Read 2965 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,910 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-both-final.gff)\n",
      "2016-07-22 09:44:39,910 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-both-final.gff)\n",
      "2016-07-22 09:44:40,387 -    INFO - mgkit.io.gff->parse_gff: Read 2281 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-both-final.gff)\n",
      "2016-07-22 09:44:40,387 -    INFO - mgkit.io.gff->parse_gff: Read 2281 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-both-final.gff)\n",
      "2016-07-22 09:44:40,412 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-both-final.gff)\n",
      "2016-07-22 09:44:40,412 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-both-final.gff)\n",
      "2016-07-22 09:44:41,110 -    INFO - mgkit.io.gff->parse_gff: Read 3502 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-both-final.gff)\n",
      "2016-07-22 09:44:41,110 -    INFO - mgkit.io.gff->parse_gff: Read 3502 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-both-final.gff)\n",
      "2016-07-22 09:44:41,133 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-both-final.gff)\n",
      "2016-07-22 09:44:41,133 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,045 -    INFO - mgkit.io.gff->parse_gff: Read 4405 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,045 -    INFO - mgkit.io.gff->parse_gff: Read 4405 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,077 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,077 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,415 -    INFO - mgkit.io.gff->parse_gff: Read 1287 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,415 -    INFO - mgkit.io.gff->parse_gff: Read 1287 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,440 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-both-final.gff)\n",
      "2016-07-22 09:44:42,440 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,025 -    INFO - mgkit.io.gff->parse_gff: Read 2219 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,025 -    INFO - mgkit.io.gff->parse_gff: Read 2219 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,059 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,059 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,689 -    INFO - mgkit.io.gff->parse_gff: Read 2479 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,689 -    INFO - mgkit.io.gff->parse_gff: Read 2479 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,712 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-both-final.gff)\n",
      "2016-07-22 09:44:43,712 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-both-final.gff)\n",
      "2016-07-22 09:44:44,647 -    INFO - mgkit.io.gff->parse_gff: Read 4197 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-both-final.gff)\n",
      "2016-07-22 09:44:44,647 -    INFO - mgkit.io.gff->parse_gff: Read 4197 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-both-final.gff)\n",
      "2016-07-22 09:44:44,684 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-both-final.gff)\n",
      "2016-07-22 09:44:44,684 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-both-final.gff)\n",
      "2016-07-22 09:44:45,441 -    INFO - mgkit.io.gff->parse_gff: Read 2795 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-both-final.gff)\n",
      "2016-07-22 09:44:45,441 -    INFO - mgkit.io.gff->parse_gff: Read 2795 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-both-final.gff)\n",
      "2016-07-22 09:44:45,478 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-both-final.gff)\n",
      "2016-07-22 09:44:45,478 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-both-final.gff)\n",
      "2016-07-22 09:44:46,458 -    INFO - mgkit.io.gff->parse_gff: Read 3272 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-both-final.gff)\n",
      "2016-07-22 09:44:46,458 -    INFO - mgkit.io.gff->parse_gff: Read 3272 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-both-final.gff)\n",
      "2016-07-22 09:44:46,485 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-both-final.gff)\n",
      "2016-07-22 09:44:46,485 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,211 -    INFO - mgkit.io.gff->parse_gff: Read 2983 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,211 -    INFO - mgkit.io.gff->parse_gff: Read 2983 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,240 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,240 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,789 -    INFO - mgkit.io.gff->parse_gff: Read 2540 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,789 -    INFO - mgkit.io.gff->parse_gff: Read 2540 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,816 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-both-final.gff)\n",
      "2016-07-22 09:44:47,816 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,272 -    INFO - mgkit.io.gff->parse_gff: Read 2400 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,272 -    INFO - mgkit.io.gff->parse_gff: Read 2400 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,302 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,302 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,826 -    INFO - mgkit.io.gff->parse_gff: Read 2487 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,826 -    INFO - mgkit.io.gff->parse_gff: Read 2487 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,853 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-both-final.gff)\n",
      "2016-07-22 09:44:48,853 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,076 -    INFO - mgkit.io.gff->parse_gff: Read 1311 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,076 -    INFO - mgkit.io.gff->parse_gff: Read 1311 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,099 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,099 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,526 -    INFO - mgkit.io.gff->parse_gff: Read 2196 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,526 -    INFO - mgkit.io.gff->parse_gff: Read 2196 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,547 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-both-final.gff)\n",
      "2016-07-22 09:44:49,547 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-both-final.gff)\n",
      "2016-07-22 09:44:50,076 -    INFO - mgkit.io.gff->parse_gff: Read 2446 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-both-final.gff)\n",
      "2016-07-22 09:44:50,076 -    INFO - mgkit.io.gff->parse_gff: Read 2446 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-both-final.gff)\n",
      "2016-07-22 09:44:50,107 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-both-final.gff)\n",
      "2016-07-22 09:44:50,107 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,085 -    INFO - mgkit.io.gff->parse_gff: Read 3202 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,085 -    INFO - mgkit.io.gff->parse_gff: Read 3202 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,134 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,134 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,864 -    INFO - mgkit.io.gff->parse_gff: Read 1807 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-both-final.gff)\n",
      "2016-07-22 09:44:51,864 -    INFO - mgkit.io.gff->parse_gff: Read 1807 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-both-final.gff)\n",
      "2016-07-22 09:44:52,907 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:52,907 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,161 -    INFO - mgkit.io.gff->parse_gff: Read 1712 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,161 -    INFO - mgkit.io.gff->parse_gff: Read 1712 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,175 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,175 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,440 -    INFO - mgkit.io.gff->parse_gff: Read 2002 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,440 -    INFO - mgkit.io.gff->parse_gff: Read 2002 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,453 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,453 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,844 -    INFO - mgkit.io.gff->parse_gff: Read 3027 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,844 -    INFO - mgkit.io.gff->parse_gff: Read 3027 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,865 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:53,865 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,222 -    INFO - mgkit.io.gff->parse_gff: Read 1502 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,222 -    INFO - mgkit.io.gff->parse_gff: Read 1502 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,243 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,243 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,764 -    INFO - mgkit.io.gff->parse_gff: Read 1988 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,764 -    INFO - mgkit.io.gff->parse_gff: Read 1988 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,796 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:54,796 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,215 -    INFO - mgkit.io.gff->parse_gff: Read 1999 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,215 -    INFO - mgkit.io.gff->parse_gff: Read 1999 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,232 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,232 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,810 -    INFO - mgkit.io.gff->parse_gff: Read 2006 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,810 -    INFO - mgkit.io.gff->parse_gff: Read 2006 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,838 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:55,838 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,062 -    INFO - mgkit.io.gff->parse_gff: Read 961 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,062 -    INFO - mgkit.io.gff->parse_gff: Read 961 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,082 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,082 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,421 -    INFO - mgkit.io.gff->parse_gff: Read 2028 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,421 -    INFO - mgkit.io.gff->parse_gff: Read 2028 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,435 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:56,435 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,092 -    INFO - mgkit.io.gff->parse_gff: Read 1510 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,092 -    INFO - mgkit.io.gff->parse_gff: Read 1510 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,115 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,115 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,217 -    INFO - mgkit.io.gff->parse_gff: Read 880 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,217 -    INFO - mgkit.io.gff->parse_gff: Read 880 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,278 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,278 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,444 -    INFO - mgkit.io.gff->parse_gff: Read 1432 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,444 -    INFO - mgkit.io.gff->parse_gff: Read 1432 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,457 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,457 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,597 -    INFO - mgkit.io.gff->parse_gff: Read 1456 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,597 -    INFO - mgkit.io.gff->parse_gff: Read 1456 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,612 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,612 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,726 -    INFO - mgkit.io.gff->parse_gff: Read 1032 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,726 -    INFO - mgkit.io.gff->parse_gff: Read 1032 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,739 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,739 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,832 -    INFO - mgkit.io.gff->parse_gff: Read 1287 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,832 -    INFO - mgkit.io.gff->parse_gff: Read 1287 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,844 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,844 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,974 -    INFO - mgkit.io.gff->parse_gff: Read 1452 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,974 -    INFO - mgkit.io.gff->parse_gff: Read 1452 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,987 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-sprot-final.gff)\n",
      "2016-07-22 09:44:59,987 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,129 -    INFO - mgkit.io.gff->parse_gff: Read 1141 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,129 -    INFO - mgkit.io.gff->parse_gff: Read 1141 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,142 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,142 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,242 -    INFO - mgkit.io.gff->parse_gff: Read 1135 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,242 -    INFO - mgkit.io.gff->parse_gff: Read 1135 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,254 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,254 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,393 -    INFO - mgkit.io.gff->parse_gff: Read 1470 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,393 -    INFO - mgkit.io.gff->parse_gff: Read 1470 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,405 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,405 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,534 -    INFO - mgkit.io.gff->parse_gff: Read 1284 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,534 -    INFO - mgkit.io.gff->parse_gff: Read 1284 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,548 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,548 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,761 -    INFO - mgkit.io.gff->parse_gff: Read 1843 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,761 -    INFO - mgkit.io.gff->parse_gff: Read 1843 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,774 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,774 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,859 -    INFO - mgkit.io.gff->parse_gff: Read 833 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,859 -    INFO - mgkit.io.gff->parse_gff: Read 833 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,870 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,870 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,959 -    INFO - mgkit.io.gff->parse_gff: Read 1195 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,959 -    INFO - mgkit.io.gff->parse_gff: Read 1195 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,976 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:00,976 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,104 -    INFO - mgkit.io.gff->parse_gff: Read 1782 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,104 -    INFO - mgkit.io.gff->parse_gff: Read 1782 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,113 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,113 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,243 -    INFO - mgkit.io.gff->parse_gff: Read 1860 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,243 -    INFO - mgkit.io.gff->parse_gff: Read 1860 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,259 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,259 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,407 -    INFO - mgkit.io.gff->parse_gff: Read 1904 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,407 -    INFO - mgkit.io.gff->parse_gff: Read 1904 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,417 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,417 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,632 -    INFO - mgkit.io.gff->parse_gff: Read 2490 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,632 -    INFO - mgkit.io.gff->parse_gff: Read 2490 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,643 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,643 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,965 -    INFO - mgkit.io.gff->parse_gff: Read 2093 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:01,965 -    INFO - mgkit.io.gff->parse_gff: Read 2093 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,000 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,000 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,170 -    INFO - mgkit.io.gff->parse_gff: Read 1971 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,170 -    INFO - mgkit.io.gff->parse_gff: Read 1971 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,185 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,185 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,357 -    INFO - mgkit.io.gff->parse_gff: Read 2097 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,357 -    INFO - mgkit.io.gff->parse_gff: Read 2097 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,367 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,367 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,489 -    INFO - mgkit.io.gff->parse_gff: Read 1445 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,489 -    INFO - mgkit.io.gff->parse_gff: Read 1445 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,498 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,498 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,689 -    INFO - mgkit.io.gff->parse_gff: Read 1760 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,689 -    INFO - mgkit.io.gff->parse_gff: Read 1760 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,704 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,704 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,860 -    INFO - mgkit.io.gff->parse_gff: Read 1980 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,860 -    INFO - mgkit.io.gff->parse_gff: Read 1980 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,872 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:02,872 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,054 -    INFO - mgkit.io.gff->parse_gff: Read 1852 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,054 -    INFO - mgkit.io.gff->parse_gff: Read 1852 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,066 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,066 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,188 -    INFO - mgkit.io.gff->parse_gff: Read 1583 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,188 -    INFO - mgkit.io.gff->parse_gff: Read 1583 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,198 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,198 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,344 -    INFO - mgkit.io.gff->parse_gff: Read 1901 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,344 -    INFO - mgkit.io.gff->parse_gff: Read 1901 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,354 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,354 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,511 -    INFO - mgkit.io.gff->parse_gff: Read 2493 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,511 -    INFO - mgkit.io.gff->parse_gff: Read 2493 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,523 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,523 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,600 -    INFO - mgkit.io.gff->parse_gff: Read 948 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,600 -    INFO - mgkit.io.gff->parse_gff: Read 948 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,616 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,616 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,732 -    INFO - mgkit.io.gff->parse_gff: Read 1416 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,732 -    INFO - mgkit.io.gff->parse_gff: Read 1416 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,744 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,744 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,868 -    INFO - mgkit.io.gff->parse_gff: Read 1525 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,868 -    INFO - mgkit.io.gff->parse_gff: Read 1525 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,881 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:03,881 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,035 -    INFO - mgkit.io.gff->parse_gff: Read 1966 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,035 -    INFO - mgkit.io.gff->parse_gff: Read 1966 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,047 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,047 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,169 -    INFO - mgkit.io.gff->parse_gff: Read 1745 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,169 -    INFO - mgkit.io.gff->parse_gff: Read 1745 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,177 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,177 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,340 -    INFO - mgkit.io.gff->parse_gff: Read 2118 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,340 -    INFO - mgkit.io.gff->parse_gff: Read 2118 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,350 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,350 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,466 -    INFO - mgkit.io.gff->parse_gff: Read 1762 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,466 -    INFO - mgkit.io.gff->parse_gff: Read 1762 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,476 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,476 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,576 -    INFO - mgkit.io.gff->parse_gff: Read 1615 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,576 -    INFO - mgkit.io.gff->parse_gff: Read 1615 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,587 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,587 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,723 -    INFO - mgkit.io.gff->parse_gff: Read 1448 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,723 -    INFO - mgkit.io.gff->parse_gff: Read 1448 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,735 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,735 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,848 -    INFO - mgkit.io.gff->parse_gff: Read 1573 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,848 -    INFO - mgkit.io.gff->parse_gff: Read 1573 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,860 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,860 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,921 -    INFO - mgkit.io.gff->parse_gff: Read 1000 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,921 -    INFO - mgkit.io.gff->parse_gff: Read 1000 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,934 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:04,934 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,023 -    INFO - mgkit.io.gff->parse_gff: Read 1274 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,023 -    INFO - mgkit.io.gff->parse_gff: Read 1274 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,033 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,033 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,146 -    INFO - mgkit.io.gff->parse_gff: Read 1454 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,146 -    INFO - mgkit.io.gff->parse_gff: Read 1454 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,159 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,159 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,317 -    INFO - mgkit.io.gff->parse_gff: Read 2053 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,317 -    INFO - mgkit.io.gff->parse_gff: Read 2053 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,330 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,330 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,415 -    INFO - mgkit.io.gff->parse_gff: Read 1150 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,415 -    INFO - mgkit.io.gff->parse_gff: Read 1150 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-sprot-final.gff)\n",
      "2016-07-22 09:45:05,574 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,574 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,663 -    INFO - mgkit.io.gff->parse_gff: Read 1043 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,663 -    INFO - mgkit.io.gff->parse_gff: Read 1043 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_41432_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,672 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,672 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,769 -    INFO - mgkit.io.gff->parse_gff: Read 1751 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,769 -    INFO - mgkit.io.gff->parse_gff: Read 1751 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51863_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,778 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:05,778 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,241 -    INFO - mgkit.io.gff->parse_gff: Read 2475 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,241 -    INFO - mgkit.io.gff->parse_gff: Read 2475 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51873_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,262 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,262 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,496 -    INFO - mgkit.io.gff->parse_gff: Read 1055 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,496 -    INFO - mgkit.io.gff->parse_gff: Read 1055 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_51892_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,519 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,519 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,967 -    INFO - mgkit.io.gff->parse_gff: Read 1786 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,967 -    INFO - mgkit.io.gff->parse_gff: Read 1786 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52266_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,993 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:06,993 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,266 -    INFO - mgkit.io.gff->parse_gff: Read 911 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,266 -    INFO - mgkit.io.gff->parse_gff: Read 911 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52270_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,320 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,320 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,783 -    INFO - mgkit.io.gff->parse_gff: Read 1589 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,783 -    INFO - mgkit.io.gff->parse_gff: Read 1589 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52271_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,814 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,814 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,997 -    INFO - mgkit.io.gff->parse_gff: Read 560 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:07,997 -    INFO - mgkit.io.gff->parse_gff: Read 560 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52278_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,026 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,026 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,377 -    INFO - mgkit.io.gff->parse_gff: Read 1524 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,377 -    INFO - mgkit.io.gff->parse_gff: Read 1524 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52290_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,404 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,404 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,724 -    INFO - mgkit.io.gff->parse_gff: Read 1257 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,724 -    INFO - mgkit.io.gff->parse_gff: Read 1257 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52338_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,786 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,786 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,972 -    INFO - mgkit.io.gff->parse_gff: Read 820 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:08,972 -    INFO - mgkit.io.gff->parse_gff: Read 820 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52366_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,001 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,001 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,232 -    INFO - mgkit.io.gff->parse_gff: Read 986 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,232 -    INFO - mgkit.io.gff->parse_gff: Read 986 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52368_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,254 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,254 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,505 -    INFO - mgkit.io.gff->parse_gff: Read 998 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,505 -    INFO - mgkit.io.gff->parse_gff: Read 998 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52375_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,529 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,529 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,648 -    INFO - mgkit.io.gff->parse_gff: Read 412 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,648 -    INFO - mgkit.io.gff->parse_gff: Read 412 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/filtered_U_52380_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,675 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,675 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,896 -    INFO - mgkit.io.gff->parse_gff: Read 1043 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,896 -    INFO - mgkit.io.gff->parse_gff: Read 1043 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51962_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,920 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:09,920 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,082 -    INFO - mgkit.io.gff->parse_gff: Read 673 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,082 -    INFO - mgkit.io.gff->parse_gff: Read 673 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51963_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,106 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,106 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,295 -    INFO - mgkit.io.gff->parse_gff: Read 833 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,295 -    INFO - mgkit.io.gff->parse_gff: Read 833 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_51967_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,332 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,332 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,475 -    INFO - mgkit.io.gff->parse_gff: Read 613 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,475 -    INFO - mgkit.io.gff->parse_gff: Read 613 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52087_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,529 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,529 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,961 -    INFO - mgkit.io.gff->parse_gff: Read 1434 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,961 -    INFO - mgkit.io.gff->parse_gff: Read 1434 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52098_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,997 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:10,997 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,198 -    INFO - mgkit.io.gff->parse_gff: Read 682 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,198 -    INFO - mgkit.io.gff->parse_gff: Read 682 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52105_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,229 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,229 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,535 -    INFO - mgkit.io.gff->parse_gff: Read 1188 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,535 -    INFO - mgkit.io.gff->parse_gff: Read 1188 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52123_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,556 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,556 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,686 -    INFO - mgkit.io.gff->parse_gff: Read 597 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,686 -    INFO - mgkit.io.gff->parse_gff: Read 597 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52180_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,709 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,709 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,852 -    INFO - mgkit.io.gff->parse_gff: Read 596 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,852 -    INFO - mgkit.io.gff->parse_gff: Read 596 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52401_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,873 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:11,873 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,152 -    INFO - mgkit.io.gff->parse_gff: Read 1420 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,152 -    INFO - mgkit.io.gff->parse_gff: Read 1420 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52403_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,177 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,177 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,532 -    INFO - mgkit.io.gff->parse_gff: Read 1653 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,532 -    INFO - mgkit.io.gff->parse_gff: Read 1653 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52410_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,559 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,559 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,986 -    INFO - mgkit.io.gff->parse_gff: Read 1647 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:12,986 -    INFO - mgkit.io.gff->parse_gff: Read 1647 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52420_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,035 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,035 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,444 -    INFO - mgkit.io.gff->parse_gff: Read 1829 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,444 -    INFO - mgkit.io.gff->parse_gff: Read 1829 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52423_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,474 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,474 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,879 -    INFO - mgkit.io.gff->parse_gff: Read 1801 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,879 -    INFO - mgkit.io.gff->parse_gff: Read 1801 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52425_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,909 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:13,909 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,149 -    INFO - mgkit.io.gff->parse_gff: Read 1217 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,149 -    INFO - mgkit.io.gff->parse_gff: Read 1217 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52434_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,175 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,175 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,588 -    INFO - mgkit.io.gff->parse_gff: Read 1915 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,588 -    INFO - mgkit.io.gff->parse_gff: Read 1915 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52439_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,617 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,617 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,844 -    INFO - mgkit.io.gff->parse_gff: Read 1102 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,844 -    INFO - mgkit.io.gff->parse_gff: Read 1102 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52448_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,871 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:14,871 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,277 -    INFO - mgkit.io.gff->parse_gff: Read 1650 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,277 -    INFO - mgkit.io.gff->parse_gff: Read 1650 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52452_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,316 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,316 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,775 -    INFO - mgkit.io.gff->parse_gff: Read 1676 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,775 -    INFO - mgkit.io.gff->parse_gff: Read 1676 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52459_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,809 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:15,809 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,123 -    INFO - mgkit.io.gff->parse_gff: Read 1112 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,123 -    INFO - mgkit.io.gff->parse_gff: Read 1112 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52472_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,154 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,154 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,490 -    INFO - mgkit.io.gff->parse_gff: Read 694 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,490 -    INFO - mgkit.io.gff->parse_gff: Read 694 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52478_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,527 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,527 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,885 -    INFO - mgkit.io.gff->parse_gff: Read 1586 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,885 -    INFO - mgkit.io.gff->parse_gff: Read 1586 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52505_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,913 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:16,913 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,450 -    INFO - mgkit.io.gff->parse_gff: Read 1893 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,450 -    INFO - mgkit.io.gff->parse_gff: Read 1893 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52514_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,493 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,493 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,605 -    INFO - mgkit.io.gff->parse_gff: Read 339 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,605 -    INFO - mgkit.io.gff->parse_gff: Read 339 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52517_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,641 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,641 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,829 -    INFO - mgkit.io.gff->parse_gff: Read 792 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,829 -    INFO - mgkit.io.gff->parse_gff: Read 792 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52520_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,860 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:17,860 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,065 -    INFO - mgkit.io.gff->parse_gff: Read 949 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,065 -    INFO - mgkit.io.gff->parse_gff: Read 949 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52524_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,096 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,096 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,629 -    INFO - mgkit.io.gff->parse_gff: Read 2223 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,629 -    INFO - mgkit.io.gff->parse_gff: Read 2223 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52525_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,665 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:18,665 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,056 -    INFO - mgkit.io.gff->parse_gff: Read 1042 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,056 -    INFO - mgkit.io.gff->parse_gff: Read 1042 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52528_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,085 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,085 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,393 -    INFO - mgkit.io.gff->parse_gff: Read 1154 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,393 -    INFO - mgkit.io.gff->parse_gff: Read 1154 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52529_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,424 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,424 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,652 -    INFO - mgkit.io.gff->parse_gff: Read 1212 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,652 -    INFO - mgkit.io.gff->parse_gff: Read 1212 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52530_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,679 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,679 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,852 -    INFO - mgkit.io.gff->parse_gff: Read 921 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,852 -    INFO - mgkit.io.gff->parse_gff: Read 921 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52531_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,919 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:19,919 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,092 -    INFO - mgkit.io.gff->parse_gff: Read 947 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,092 -    INFO - mgkit.io.gff->parse_gff: Read 947 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52532_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,125 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,125 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,333 -    INFO - mgkit.io.gff->parse_gff: Read 909 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,333 -    INFO - mgkit.io.gff->parse_gff: Read 909 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52536_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,381 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,381 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,455 -    INFO - mgkit.io.gff->parse_gff: Read 311 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,455 -    INFO - mgkit.io.gff->parse_gff: Read 311 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52544_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,479 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,479 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,701 -    INFO - mgkit.io.gff->parse_gff: Read 921 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,701 -    INFO - mgkit.io.gff->parse_gff: Read 921 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52582_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,732 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,732 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,934 -    INFO - mgkit.io.gff->parse_gff: Read 987 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,934 -    INFO - mgkit.io.gff->parse_gff: Read 987 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52615_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,955 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:20,955 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,200 -    INFO - mgkit.io.gff->parse_gff: Read 1133 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,200 -    INFO - mgkit.io.gff->parse_gff: Read 1133 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52637_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,225 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,225 -    INFO - mgkit.io.gff->parse_gff: Loading GFF from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,397 -    INFO - mgkit.io.gff->parse_gff: Read 656 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-trembl-final.gff)\n",
      "2016-07-22 09:45:21,397 -    INFO - mgkit.io.gff->parse_gff: Read 656 line from file (/home/alex/Documents/Hons/Seaquence/francesco_data/gff_bins-2016-06-14b/unfiltered_U_52661_genomic-trembl-final.gff)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 1638 341 1292\n",
      "666 1532 516 998\n",
      "533 1120 458 854\n",
      "658 1550 550 1106\n",
      "563 1143 508 939\n",
      "669 1554 577 1141\n",
      "878 1878 667 1164\n",
      "619 1485 520 1044\n",
      "202 708 191 629\n",
      "552 1226 491 951\n",
      "592 1396 481 951\n",
      "563 1021 530 889\n",
      "627 1385 517 992\n",
      "545 1139 472 901\n",
      "1079 1614 830 1090\n",
      "584 1380 530 1117\n",
      "217 948 204 789\n",
      "437 753 403 659\n",
      "778 1650 648 1211\n",
      "549 1292 412 818\n",
      "108 867 101 795\n",
      "1037 2235 763 1309\n",
      "355 853 316 650\n",
      "414 802 365 642\n",
      "896 1545 716 1029\n",
      "580 1322 457 902\n",
      "716 1913 579 1303\n",
      "374 961 348 863\n",
      "550 1270 461 891\n",
      "960 1225 794 964\n",
      "448 1121 381 772\n",
      "555 1271 454 925\n",
      "853 1103 750 934\n",
      "506 1092 418 802\n",
      "648 1507 528 1016\n",
      "833 1010 738 867\n",
      "691 1499 596 1154\n",
      "682 1538 510 994\n",
      "499 1125 409 771\n",
      "985 1538 703 959\n",
      "485 814 405 638\n",
      "650 1437 517 1008\n",
      "367 777 327 631\n",
      "398 964 367 757\n",
      "914 1625 696 1100\n",
      "609 1424 487 952\n",
      "724 1694 503 1052\n",
      "594 1123 499 850\n",
      "577 1379 487 999\n",
      "509 1198 398 779\n",
      "425 1097 370 753\n",
      "461 1199 400 796\n"
     ]
    }
   ],
   "source": [
    "#I made a new KEGG KO file from all of the microbial gff so there was no need to constantly mount the work server or mess with gffs\n",
    "\n",
    "def load_gffs(dir_name,glob_id):\n",
    "    gff_files = {}\n",
    "    for fname in glob(os.path.join(dir_name,glob_id)):\n",
    "        key = '_'.join(os.path.basename(fname).split('_')[1:3])\n",
    "        gff_files[key] = list(gff.parse_gff(fname))\n",
    "    return gff_files\n",
    "    \n",
    "def get_KO_from_gff(gff_files):\n",
    "    KO_ids={}\n",
    "    for genome_id, annotations in gff_files.iteritems():\n",
    "        genome_ko_ids = set()\n",
    "        for annotation in annotations:\n",
    "            for ko_id in annotation.get_mapping('KO'):\n",
    "                genome_ko_ids.add(ko_id)\n",
    "        KO_ids[genome_id]=genome_ko_ids\n",
    "    return KO_ids\n",
    "\n",
    "def get_KO_from_gff_not_set(gff_files):\n",
    "    KO_ids={}\n",
    "    for genome_id, annotations in gff_files.iteritems():\n",
    "        genome_ko_ids = []\n",
    "        for annotation in annotations:\n",
    "            for ko_id in annotation.get_mapping('KO'):\n",
    "                genome_ko_ids.append(ko_id)\n",
    "        KO_ids[genome_id]=genome_ko_ids\n",
    "    return KO_ids\n",
    "\n",
    "def write_genome_KO_file(output_file,KO_Genome_hits):\n",
    "    #print KO_Genome_hits\n",
    "    with open(output_file,'w') as microb_kos:\n",
    "        for genome, KO_hits in KO_Genome_hits.iteritems():\n",
    "            microb_kos.write(\"{0}\\t{1}\\n\".format(genome,\";\".join(KO_hits)))\n",
    "    return\n",
    "\n",
    "def remake_KOs_file(gff_dir, output_file, glob_ids):\n",
    "    gff_files={}\n",
    "    KO_hits={}\n",
    "    for glob_id in glob_ids:\n",
    "        gff_files[glob_id]=load_gffs(gff_dir,glob_id)\n",
    "        KO_hits[glob_id]=get_KO_from_gff_not_set(gff_files[glob_id])\n",
    "    if len(glob_ids)==1:\n",
    "        #print KO_hits[glob_id][0]\n",
    "        microbial_KO_hits=KO_hits.values()[0]\n",
    "    else:\n",
    "        microbial_KO_hits=merge_KO_hits(KO_hits)\n",
    "    write_genome_KO_file(output_file,microbial_KO_hits)\n",
    "    return microbial_KO_hits\n",
    "\n",
    "def merge_KO_hits(mult_KO_hits):\n",
    "    all_genomes=set(itertools.chain(key for genome_KO_dicts in mult_KO_hits.itervalues() for key in genome_KO_dicts.iterkeys()))\n",
    "    new_dict={genome:[] for genome in all_genomes}\n",
    "    for glob_id, genome_dicts in mult_KO_hits.iteritems():\n",
    "        for genome, KOs in genome_dicts.iteritems():\n",
    "            new_dict[genome]=new_dict[genome]+KOs\n",
    "    return new_dict\n",
    "\n",
    "microbial_KO_both_hits=remake_KOs_file(gff_dir,microbial_kegg,[\"*_genomic-both-final.gff\"])\n",
    "\n",
    "microbial_KO_sprot_trembl_hits=remake_KOs_file(gff_dir,microbial_kegg,[\"*_genomic-sprot-final.gff\",\"*_genomic-trembl-final.gff\"])\n",
    "\n",
    "for genome, KOs in microbial_KO_both_hits.iteritems():\n",
    "    print len(KOs), len(microbial_KO_sprot_trembl_hits[genome]), len(set(KOs)), len(set(microbial_KO_sprot_trembl_hits[genome]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simple, euk-like repeats table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gene_dir=\"G:\\data\\eukaryote_like_repeats\\gene_hits\"\n",
    "#gene_dir=\"/home/baker/Documents/MountedDrive/seaquence/data/eukaryote_like_repeats/gene_hits\"\n",
    "#load_euk_like_repeat_hits(gene_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob as gb\n",
    "from collections import defaultdict\n",
    "\n",
    "def hmmer_domtblout_parser(file_path,header_line,comment_char):\n",
    "    i=0\n",
    "    header_one_space_sep=[2,20]\n",
    "    line_one_space_sep=[2,-1]\n",
    "    regex_clean=re.compile(\"\\s{2,}\")\n",
    "    with open (file_path) as hmmer_hits:\n",
    "        for line in hmmer_hits:\n",
    "            if i==header_line:\n",
    "                yield list(itertools.chain(*[fields.split(\" \", 1) if i in header_one_space_sep else [fields] for i,fields in enumerate(regex_clean.split(line.strip())) ]))\n",
    "            elif not line.startswith(comment_char):\n",
    "                part_proc=regex_clean.split(line.strip())\n",
    "                for i in line_one_space_sep:\n",
    "                    part_proc[i]=part_proc[i].split(None,2)\n",
    "                \n",
    "                yield list(itertools.chain(*[ [item] if not isinstance(item,list) else item for item in part_proc]))\n",
    "            i+=1\n",
    "    \n",
    "def create_hmmer_domtblout_df(file_path,header_line,comment_char):\n",
    "    hmmer_file=hmmer_domtblout_parser(file_path,header_line,comment_char)\n",
    "    header=next(hmmer_file)\n",
    "    df=pd.DataFrame([\n",
    "            line for line in hmmer_file \n",
    "        ])\n",
    "    df.columns=header\n",
    "    return df\n",
    "\n",
    "def all_domtblout_df(file_path,header_line,comment_char,optional_reg_cut):\n",
    "    repeat_dfs={}\n",
    "    i=0\n",
    "    for file_path in gb.glob(os.path.join(file_path, \"*.tsv\")):\n",
    "        file_name=os.path.basename(file_path)\n",
    "        #print file_name\n",
    "        if isinstance(optional_reg_cut,type(None)):\n",
    "            file_id=file_name.replace(\".tsv\",\"\")\n",
    "        else:\n",
    "            file_id=file_name.replace(\".tsv\",\"\")\n",
    "            file_id=re.sub(optional_reg_cut,\"\",file_id)\n",
    "        repeat_dfs[file_id]=create_hmmer_domtblout_df(file_path,header_line,comment_char)\n",
    "        i+=1\n",
    "        if i%10==0:\n",
    "            print \"{0} files have been processed. The last was {1}\".format(i,file_id)\n",
    "    if len(repeat_dfs)==0:\n",
    "        print \"No files were loaded\"\n",
    "    return repeat_dfs\n",
    "\n",
    "def merge_repeat_dfs(df_dict):\n",
    "    df_list=[None]*len(df_dict)\n",
    "    i=0\n",
    "    for genome_id,df in df_dict.iteritems():\n",
    "        new_df=df\n",
    "        new_df['Genome_id']=genome_id\n",
    "        #new_df.rename(columns={0:'Gene_Name'},inplace=True)\n",
    "        df_list[i]=new_df\n",
    "        i+=1\n",
    "    merged_dict=pd.concat(df_list,axis=0)\n",
    "    merged_dict.index.names=[\"Gene_name\"]\n",
    "    cols = merged_dict.columns.tolist()\n",
    "    cols=cols[-1:]+cols[0:-1]\n",
    "    merged_dict=merged_dict[cols]\n",
    "    merged_dict['Genome_id']=merged_dict['Genome_id'].str.strip(\"_genomic\").str.strip(\"aa_genes_unfiltered_\").str.strip(\"aa_genes_filtered_\")\n",
    "    print merged_dict\n",
    "#    print merged_dict.ix[:,0]\n",
    "    return merged_dict\n",
    "\n",
    "def merge_repeat_dfs_wf(df_dict,output_file,taxonomy_file):\n",
    "    gene_level_hits=merge_repeat_dfs(df_dict)\n",
    "    gene_level_hits['Taxonomy']=gene_level_hits['Genome_id'].map(taxonomy_file)\n",
    "    cols = gene_level_hits.columns.tolist()\n",
    "    cols=[cols[0]]+cols[-1:]+cols[1:-1]\n",
    "    gene_level_hits=gene_level_hits[cols]\n",
    "    gene_level_hits.to_csv(output_file,sep=\"\\t\",index=True)\n",
    "    \n",
    "    return gene_level_hits\n",
    "    \n",
    "\n",
    "def all_hmms_hit(df):\n",
    "    \n",
    "    return\n",
    "\n",
    "def construct_n_genes_hits(df_dict,all_columns):\n",
    "    genome_ids=df_dict.keys()\n",
    "    column_names=pd.unique(itertools.chain(*df_dict.itervalues()))\n",
    "    gene_count_df=pd.DataFrame(index=genome_ids,columns=all_columns)\n",
    "    gene_count_df.index.name=\"Genome_id\"\n",
    "    \n",
    "    for file_id, df in df_dict.iteritems():\n",
    "        for repeat_motif,count in df.iteritems():\n",
    "            gene_count_df.set_value(file_id,repeat_motif,count)\n",
    "            \n",
    "    return gene_count_df\n",
    "\n",
    "def process_gene_hits(complete_df_dict,genome_taxonomy,output_file,all_motifs,taxonomy_file):\n",
    "    gene_hits={file_id: make_hmm_hits_to_gene_hits(df) for file_id, df in complete_df_dict.iteritems()}\n",
    "    gene_df=construct_n_genes_hits(gene_hits,all_motifs)\n",
    "    gene_df.reset_index(level=0,inplace=True)\n",
    "    gene_df['Genome_id']=gene_df['Genome_id'].str.strip(\"_genomic\").str.strip(\"aa_genes_unfiltered_\").str.strip(\"aa_genes_filtered_\")\n",
    "    #print gene_df.ix[:,0]\n",
    "    #print taxonomy_file\n",
    "    gene_df['Taxonomy']=gene_df['Genome_id'].map(taxonomy_file)\n",
    "    cols = gene_df.columns.tolist()\n",
    "    cols=[cols[0]]+cols[-1:]+cols[1:-1]\n",
    "    gene_df=gene_df[cols]\n",
    "    #Add taxonomy information\n",
    "    gene_df.to_csv(output_file, sep=\"\\t\",index=False)\n",
    "    \n",
    "    return gene_df\n",
    "\n",
    "def hmm_hits_in_gene(df,all_columns):\n",
    "    genes_hit=pd.unique(df['query name'])\n",
    "    repeats_found=pd.unique(df['# target name'])\n",
    "    hit_df=pd.DataFrame(index=genes_hit,columns=all_columns)\n",
    "    hit_df=hit_df.fillna(0)\n",
    "    all_counts=df.groupby(['query name','# target name']).count()['of']\n",
    "    for ((contig,repeat_motif),count) in all_counts.iteritems():\n",
    "        hit_df.set_value(contig,repeat_motif,count)\n",
    "        \n",
    "    return hit_df\n",
    "\n",
    "def make_hmm_hits_to_gene_hits(df):\n",
    "    #Check for any columns with at least one hit, add all true values\n",
    "    #to get number of genes with that motif.\n",
    "    return (df>0).sum(axis=0)\n",
    "\n",
    "def get_all_target_values(df_dict):\n",
    "    target_values=[]\n",
    "    for genome_id, df in df_dict.iteritems():\n",
    "        target_values.append(df['# target name'])\n",
    "        \n",
    "    return pd.unique(pd.concat(target_values,axis=0))\n",
    "\n",
    "def hmm_hits_wf(input_dir, output_dir,taxonomy_file, header_line,comment_char,optional_reg_cut):\n",
    "    all_dfs=all_domtblout_df(input_dir,header_line,comment_char,optional_reg_cut)\n",
    "    all_target_ids=get_all_target_values(all_dfs)\n",
    "    motif_hits_in_gene={file_id: hmm_hits_in_gene(df,all_target_ids) for file_id,df in all_dfs.iteritems()}\n",
    "    genome_taxonomy=load_bin_names(taxonomy_file)\n",
    "    genome_taxonomy=defaultdict(lambda: \"No predefined Taxonomy\",genome_taxonomy)\n",
    "    N_gene_hits=process_gene_hits(motif_hits_in_gene,genome_taxonomy,os.path.join(output_dir,\"N_genes_with_hits.tsv\"),all_target_ids,genome_taxonomy)\n",
    "    merged_hmm_hits=merge_repeat_dfs_wf(motif_hits_in_gene,os.path.join(output_dir,\"hmm_hits_per_gene_per_genome.tsv\"),genome_taxonomy)\n",
    "    \n",
    "    return N_gene_hits\n",
    "    \n",
    "def load_bin_names(tax_file):\n",
    "    #Load bin_ids and bins_taxonomy from file.\n",
    "    bin_names={}\n",
    "    bin_pair=[]\n",
    "    with open(tax_file,'r') as bin_tax_pair:\n",
    "        bin_tax_pair.readline()\n",
    "        for line in bin_tax_pair:\n",
    "            bin_pair.append(tuple(line.strip().split(\"\\t\")))\n",
    "\n",
    "    bin_names={bin_id:taxonomy for taxonomy, bin_id in bin_pair}\n",
    "    return bin_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/baker/grive/Honours/eukaryote_like_repeats/gene_hits'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/baker/grive/Honours/HMM_searches/Symbioses_test/euk_repeat_results'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files have been processed. The last was aa_genes_filtered_U_52338_genomic\n",
      "20 files have been processed. The last was aa_genes_unfiltered_U_52105_genomic\n",
      "30 files have been processed. The last was aa_genes_unfiltered_U_52439_genomic\n",
      "40 files have been processed. The last was aa_genes_unfiltered_U_52524_genomic\n",
      "50 files have been processed. The last was aa_genes_unfiltered_U_52615_genomic\n",
      "                 Genome_id  T2SSE  TPR_16  TPR_19  TPR_2  TPR_14  TPR_6  \\\n",
      "Gene_name                                                                 \n",
      "contig_446576_2    U_52529      1       0       0      0       0      0   \n",
      "contig_446576_3    U_52529      0       3       2      4       5      4   \n",
      "contig_446576_4    U_52529      0       0       0      0       0      0   \n",
      "contig_639749_1    U_52529      1       0       0      0       0      0   \n",
      "contig_658327_3    U_52529      0       9      10     13      12     10   \n",
      "contig_658327_8    U_52529      0       3       4      6       5      0   \n",
      "contig_742959_15   U_52529      0       2       0      3       3      3   \n",
      "contig_780312_1    U_52529      0       0       0      0       1      0   \n",
      "contig_785674_3    U_52529      1       0       0      0       0      0   \n",
      "contig_800139_1    U_52529      2       0       0      0       0      0   \n",
      "contig_845252_2    U_52529      0       3       4      3       3      4   \n",
      "contig_860008_1    U_52529      1       0       0      0       0      0   \n",
      "contig_873414_19   U_52529      0       0       0      0       2      0   \n",
      "contig_879610_2    U_52529      0       4       4      4       6      3   \n",
      "contig_882198_8    U_52529      0       2       4      7       5      4   \n",
      "contig_901963_2    U_52529      0       4       6      6       8      6   \n",
      "contig_905176_2    U_52529      0       0       0      2       0      0   \n",
      "contig_905550_1    U_52529      0       1       1      2       3      2   \n",
      "contig_906163_12   U_52529      0       2       2      4       2      4   \n",
      "contig_912680_5    U_52529      2       0       0      0       0      0   \n",
      "contig_912680_18   U_52529      0       0       0      0       0      0   \n",
      "contig_914325_1    U_52529      0       6       6      6       6      5   \n",
      "contig_915459_2    U_52529      0       4       3      7       4      5   \n",
      "contig_925061_8    U_52529      0       0       4      4       5      0   \n",
      "contig_948076_1    U_52529      2       0       0      0       0      0   \n",
      "contig_948076_4    U_52529      0       0       0      0       0      0   \n",
      "contig_952100_3    U_52529      0       0       0      0       0      0   \n",
      "contig_960418_2    U_52529      0       7       7     10      10      8   \n",
      "contig_960418_3    U_52529      1       0       0      0       0      0   \n",
      "contig_965982_1    U_52529      2       0       0      0       0      0   \n",
      "...                    ...    ...     ...     ...    ...     ...    ...   \n",
      "contig_802444_10   U_52582      0       1       1      2       2      2   \n",
      "contig_133648_1    U_52582      0       4       3      3       7      5   \n",
      "contig_133648_21   U_52582      2       0       0      0       0      0   \n",
      "contig_475443_4    U_52582      0       4       1      4       5      3   \n",
      "contig_924708_7    U_52582      0       0       0      0       0      0   \n",
      "contig_924708_13   U_52582      0       7       8     10      10      9   \n",
      "contig_921673_9    U_52582      0      10      11     15      14     14   \n",
      "contig_921673_16   U_52582      0       5       5      8       9      7   \n",
      "contig_921673_32   U_52582      0       2       2      3       3      3   \n",
      "contig_163488_11   U_52582      1       0       0      0       0      0   \n",
      "contig_545269_3    U_52582      0       6       7      8       8      8   \n",
      "contig_545269_5    U_52582      0       9       0      5       8      6   \n",
      "contig_120214_23   U_52582      1       0       0      0       0      0   \n",
      "contig_120214_50   U_52582      0       0       0      0       0      0   \n",
      "contig_292417_6    U_52582      0       4       5      7       5      5   \n",
      "contig_532169_3    U_52582      0       0       0      0       0      0   \n",
      "contig_260712_21   U_52582      0       4       3      5       4      2   \n",
      "contig_260712_34   U_52582      0       2       2      4       2      4   \n",
      "contig_260712_46   U_52582      0       3       3      4       4      5   \n",
      "contig_308586_72   U_52582      1       0       0      0       0      0   \n",
      "contig_308586_80   U_52582      0       0       0      0       0      0   \n",
      "contig_273577_15   U_52582      0       0       0      0       0      0   \n",
      "contig_243337_11   U_52582      0       3       0      0       0      0   \n",
      "contig_879637_2    U_52582      1       0       0      0       0      0   \n",
      "contig_759686_26   U_52582      0       4       0      0       5      3   \n",
      "contig_85365_29    U_52582      0       5       5      8       8      8   \n",
      "contig_85365_45    U_52582      0       0       0      0       2      0   \n",
      "contig_85365_46    U_52582      0       3       4      5       5      0   \n",
      "contig_193178_15   U_52582      2       0       0      0       0      0   \n",
      "NaN                U_52582      0       0       0      0       0      0   \n",
      "\n",
      "                  TPR_1  TPR_12  TPR_7       ...         WD40_alt  WD40  \\\n",
      "Gene_name                                    ...                          \n",
      "contig_446576_2       0       0      0       ...                0     0   \n",
      "contig_446576_3       4       3      3       ...                0     0   \n",
      "contig_446576_4       0       0      0       ...                0     0   \n",
      "contig_639749_1       0       0      0       ...                0     0   \n",
      "contig_658327_3      11       9     11       ...                0     0   \n",
      "contig_658327_8       4       4      7       ...                0     0   \n",
      "contig_742959_15      4       3      6       ...                0     0   \n",
      "contig_780312_1       0       0      0       ...                0     0   \n",
      "contig_785674_3       0       0      0       ...                0     0   \n",
      "contig_800139_1       0       0      0       ...                0     0   \n",
      "contig_845252_2       3       3      3       ...                0     0   \n",
      "contig_860008_1       0       0      0       ...                0     0   \n",
      "contig_873414_19      0       0      0       ...                0     0   \n",
      "contig_879610_2       0       3      0       ...                0     0   \n",
      "contig_882198_8       6       5      0       ...                0     0   \n",
      "contig_901963_2       5       8      7       ...                0     0   \n",
      "contig_905176_2       0       0      0       ...                0     0   \n",
      "contig_905550_1       1       1      1       ...                0     0   \n",
      "contig_906163_12      3       2      0       ...                0     0   \n",
      "contig_912680_5       0       0      0       ...                0     0   \n",
      "contig_912680_18      0       0      0       ...                0     0   \n",
      "contig_914325_1       6       4      5       ...                0     0   \n",
      "contig_915459_2       5       0      2       ...                0     0   \n",
      "contig_925061_8       0       5      0       ...                0     0   \n",
      "contig_948076_1       0       0      0       ...                0     0   \n",
      "contig_948076_4       0       0      0       ...                0     0   \n",
      "contig_952100_3       0       0      0       ...                0     0   \n",
      "contig_960418_2      10       6     10       ...                0     0   \n",
      "contig_960418_3       0       0      0       ...                0     0   \n",
      "contig_965982_1       0       0      0       ...                0     0   \n",
      "...                 ...     ...    ...       ...              ...   ...   \n",
      "contig_802444_10      2       1      2       ...                0     0   \n",
      "contig_133648_1       3       4      2       ...                0     0   \n",
      "contig_133648_21      0       0      0       ...                0     0   \n",
      "contig_475443_4       2       2      2       ...                0     0   \n",
      "contig_924708_7       0       0      0       ...                0     0   \n",
      "contig_924708_13     10       6     11       ...                0     0   \n",
      "contig_921673_9      15      10     13       ...                0     0   \n",
      "contig_921673_16      8       7      7       ...                0     0   \n",
      "contig_921673_32      3       2      3       ...                0     0   \n",
      "contig_163488_11      0       0      0       ...                0     0   \n",
      "contig_545269_3       8       6      8       ...                0     0   \n",
      "contig_545269_5       3       4      0       ...                0     0   \n",
      "contig_120214_23      0       0      0       ...                0     0   \n",
      "contig_120214_50      0       0      0       ...                0     0   \n",
      "contig_292417_6       6       4      5       ...                0     0   \n",
      "contig_532169_3       0       0      0       ...                0     0   \n",
      "contig_260712_21      4       0      0       ...                0     0   \n",
      "contig_260712_34      0       2      0       ...                0     0   \n",
      "contig_260712_46      4       4      4       ...                0     0   \n",
      "contig_308586_72      0       0      0       ...                0     0   \n",
      "contig_308586_80      0       0      0       ...                0     0   \n",
      "contig_273577_15      0       0      0       ...                0     0   \n",
      "contig_243337_11      0       0      0       ...                0     0   \n",
      "contig_879637_2       0       0      0       ...                0     0   \n",
      "contig_759686_26      0       0      0       ...                0     0   \n",
      "contig_85365_29       8       5      8       ...                0     0   \n",
      "contig_85365_45       1       0      1       ...                0     0   \n",
      "contig_85365_46       4       3      4       ...                0     0   \n",
      "contig_193178_15      0       0      0       ...                0     0   \n",
      "NaN                   0       0      0       ...                0     0   \n",
      "\n",
      "                  YscO-like  Type_III_YscX  YopE  YscW  TAL_effector  WD40_3  \\\n",
      "Gene_name                                                                      \n",
      "contig_446576_2           0              0     0     0             0       0   \n",
      "contig_446576_3           0              0     0     0             0       0   \n",
      "contig_446576_4           0              0     0     0             0       0   \n",
      "contig_639749_1           0              0     0     0             0       0   \n",
      "contig_658327_3           0              0     0     0             0       0   \n",
      "contig_658327_8           0              0     0     0             0       0   \n",
      "contig_742959_15          0              0     0     0             0       0   \n",
      "contig_780312_1           0              0     0     0             0       0   \n",
      "contig_785674_3           0              0     0     0             0       0   \n",
      "contig_800139_1           0              0     0     0             0       0   \n",
      "contig_845252_2           0              0     0     0             0       0   \n",
      "contig_860008_1           0              0     0     0             0       0   \n",
      "contig_873414_19          0              0     0     0             0       0   \n",
      "contig_879610_2           0              0     0     0             0       0   \n",
      "contig_882198_8           0              0     0     0             0       0   \n",
      "contig_901963_2           0              0     0     0             0       0   \n",
      "contig_905176_2           0              0     0     0             0       0   \n",
      "contig_905550_1           0              0     0     0             0       0   \n",
      "contig_906163_12          0              0     0     0             0       0   \n",
      "contig_912680_5           0              0     0     0             0       0   \n",
      "contig_912680_18          0              0     0     0             0       0   \n",
      "contig_914325_1           0              0     0     0             0       0   \n",
      "contig_915459_2           0              0     0     0             0       0   \n",
      "contig_925061_8           0              0     0     0             0       0   \n",
      "contig_948076_1           0              0     0     0             0       0   \n",
      "contig_948076_4           0              0     0     0             0       0   \n",
      "contig_952100_3           0              0     0     0             0       0   \n",
      "contig_960418_2           0              0     0     0             0       0   \n",
      "contig_960418_3           0              0     0     0             0       0   \n",
      "contig_965982_1           0              0     0     0             0       0   \n",
      "...                     ...            ...   ...   ...           ...     ...   \n",
      "contig_802444_10          0              0     0     0             0       0   \n",
      "contig_133648_1           0              0     0     0             0       0   \n",
      "contig_133648_21          0              0     0     0             0       0   \n",
      "contig_475443_4           0              0     0     0             0       0   \n",
      "contig_924708_7           0              0     0     0             0       0   \n",
      "contig_924708_13          0              0     0     0             0       0   \n",
      "contig_921673_9           0              0     0     0             0       0   \n",
      "contig_921673_16          0              0     0     0             0       0   \n",
      "contig_921673_32          0              0     0     0             0       0   \n",
      "contig_163488_11          0              0     0     0             0       0   \n",
      "contig_545269_3           0              0     0     0             0       0   \n",
      "contig_545269_5           0              0     0     0             0       0   \n",
      "contig_120214_23          0              0     0     0             0       0   \n",
      "contig_120214_50          0              0     0     0             0       0   \n",
      "contig_292417_6           0              0     0     0             0       0   \n",
      "contig_532169_3           0              0     0     0             0       0   \n",
      "contig_260712_21          0              0     0     0             0       0   \n",
      "contig_260712_34          0              0     0     0             0       0   \n",
      "contig_260712_46          0              0     0     0             0       0   \n",
      "contig_308586_72          0              0     0     0             0       0   \n",
      "contig_308586_80          0              0     0     0             0       0   \n",
      "contig_273577_15          0              0     0     0             0       0   \n",
      "contig_243337_11          0              0     0     0             0       0   \n",
      "contig_879637_2           0              0     0     0             0       0   \n",
      "contig_759686_26          0              0     0     0             0       0   \n",
      "contig_85365_29           0              0     0     0             0       0   \n",
      "contig_85365_45           0              0     0     0             0       0   \n",
      "contig_85365_46           0              0     0     0             0       0   \n",
      "contig_193178_15          0              0     0     0             0       0   \n",
      "NaN                       0              0     0     0             0       0   \n",
      "\n",
      "                  WD40_4  T3SS_needle_reg  \n",
      "Gene_name                                  \n",
      "contig_446576_2        0                0  \n",
      "contig_446576_3        0                0  \n",
      "contig_446576_4        0                0  \n",
      "contig_639749_1        0                0  \n",
      "contig_658327_3        0                0  \n",
      "contig_658327_8        0                0  \n",
      "contig_742959_15       0                0  \n",
      "contig_780312_1        0                0  \n",
      "contig_785674_3        0                0  \n",
      "contig_800139_1        0                0  \n",
      "contig_845252_2        0                0  \n",
      "contig_860008_1        0                0  \n",
      "contig_873414_19       0                0  \n",
      "contig_879610_2        0                0  \n",
      "contig_882198_8        0                0  \n",
      "contig_901963_2        0                0  \n",
      "contig_905176_2        0                0  \n",
      "contig_905550_1        0                0  \n",
      "contig_906163_12       0                0  \n",
      "contig_912680_5        0                0  \n",
      "contig_912680_18       0                0  \n",
      "contig_914325_1        0                0  \n",
      "contig_915459_2        0                0  \n",
      "contig_925061_8        0                0  \n",
      "contig_948076_1        0                0  \n",
      "contig_948076_4        0                0  \n",
      "contig_952100_3        0                0  \n",
      "contig_960418_2        0                0  \n",
      "contig_960418_3        0                0  \n",
      "contig_965982_1        0                0  \n",
      "...                  ...              ...  \n",
      "contig_802444_10       0                0  \n",
      "contig_133648_1        0                0  \n",
      "contig_133648_21       0                0  \n",
      "contig_475443_4        0                0  \n",
      "contig_924708_7        0                0  \n",
      "contig_924708_13       0                0  \n",
      "contig_921673_9        0                0  \n",
      "contig_921673_16       0                0  \n",
      "contig_921673_32       0                0  \n",
      "contig_163488_11       0                0  \n",
      "contig_545269_3        0                0  \n",
      "contig_545269_5        0                0  \n",
      "contig_120214_23       0                0  \n",
      "contig_120214_50       0                0  \n",
      "contig_292417_6        0                0  \n",
      "contig_532169_3        0                0  \n",
      "contig_260712_21       0                0  \n",
      "contig_260712_34       0                0  \n",
      "contig_260712_46       0                0  \n",
      "contig_308586_72       0                0  \n",
      "contig_308586_80       0                0  \n",
      "contig_273577_15       0                0  \n",
      "contig_243337_11       0                0  \n",
      "contig_879637_2        0                0  \n",
      "contig_759686_26       0                0  \n",
      "contig_85365_29        0                0  \n",
      "contig_85365_45        0                0  \n",
      "contig_85365_46        0                0  \n",
      "contig_193178_15       0                0  \n",
      "NaN                    0                0  \n",
      "\n",
      "[5519 rows x 46 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_id</th>\n",
       "      <th>Taxonomy</th>\n",
       "      <th>T2SSE</th>\n",
       "      <th>TPR_16</th>\n",
       "      <th>TPR_19</th>\n",
       "      <th>TPR_2</th>\n",
       "      <th>TPR_14</th>\n",
       "      <th>TPR_6</th>\n",
       "      <th>TPR_1</th>\n",
       "      <th>TPR_12</th>\n",
       "      <th>...</th>\n",
       "      <th>WD40_alt</th>\n",
       "      <th>WD40</th>\n",
       "      <th>YscO-like</th>\n",
       "      <th>Type_III_YscX</th>\n",
       "      <th>YopE</th>\n",
       "      <th>YscW</th>\n",
       "      <th>TAL_effector</th>\n",
       "      <th>WD40_3</th>\n",
       "      <th>WD40_4</th>\n",
       "      <th>T3SS_needle_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U_52529</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammproteobac...</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U_51963</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U_52278</td>\n",
       "      <td>d__Bacteria;p__Gemmatimonadetes;c__Gemm-2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U_52536</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U_52439</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>98</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U_52531</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__SAR202</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U_51962</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U_52520</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__SAR202</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U_52478</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria (sister to o__ko...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U_52271</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U_52448</td>\n",
       "      <td>d__Bacteria;p__Gemmatimonadetes;c__Gemm-4</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>U_52403</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>23</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>U_52401</td>\n",
       "      <td>d__Bacteria;p__Actinobacteria;c__Acidimicrobii...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>U_52615</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>U_51967</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>U_52528</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__TK17;o__TK18</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>U_52180</td>\n",
       "      <td>d__Archaea;p__Thaumarchaeota;c__Cenarchaea;o__...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U_52290</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>23</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U_52366</td>\n",
       "      <td>d__Archaea;p__Thaumarchaeota;c__Cenarchaea;o__...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>U_52425</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria;c__Sva0725;o__Sva...</td>\n",
       "      <td>29</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>U_52517</td>\n",
       "      <td>d__Bacteria;p__SBR1093;c__EC214</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U_52105</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__TK17;o__mle1-48</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>U_52525</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria;c__Solibacteres;f...</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>117</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>U_52375</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U_52544</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>U_52505</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>22</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>128</td>\n",
       "      <td>122</td>\n",
       "      <td>107</td>\n",
       "      <td>121</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>U_52514</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>U_52459</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>107</td>\n",
       "      <td>101</td>\n",
       "      <td>94</td>\n",
       "      <td>99</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>U_52524</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>U_41432</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>U_52530</td>\n",
       "      <td>d__Bacteria;p__PAUC34f</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>U_51892</td>\n",
       "      <td>d__Bacteria;p__Gemmatimonadetes;c__Gemm-2</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>U_52380</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>U_52472</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>U_52661</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__SAR202</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>U_52368</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria;c__Acidobacteria-...</td>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>U_51863</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>19</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>U_51873</td>\n",
       "      <td>p__Proteobacteria;c__Deltaproteobacteria;o__Sy...</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>U_52434</td>\n",
       "      <td>d__Bacteria;p__Anck6</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>U_52123</td>\n",
       "      <td>d__Bacteria;p__Chlooflexi;c__Anaerolineae;o__C...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>U_52423</td>\n",
       "      <td>p__Proteobacteria;c__Deltaproteobacteria;o__Sy...</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>U_52087</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>U_52420</td>\n",
       "      <td>d__Bacteria;p__PAUC34f</td>\n",
       "      <td>19</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>U_52637</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>U_52098</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria;c__Acidobacteria-...</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>U_52452</td>\n",
       "      <td>d__Bacteria;p__Gemmatimonadetes;c__Gemm-2</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>U_52410</td>\n",
       "      <td>p__Poribacteria</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>U_52266</td>\n",
       "      <td>d__Bacteria;p__Acidobacteria;c__Solibacteres;f...</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>U_52270</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>U_52532</td>\n",
       "      <td>d__Bacteria;p__Chloroflexi</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>U_52338</td>\n",
       "      <td>d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>U_52582</td>\n",
       "      <td>d__Bacteria;p__Nitrospirae;c__Nitrospirales;f_...</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genome_id                                           Taxonomy T2SSE TPR_16  \\\n",
       "0    U_52529  d__Bacteria;p__Proteobacteria;c__Gammproteobac...    16     30   \n",
       "1    U_51963                         d__Bacteria;p__Chloroflexi    12     15   \n",
       "2    U_52278          d__Bacteria;p__Gemmatimonadetes;c__Gemm-2    10     13   \n",
       "3    U_52536                         d__Bacteria;p__Chloroflexi    12     14   \n",
       "4    U_52439                                    p__Poribacteria    24    103   \n",
       "5    U_52531               d__Bacteria;p__Chloroflexi;c__SAR202    15     10   \n",
       "6    U_51962  d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...    11     31   \n",
       "7    U_52520               d__Bacteria;p__Chloroflexi;c__SAR202    10      4   \n",
       "8    U_52478  d__Bacteria;p__Actinobacteria (sister to o__ko...    11      4   \n",
       "9    U_52271                       d__Bacteria;p__Acidobacteria    17     53   \n",
       "10   U_52448          d__Bacteria;p__Gemmatimonadetes;c__Gemm-4    14     29   \n",
       "11   U_52403                                    p__Poribacteria    23     80   \n",
       "12   U_52401  d__Bacteria;p__Actinobacteria;c__Acidimicrobii...    10      2   \n",
       "13   U_52615                         d__Bacteria;p__Chloroflexi    10     14   \n",
       "14   U_51967  d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...    14     30   \n",
       "15   U_52528         d__Bacteria;p__Chloroflexi;c__TK17;o__TK18    13      9   \n",
       "16   U_52180  d__Archaea;p__Thaumarchaeota;c__Cenarchaea;o__...     7      7   \n",
       "17   U_52290                                    p__Poribacteria    23     87   \n",
       "18   U_52366  d__Archaea;p__Thaumarchaeota;c__Cenarchaea;o__...     9     10   \n",
       "19   U_52425  d__Bacteria;p__Acidobacteria;c__Sva0725;o__Sva...    29     67   \n",
       "20   U_52517                    d__Bacteria;p__SBR1093;c__EC214    10      8   \n",
       "21   U_52105      d__Bacteria;p__Chloroflexi;c__TK17;o__mle1-48    10      6   \n",
       "22   U_52525  d__Bacteria;p__Acidobacteria;c__Solibacteres;f...    20    112   \n",
       "23   U_52375                         d__Bacteria;p__Chloroflexi     7      9   \n",
       "24   U_52544  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...     8      9   \n",
       "25   U_52505                                    p__Poribacteria    22    107   \n",
       "26   U_52514  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...    24     54   \n",
       "27   U_52459                                    p__Poribacteria    23     96   \n",
       "28   U_52524  d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...    11     18   \n",
       "29   U_41432  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...    14     58   \n",
       "30   U_52530                             d__Bacteria;p__PAUC34f    15     52   \n",
       "31   U_51892          d__Bacteria;p__Gemmatimonadetes;c__Gemm-2    16     24   \n",
       "32   U_52380                         d__Bacteria;p__Chloroflexi    10      6   \n",
       "33   U_52472  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...    19     29   \n",
       "34   U_52661               d__Bacteria;p__Chloroflexi;c__SAR202     7      2   \n",
       "35   U_52368  d__Bacteria;p__Acidobacteria;c__Acidobacteria-...    27     63   \n",
       "36   U_51863                                    p__Poribacteria    19     80   \n",
       "37   U_51873  p__Proteobacteria;c__Deltaproteobacteria;o__Sy...    23     56   \n",
       "38   U_52434                               d__Bacteria;p__Anck6    16     34   \n",
       "39   U_52123  d__Bacteria;p__Chlooflexi;c__Anaerolineae;o__C...    20     13   \n",
       "40   U_52423  p__Proteobacteria;c__Deltaproteobacteria;o__Sy...    17     38   \n",
       "41   U_52087  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...    23     12   \n",
       "42   U_52420                             d__Bacteria;p__PAUC34f    19     63   \n",
       "43   U_52637  d__Bacteria;p__Chloroflexi;c__Anaerolineae;o__...    18     30   \n",
       "44   U_52098  d__Bacteria;p__Acidobacteria;c__Acidobacteria-...    17     32   \n",
       "45   U_52452          d__Bacteria;p__Gemmatimonadetes;c__Gemm-2    22     30   \n",
       "46   U_52410                                    p__Poribacteria    19     72   \n",
       "47   U_52266  d__Bacteria;p__Acidobacteria;c__Solibacteres;f...    23     59   \n",
       "48   U_52270  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...    25     23   \n",
       "49   U_52532                         d__Bacteria;p__Chloroflexi    14     15   \n",
       "50   U_52338  d__Bacteria;p__Bacteroidetes;c__Rhodothermia;o...    18     40   \n",
       "51   U_52582  d__Bacteria;p__Nitrospirae;c__Nitrospirales;f_...    13     39   \n",
       "\n",
       "   TPR_19 TPR_2 TPR_14 TPR_6 TPR_1 TPR_12       ...       WD40_alt WD40  \\\n",
       "0      28    34     34    26    27     27       ...              0    0   \n",
       "1      10    13     14    10    10     10       ...              1    1   \n",
       "2      15    11     18     9     9     11       ...              0    4   \n",
       "3      12    15     12    10    13     14       ...              1    5   \n",
       "4      98   106    100    95    99     99       ...              1   88   \n",
       "5      10    11     10     6    10     10       ...              1    1   \n",
       "6      31    31     32    30    25     29       ...              0    1   \n",
       "7       4     4      6     4     4      4       ...              0    0   \n",
       "8       2     4      3     1     2      3       ...              0    2   \n",
       "9      47    54     53    48    47     51       ...              0    4   \n",
       "10     30    29     34    26    22     25       ...              1    9   \n",
       "11     84    85     86    83    84     81       ...              0   26   \n",
       "12      2     2      3     2     2      2       ...              0    0   \n",
       "13     11    13     13    10    12     12       ...              0    2   \n",
       "14     29    29     30    27    28     22       ...              0    0   \n",
       "15      8    10      9     7     7      6       ...              0    4   \n",
       "16      6     7      6     6     7      6       ...              1    4   \n",
       "17     78    97     91    89    89     90       ...              0  180   \n",
       "18     11    10     11     9    10     10       ...              2    1   \n",
       "19     61    65     67    57    56     64       ...              0    9   \n",
       "20      8    11      8     8     8      7       ...              0    0   \n",
       "21      6     8      7     5     6      8       ...              0    0   \n",
       "22    108   108    117    97    93    101       ...              0    6   \n",
       "23      7    12      9     8    11     10       ...              0    2   \n",
       "24      9     9      9     8     8      4       ...              0    0   \n",
       "25    109   128    122   107   121    117       ...              0  148   \n",
       "26     55    59     71    42    48     53       ...              0    5   \n",
       "27     94   107    101    94    99     94       ...              1   71   \n",
       "28     17    18     20    14    14     15       ...              0    4   \n",
       "29     46    60     51    42    44     47       ...              1    2   \n",
       "30     51    55     55    51    53     47       ...              0    5   \n",
       "31     20    24     26    20    14     18       ...              1    1   \n",
       "32      7     7      7     5     6      6       ...              0    1   \n",
       "33     30    34     34    24    26     23       ...              1    1   \n",
       "34      2     2      4     2     2      3       ...              1    0   \n",
       "35     65    68     71    62    58     59       ...              0    7   \n",
       "36     79    86     79    76    82     79       ...              0   42   \n",
       "37     54    65     60    58    55     51       ...              1    4   \n",
       "38     34    36     38    31    35     35       ...              1    1   \n",
       "39     12    13     14    10     9     11       ...              0    5   \n",
       "40     34    43     40    34    39     39       ...              0    1   \n",
       "41     27    17     21    16    16     18       ...              0    0   \n",
       "42     62    68     70    59    61     57       ...              0    7   \n",
       "43     25    32     33    21    28     29       ...              1   10   \n",
       "44     29    35     37    30    29     29       ...              0    6   \n",
       "45     27    30     34    25    17     28       ...              0    6   \n",
       "46     68    77     74    70    77     68       ...              0   41   \n",
       "47     54    59     64    55    51     54       ...              0   11   \n",
       "48     18    27     22    15    20     18       ...              1   34   \n",
       "49     12    14     13    10    13     13       ...              0    1   \n",
       "50     40    40     43    29    33     34       ...              0    0   \n",
       "51     37    40     42    35    36     36       ...              0    3   \n",
       "\n",
       "   YscO-like Type_III_YscX YopE YscW TAL_effector WD40_3 WD40_4  \\\n",
       "0          0             0    0    0            0      0      0   \n",
       "1          0             0    0    0            0      0      0   \n",
       "2          0             0    0    0            0      0      0   \n",
       "3          0             0    0    0            0      0      0   \n",
       "4          1             0    0    0            0      0      0   \n",
       "5          1             0    0    0            0      0      0   \n",
       "6          0             0    0    0            0      0      0   \n",
       "7          0             0    0    0            0      0      0   \n",
       "8          0             0    0    0            0      0      0   \n",
       "9          0             1    0    0            0      0      0   \n",
       "10         1             0    0    0            0      0      0   \n",
       "11         0             0    0    0            0      0      0   \n",
       "12         0             0    0    0            0      0      0   \n",
       "13         0             0    1    1            0      0      0   \n",
       "14         0             0    0    0            1      0      0   \n",
       "15         0             0    0    0            0      0      0   \n",
       "16         0             0    0    0            0      0      0   \n",
       "17         2             0    0    0            0      1      0   \n",
       "18         0             0    0    0            0      0      0   \n",
       "19         0             0    0    0            0      0      0   \n",
       "20         0             0    0    0            0      0      0   \n",
       "21         0             0    0    2            0      0      0   \n",
       "22         0             0    0    0            0      0      1   \n",
       "23         0             0    0    0            0      0      0   \n",
       "24         0             0    0    0            0      0      0   \n",
       "25         2             1    0    0            0      1      0   \n",
       "26         0             1    0    0            0      0      0   \n",
       "27         1             0    0    0            0      0      0   \n",
       "28         0             0    0    0            0      0      0   \n",
       "29         1             0    0    0           17      0      0   \n",
       "30         0             0    1    0            0      0      0   \n",
       "31         0             0    0    0            0      0      0   \n",
       "32         0             0    0    0            0      0      0   \n",
       "33         0             0    0    0            0      1      0   \n",
       "34         0             0    0    0            0      0      0   \n",
       "35         1             0    0    0            0      0      0   \n",
       "36         1             0    0    0            0      0      0   \n",
       "37         0             0    1    0            0      0      1   \n",
       "38         0             0    0    0            0      0      0   \n",
       "39         0             0    0    0            0      0      0   \n",
       "40         1             0    0    0            0      0      0   \n",
       "41         0             0    0    0            0      0      0   \n",
       "42         1             0    0    1            0      0      0   \n",
       "43         0             0    0    0            0      0      0   \n",
       "44         1             0    0    0            0      0      0   \n",
       "45         2             1    1    0            0      0      0   \n",
       "46         1             0    0    0            0      0      0   \n",
       "47         5             0    0    0            0      0      0   \n",
       "48         1             0    0    1            0      0      0   \n",
       "49         0             0    0    0            0      0      0   \n",
       "50         0             0    0    0            0      0      0   \n",
       "51         0             0    0    0            0      0      0   \n",
       "\n",
       "   T3SS_needle_reg  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "5                0  \n",
       "6                0  \n",
       "7                0  \n",
       "8                0  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               0  \n",
       "16               0  \n",
       "17               0  \n",
       "18               0  \n",
       "19               0  \n",
       "20               0  \n",
       "21               0  \n",
       "22               0  \n",
       "23               0  \n",
       "24               0  \n",
       "25               1  \n",
       "26               0  \n",
       "27               0  \n",
       "28               0  \n",
       "29               0  \n",
       "30               0  \n",
       "31               0  \n",
       "32               0  \n",
       "33               0  \n",
       "34               1  \n",
       "35               0  \n",
       "36               0  \n",
       "37               0  \n",
       "38               0  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               0  \n",
       "44               0  \n",
       "45               0  \n",
       "46               0  \n",
       "47               1  \n",
       "48               0  \n",
       "49               0  \n",
       "50               0  \n",
       "51               0  \n",
       "\n",
       "[52 rows x 47 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_hits_wf(gene_dir, hmm_dir,tax_file,1,\"#\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genes_hit=pd.unique(new_df['query name'])\n",
    "repeats_found=pd.unique(new_df['# target name'])\n",
    "hit_df=pd.DataFrame(index=genes_hit,columns=repeats_found)\n",
    "hit_df=hit_df.fillna(0)\n",
    "print hit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name=os.path.join(gene_dir,\"aa_genes_filtered_U_41432_genomic.tsv\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_4</th>\n",
       "      <th>TPR_11</th>\n",
       "      <th>TPR_1</th>\n",
       "      <th>TPR_2</th>\n",
       "      <th>TPR_16</th>\n",
       "      <th>TPR_8</th>\n",
       "      <th>TPR_10</th>\n",
       "      <th>TPR_12</th>\n",
       "      <th>TPR_14</th>\n",
       "      <th>TPR_17</th>\n",
       "      <th>...</th>\n",
       "      <th>TPR_21</th>\n",
       "      <th>TPR_3</th>\n",
       "      <th>WD40</th>\n",
       "      <th>WD40_alt</th>\n",
       "      <th>Ank_2</th>\n",
       "      <th>Ank_3</th>\n",
       "      <th>Ank</th>\n",
       "      <th>Ank_5</th>\n",
       "      <th>Ank_4</th>\n",
       "      <th>TPR_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_76860_1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_76860_5</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_76860_6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_112401_17</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_103936_8</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_86701_5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_96605_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_96701_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141573_8</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141573_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141573_14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_96305_11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_93646_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_93646_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_138012_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_87694_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_208735_7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_123097_1</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_100995_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_100465_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_222368_19</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_193301_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_228243_1</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_114601_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_124979_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_160109_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_100675_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_138664_1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_105279_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_105279_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_158154_10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_126141_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_122392_3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_122392_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_118508_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_173623_1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_185358_3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_101217_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_101217_19</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_133421_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_245003_2</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_34769_2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_108868_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_103381_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_117430_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_101982_23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141481_1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141481_2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_141481_3</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_70328_11</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_97400_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_97400_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_55018_4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_90042_16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_96699_3</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_131156_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_15225_7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_92980_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_181127_2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L35C15UnmappedToSymbiodinium_L35C15UnmappedToPlutea_nesoni_seqprepped_13206_GBR_UNSW_H8P31ADXX_TAAGGCGA_combinedL1L2__merged_contig_203816_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    TPR_4  TPR_11  TPR_1  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       7      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       8      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       4      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     11      12     13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       2      1   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       1      1   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       2      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     10       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     11      12     14   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       6      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     16      14     19   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       8      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "...                                                   ...     ...    ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      6       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       6      5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      6       7      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       4      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       7      7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       1      1   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      7       4      6   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       3      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     12      10     13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      7      10     13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      9       7      9   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       0      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       5      5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "\n",
       "                                                    TPR_2  TPR_16  TPR_8  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      9       7      9   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      9       5      7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       5      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     13       8     13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      7       2      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      1       1      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       1      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       2      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       5      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     18      13     16   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       3      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       4      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     21      14     18   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       6      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      7       4      7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "...                                                   ...     ...    ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      6       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      6       5      5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       6      8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     10       5      7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       2      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       2      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       2      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       3      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      8       6      6   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       2      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     13      10     13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     13      10     12   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       2      1   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       2      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...     10       7     10   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       1      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       1      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       3      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0      0   \n",
       "\n",
       "                                                    TPR_10  TPR_12  TPR_14  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8       7       8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8       5       7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      13       9      12   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       2       4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       1   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       1       2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       7       4       6   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      12      12      16   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       4       3       4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5       4       5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      12      13      22   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       1       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       5       7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       7       3       4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "...                                                    ...     ...     ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       4       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5       4       5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       3       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8       6       8   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       3       1       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      10       7       9   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       3       2       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       1       3       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5       5       9   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2       1       2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      13      12      13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      10      11      13   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       1       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       2       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      10       7      10   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       1       2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5       3       5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0       0       0   \n",
       "\n",
       "                                                    TPR_17   ...    TPR_21  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       7   ...         3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8   ...         4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      14   ...         4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       3   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      12   ...         7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      14   ...        11   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       3   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "...                                                    ...   ...       ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       7   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       7   ...         4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8   ...         3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       3   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       6   ...         3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      11   ...         7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       8   ...         5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       2   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       9   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       5   ...         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...       0   ...         0   \n",
       "\n",
       "                                                    TPR_3  WD40  WD40_alt  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0    15         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         7   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "...                                                   ...   ...       ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     9         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      9     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0     0         0   \n",
       "\n",
       "                                                    Ank_2  Ank_3  Ank  Ank_5  \\\n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3      5    5      4   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3      4    4      3   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5      7    7      5   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4      8    8      6   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3      6    6      5   \n",
       "...                                                   ...    ...  ...    ...   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3      4    5      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2      3    3      2   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3      7    7      6   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0      0    0      0   \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4      9    9      7   \n",
       "\n",
       "                                                    Ank_4  TPR_18  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      3       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       5  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      6       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      4       0  \n",
       "...                                                   ...     ...  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      2       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      5       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      0       0  \n",
       "L35C15UnmappedToSymbiodinium_L35C15UnmappedToPl...      7       0  \n",
       "\n",
       "[89 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ((contig,repeat_motif),count) in grouped_counts.iteritems():\n",
    "    #print contig,repeat_motif,count\n",
    "    hit_df.set_value(contig,repeat_motif,count)\n",
    "hit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "    \n",
    "    \n",
    "def write_windows_colour_file(windows_file,Donovan_colour_file,output_file):\n",
    "    windows_dict=new_windows_colours_files(windows_file,Donovan_colour_file)\n",
    "    output_txt=\"\\n\".join([\"\\t\".join((key,value)) for key,value in windows_dict.iteritems()])\n",
    "    \n",
    "    with open(output_file,'w') as new_colour_file:\n",
    "        new_colour_file.write(output_txt)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def convert_colour_files_for_windows(windows_size, output_directory, donovan_colour_files,sequence_file):\n",
    "    \n",
    "    \n",
    "    return\n",
    "    \n",
    "def load_Francesco_colour_file(directory_path):\n",
    "    colour_files={}\n",
    "    for file_name in glob(os.path.join(directory_path,\"*.tab\")):\n",
    "        with open(file_name) as current_genome:\n",
    "            genome_file_name=os.path.basename(file_name).split(\".fasta\")[0]+\".fasta\"\n",
    "            colour_files[genome_file_name]={}\n",
    "            next(current_genome)\n",
    "            for line in current_genome:\n",
    "                contig, Ancester_lineage,LCA_lineage,R,G,B=line.strip().split(\"\\t\")\n",
    "                colour_files[genome_file_name][contig]=(R,G,B)\n",
    "    return colour_files\n",
    "\n",
    "def write_Donovan_colour_files(output_directory,F_colour_files):\n",
    "    donovan_format={}\n",
    "    for file_name,contig_values in F_colour_files.iteritems():\n",
    "        print file_name\n",
    "        donovan_format[file_name+\".don.tab\"]={}\n",
    "        new_colour_file=open(os.path.join(output_directory,file_name+\".don.tab\"),'w')\n",
    "        storage_list=[\"na\"]*len(contig_values)\n",
    "        i=0\n",
    "        for contig, colour_tuple in contig_values.iteritems():\n",
    "            colour_code=[str(int(float(colour_prop)*255)) for colour_prop in colour_tuple]\n",
    "            #print colour_code\n",
    "            donovan_format[file_name+\".don.tab\"][contig]=\",\".join(colour_code)\n",
    "            storage_list[i]=\"\\t\".join([contig,\",\".join(colour_code)])\n",
    "            i+=1\n",
    "        new_colour_file.write(\"\\n\".join(storage_list))         \n",
    "        new_colour_file.close()  \n",
    "    return\n",
    "        \n",
    "def new_windows_colours_files(windows_file,Donovan_colour_file):\n",
    "    colour_pairings={}\n",
    "    with open(Donovan_colour_file) as Don_col:\n",
    "        for line in Don_col:\n",
    "            contig, col_tup=line.strip().split(\"\\t\")\n",
    "            #col_tup=tuple()\n",
    "            colour_pairings[contig]=col_tup\n",
    "    #print \"The Donovan style dictionary\",colour_pairings\n",
    "    \n",
    "    reg_pat=\"(?:>)(.*)(?:\\n)\" #Extracts contig name\n",
    "    #colour_pairings=defaultdict(lambda x: x,colour_pairings)\n",
    "    #with open(windows_file,'r') as windows_seq:\n",
    "    #    for line in windows_seq:\n",
    "    #        if line.startswith(\">\"):\n",
    "    windows=open(windows_file,'r')\n",
    "    windows_txt=\"\".join(windows.readlines()) #reasonable since single cells should not get big\n",
    "    windows.close()\n",
    "    windows_dict={}\n",
    "    for match in re.finditer(reg_pat,windows_txt):\n",
    "        contig_name=match.groups()[0]\n",
    "        #print contig_name\n",
    "        contig,position=contig_name.rsplit(\":\",1) #sep name and postion\n",
    "        if contig in colour_pairings:\n",
    "            windows_dict[contig_name]=colour_pairings[contig]\n",
    "    #print \"The windows dictionary\", windows_dict\n",
    "    \n",
    "    return windows_dict\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 5588 contigs in the lca colour file. 5890 windows are to be coloured.\n"
     ]
    }
   ],
   "source": [
    "windows_file=\"C:\\\\Users\\\\Baker\\\\Google Drive\\\\Honours\\\\SingleCellM\\\\Experimenting\\\\ACE-SCG_MDA003-K22.scaffoldswindows.fasta\"\n",
    "\n",
    "francesco_colour_file=\"C:\\\\Users\\\\Baker\\\\Google Drive\\\\Honours\\\\SingleCellM\\\\Experimenting\\\\ACE-SCG_MDA003-K22.scaffolds.fasta.gz-nt_lca-colors.tab\"\n",
    "\n",
    "output_file=\"C:\\\\Users\\\\Baker\\\\Google Drive\\\\Honours\\\\SingleCellM\\\\Experimenting\\\\new_ACE-SCG_MDA003-K22.window_colours.tab\"\n",
    "\n",
    "windows_colour_file_wf(windows_file,francesco_colour_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE-SCG_MDA003-M17.scaffolds.fasta\n",
      "ACE-SCG_MDA005-L4.scaffolds.fasta\n",
      "ACE-SCG_MDA003-O19.scaffolds.fasta\n",
      "ACE-SCG_MDA004-K17.scaffolds.fasta\n",
      "ACE-SCG_MDA004-K10.scaffolds.fasta\n",
      "ACE-SCG_MDA004-G6.scaffolds.fasta\n",
      "ACE-SCG_MDA003-O15.scaffolds.fasta\n",
      "ACE-SCG_MDA006-J10.scaffolds.fasta\n",
      "ACE-SCG_MDA006-O3.scaffolds.fasta\n",
      "ACE-SCG_MDA005-J11.scaffolds.fasta\n",
      "GCA_000986845.1_ASM98684v1_genomic.fasta\n",
      "ACE-SCG_MDA003-N9.scaffolds.fasta\n",
      "ACE-SCG_MDA004-N3.scaffolds.fasta\n",
      "ACE-SCG_MDA004-M13.scaffolds.fasta\n",
      "ACE-SCG_MDA004-N11.scaffolds.fasta\n",
      "GCA_001549325.1_SCGC-AAA382N08_genomic.fasta\n",
      "ACE-SCG_MDA006-P3.scaffolds.fasta\n",
      "ACE-SCG_MDA003-K22.scaffolds.fasta\n",
      "ACE-SCG_MDA006-P5.scaffolds.fasta\n",
      "ACE-SCG_MDA003-M3.scaffolds.fasta\n",
      "ACE-SCG_MDA004-L10.scaffolds.fasta\n",
      "ACE-SCG_MDA005-N12.scaffolds.fasta\n",
      "ACE-SCG_MDA003-N16.scaffolds.fasta\n"
     ]
    }
   ],
   "source": [
    "colour_data=load_Francesco_colour_file(\"C:\\\\Users\\\\Baker\\\\Google Drive\\\\Honours\\\\SingleCellM\\\\Francesco_Data\\\\nt_tab\")\n",
    "write_Donovan_colour_files(\"C:\\\\Users\\\\Baker\\\\Google Drive\\\\Honours\\\\SingleCellM\\\\Francesco_Data\\\\Donovan_colours\",colour_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legend.numpoints': 1, 'axes.axisbelow': True, 'font.sans-serif': [u'Bitstream Vera Sans'], 'axes.labelcolor': '.15', 'ytick.major.size': 0.0, 'axes.grid': True, 'ytick.minor.size': 0.0, 'legend.scatterpoints': 1, 'axes.edgecolor': 'white', 'grid.color': 'white', 'legend.frameon': False, 'ytick.color': '.15', 'xtick.major.size': 0.0, 'figure.facecolor': 'white', 'xtick.color': '.15', 'xtick.minor.size': 0.0, 'font.family': [u'sans-serif'], 'xtick.direction': u'out', 'lines.solid_capstyle': u'round', 'grid.linestyle': u'-', 'image.cmap': u'Greys', 'axes.facecolor': '#EAEAF2', 'text.color': '.15', 'ytick.direction': u'out', 'axes.linewidth': 0.0}\n",
      "oxidative_phosphorylation ['map00190'] Blues\n",
      "two-component ['map02020'] Greens\n",
      "vitamins&cofactors ['map00730', 'map00740', 'map00750', 'map00760', 'map00770', 'map00780', 'map00785', 'map00790', 'map00670', 'map00830', 'map00860', 'map00130'] Oranges\n",
      "AminoAcidMetabolism ['map00250', 'map00270', 'map00260', 'map00280', 'map00290', 'map00300', 'map00310', 'map00220', 'map00330', 'map00340', 'map00350', 'map00360', 'map00380', 'map00400'] Purples\n",
      "nitrogen-sulfur-fatty_acid-photosynthesis ['map00910', 'map00920', 'map01212', 'map00195'] Reds\n",
      "carbon ['map01200'] Greys\n",
      "amino-acids ['map01230'] Blues\n",
      "oxidative_phosphorylation ['map00190'] Blues\n",
      "two-component ['map02020'] Greens\n",
      "vitamins&cofactors ['map00730', 'map00740', 'map00750', 'map00760', 'map00770', 'map00780', 'map00785', 'map00790', 'map00670', 'map00830', 'map00860', 'map00130'] Oranges\n",
      "AminoAcidMetabolism ['map00250', 'map00270', 'map00260', 'map00280', 'map00290', 'map00300', 'map00310', 'map00220', 'map00330', 'map00340', 'map00350', 'map00360', 'map00380', 'map00400'] Purples\n",
      "nitrogen-sulfur-fatty_acid-photosynthesis ['map00910', 'map00920', 'map01212', 'map00195'] Reds\n",
      "carbon ['map01200'] Greys\n",
      "amino-acids ['map01230'] Blues\n"
     ]
    }
   ],
   "source": [
    "sns.set_style({'font.family':'sans-serif', 'font.sans-serif':'Bitstream Vera Sans'})\n",
    "\n",
    "print sns.axes_style()\n",
    "\n",
    "def fix_eps(fpath):\n",
    "    \"\"\"Fix carriage returns in EPS files caused by Arial font.\"\"\"\n",
    "    txt = b\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        for line in f:\n",
    "            if b\"\\r\\rHebrew\" in line:\n",
    "                line = line.replace(b\"\\r\\rHebrew\", b\"Hebrew\")\n",
    "            txt += line\n",
    "    with open(fpath, \"wb\") as f:\n",
    "        f.write(txt)\n",
    "\n",
    "def plot_heatmap_proportion(path_id, path_name, KO_genome_files, cmap,output_dir,database_dir,bin_names):\n",
    "    \n",
    "    sns.set_style({'font.family':'sans-serif', 'font.sans-serif':'Bitstream Vera Sans'})\n",
    "\n",
    "    PTH_MO_pairs = load_local_kegg_database_pairings(database_dir,[(\"pathway\",\"module\")], False)[(\"pathway\",\"module\")]\n",
    "    linkable_base_paths=set(PTH_MO_pairs.iterkeys()) & set(path_id)\n",
    "    base_mod= set(itertools.chain(*[PTH_MO_pairs[pathway] for pathway in linkable_base_paths]))\n",
    "    \n",
    "    MO_KO_pairs  = load_local_kegg_database_pairings(database_dir,[(\"module\",\"orthology\")], False)[(\"module\",\"orthology\")]\n",
    "    all_modules = {MO:MO_KO_pairs[MO] for MO in base_mod} #kc.link_ids('ko', base_mod)\n",
    "    module_totals = pd.Series(\n",
    "        {\n",
    "            mod_id: len(ko_ids)\n",
    "            for mod_id, ko_ids in all_modules.iteritems()\n",
    "        }\n",
    "    )\n",
    "    rev_modules = dictionary.reverse_mapping(all_modules)\n",
    "    \n",
    "    module_names=load_readable_names(database_dir,[\"module\"],False)[\"module\"]\n",
    "    \n",
    "    mod_prop = {}\n",
    "    for genome_id, KOs in KO_genome_files.iteritems():\n",
    "        mod_prop[genome_id] = {}\n",
    "        genome_ko_ids = KOs\n",
    "        for mod_id, ko_ids in all_modules.iteritems():\n",
    "            mod_prop[genome_id][mod_id] = len(set(ko_ids) & genome_ko_ids)\n",
    "    \n",
    "    mod_prop = pd.DataFrame(mod_prop).fillna(0)\n",
    "    mod_prop = mod_prop[mod_prop.sum(axis=1) > 0].divide(module_totals, axis='index').dropna()\n",
    "    mod_prop = mod_prop.rename(index=module_names, columns=bin_names)\n",
    "    mod_prop=mod_prop.sort_index(axis='columns')\n",
    "    \n",
    "    h2 = sns.clustermap(mod_prop, col_cluster=False, method='complete', cmap=cmap)\n",
    "    \n",
    "    #font_0=h2.FontProperties()\n",
    "    #font_0.set_family('sans-serif')\n",
    "    #font_0.set_style('Bitstream Vera Sans')\n",
    "    h2.ax_heatmap.set_title(path_name)\n",
    "    for text in h2.ax_heatmap.get_yticklabels():\n",
    "        text.set_rotation('horizontal')\n",
    "    for text in h2.ax_heatmap.get_xticklabels():\n",
    "        text.set_rotation('vertical')\n",
    "    #h2.savefig(os.path.join(output_dir,'{}-modules_proportion.pdf'.format(path_name)))\n",
    "    h2.savefig(os.path.join(output_dir,'{}-modules_proportion.eps'.format(path_name)),format=\"eps\")\n",
    "    h2.savefig(os.path.join(output_dir,'{}-modules_proportion.svg'.format(path_name)),format=\"svg\")\n",
    "    fix_eps(os.path.join(output_dir,'{}-modules_proportion.eps'.format(path_name)))\n",
    "    \n",
    "colors = ['Blues', 'Greens', 'Oranges', 'Purples', 'Reds', 'Greys','Blues','Blues']\n",
    "for (path_name, path_id), palette in zip(pathways.iteritems(), colors):\n",
    "    print path_name, path_id, palette\n",
    "    plot_heatmap_proportion(path_id, path_name, KO_genome_hits, palette,output_dir,os.path.join(output_dir,\"Databases\"),bin_names)\n",
    "\n",
    "\n",
    "\n",
    "def group_micro_plot_heatmap_proprtion(path_id, path_name, KO_genome_files, cmap,output_dir,database_dir,bin_names):\n",
    "    \n",
    "    sns.set_style({'font.family':'sans-serif', 'font.sans-serif':'Bitstream Vera Sans'})\n",
    "    \n",
    "    PTH_MO_pairs = load_local_kegg_database_pairings(database_dir,[(\"pathway\",\"module\")], False)[(\"pathway\",\"module\")]\n",
    "    linkable_base_paths=set(PTH_MO_pairs.iterkeys()) & set(path_id)\n",
    "    base_mod= set(itertools.chain(*[PTH_MO_pairs[pathway] for pathway in linkable_base_paths]))\n",
    "    \n",
    "    MO_KO_pairs  = load_local_kegg_database_pairings(database_dir,[(\"module\",\"orthology\")], False)[(\"module\",\"orthology\")]\n",
    "    all_modules = {MO:MO_KO_pairs[MO] for MO in base_mod} #kc.link_ids('ko', base_mod)\n",
    "    module_totals = pd.Series(\n",
    "        {\n",
    "            mod_id: len(ko_ids)\n",
    "            for mod_id, ko_ids in all_modules.iteritems()\n",
    "        }\n",
    "    )\n",
    "    rev_modules = dictionary.reverse_mapping(all_modules)\n",
    "    \n",
    "    module_names=load_readable_names(database_dir,[\"module\"],False)[\"module\"]\n",
    "    \n",
    "    mod_prop = {}\n",
    "    for genome_id, KOs in KO_genome_files.iteritems():\n",
    "        mod_prop[genome_id] = {}\n",
    "        genome_ko_ids = KOs\n",
    "        for mod_id, ko_ids in all_modules.iteritems():\n",
    "            mod_prop[genome_id][mod_id] = len(set(ko_ids) & genome_ko_ids)\n",
    "            \n",
    "    euk_names=[\"coral\",\"SymbC15\"]\n",
    "    \n",
    "    bacteria=set(mod_prop.keys()) - set(euk_names)\n",
    "    \n",
    "    new_mod_prop={}\n",
    "    new_mod_prop[\"microorganisms\"]={}\n",
    "    for module in mod_prop[\"coral\"].iterkeys():\n",
    "        new_mod_prop[\"microorganisms\"][module]=0\n",
    "    for euk in euk_names:\n",
    "        new_mod_prop[euk]=mod_prop[euk]\n",
    "    for genome, module_counts in mod_prop.iteritems():\n",
    "        if genome not in euk_names:\n",
    "            for module, count in module_counts.iteritems():\n",
    "                new_mod_prop[\"microorganisms\"][module]=max(new_mod_prop[\"microorganisms\"][module],count)\n",
    "                \n",
    "    new_bin_names={gen_id:gen_name for gen_id,gen_name in bin_names.iteritems() if gen_id in euk_names}\n",
    "    new_bin_names[\"microorganisms\"]=\"microorganisms\"\n",
    "    bin_names=new_bin_names\n",
    "    \n",
    "    mod_prop = pd.DataFrame(new_mod_prop).fillna(0)\n",
    "    mod_prop = mod_prop[mod_prop.sum(axis=1) > 0].divide(module_totals, axis='index').dropna()\n",
    "    mod_prop = mod_prop.rename(index=module_names, columns=bin_names)\n",
    "    mod_prop=mod_prop.sort_index(axis='columns')\n",
    "    \n",
    "        \n",
    "    h2 = sns.clustermap(mod_prop, col_cluster=False, method='complete', cmap=cmap)\n",
    "    #font_0=h2.FontProperties()\n",
    "    #h2.set_style({'font.family':'sans-serif', 'font.sans-serif':'Bitstream Vera Sans'})\n",
    "    #font_0.set_family('sans-serif')\n",
    "    #font_0.set_style('Bitstream Vera Sans')\n",
    "    h2.ax_heatmap.set_title(path_name)\n",
    "    for text in h2.ax_heatmap.get_yticklabels():\n",
    "        text.set_rotation('horizontal')\n",
    "    for text in h2.ax_heatmap.get_xticklabels():\n",
    "        text.set_rotation('vertical')\n",
    "    #h2.savefig(os.path.join(output_dir,'{}_grouped_microbes_modules_proportion.pdf'.format(path_name)))\n",
    "    h2.savefig(os.path.join(output_dir,'{}_grouped_microbes_modules_proportion.eps'.format(path_name)),format=\"eps\")\n",
    "    h2.savefig(os.path.join(output_dir,'{}_grouped_microbes_modules_proportion.svg'.format(path_name)),format=\"svg\")\n",
    "    fix_eps(os.path.join(output_dir,'{}_grouped_microbes_modules_proportion.eps'.format(path_name)))\n",
    "    \n",
    "colors = ['Blues', 'Greens', 'Oranges', 'Purples', 'Reds', 'Greys','Blues','Blues']\n",
    "for (path_name, path_id), palette in zip(pathways.iteritems(), colors):\n",
    "    print path_name, path_id, palette\n",
    "    group_micro_plot_heatmap_proprtion(path_id, path_name, KO_genome_hits, palette,output_dir,os.path.join(output_dir,\"Databases\"),bin_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
